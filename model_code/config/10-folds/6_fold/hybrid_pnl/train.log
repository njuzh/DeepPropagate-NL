nohup: ignoring input
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:107: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:30: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

12/27 03:47:08 label: default
12/27 03:47:08 description:
  default configuration
  next line of description
  last line
12/27 03:47:08 /root/icpc/icpc/translate/__main__.py config/10-folds/6_fold/hybrid_pnl/config.yaml --train -v
12/27 03:47:08 commit hash 74e0554cb3eb5df835cef993ad570ff8de651f71
12/27 03:47:08 tensorflow version: 1.14.0
12/27 03:47:08 program arguments
12/27 03:47:08   aggregation_method   'sum'
12/27 03:47:08   align_encoder_id     0
12/27 03:47:08   allow_growth         True
12/27 03:47:08   attention_type       'global'
12/27 03:47:08   attn_filter_length   0
12/27 03:47:08   attn_filters         0
12/27 03:47:08   attn_prev_word       False
12/27 03:47:08   attn_size            128
12/27 03:47:08   attn_temperature     1.0
12/27 03:47:08   attn_window_size     0
12/27 03:47:08   average              False
12/27 03:47:08   baseline_activation  None
12/27 03:47:08   baseline_learning_rate 0.001
12/27 03:47:08   baseline_optimizer   'adam'
12/27 03:47:08   baseline_steps       0
12/27 03:47:08   batch_mode           'standard'
12/27 03:47:08   batch_size           64
12/27 03:47:08   beam_size            5
12/27 03:47:08   bidir                True
12/27 03:47:08   bidir_projection     False
12/27 03:47:08   binary               False
12/27 03:47:08   cell_size            256
12/27 03:47:08   cell_type            'GRU'
12/27 03:47:08   character_level      False
12/27 03:47:08   checkpoints          []
12/27 03:47:08   conditional_rnn      False
12/27 03:47:08   config               'config/10-folds/6_fold/hybrid_pnl/config.yaml'
12/27 03:47:08   convolutions         None
12/27 03:47:08   data_dir             'data/gooddata/6_fold'
12/27 03:47:08   debug                False
12/27 03:47:08   decay_after_n_epoch  1
12/27 03:47:08   decay_every_n_epoch  1
12/27 03:47:08   decay_if_no_progress None
12/27 03:47:08   decoders             [{'max_len': 40, 'name': 'nl'}]
12/27 03:47:08   description          'default configuration\nnext line of description\nlast line\n'
12/27 03:47:08   dev_prefix           'test'
12/27 03:47:08   early_stopping       True
12/27 03:47:08   embedding_dropout    0.0
12/27 03:47:08   embedding_initializer None
12/27 03:47:08   embedding_size       256
12/27 03:47:08   embedding_weight_scale None
12/27 03:47:08   embeddings_on_cpu    True
12/27 03:47:08   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 80, 'name': 'pnl'}]
12/27 03:47:08   ensemble             False
12/27 03:47:08   eval_burn_in         0
12/27 03:47:08   feed_previous        0.0
12/27 03:47:08   final_state          'last'
12/27 03:47:08   freeze_variables     []
12/27 03:47:08   generate_first       True
12/27 03:47:08   gpu_id               3
12/27 03:47:08   highway_layers       0
12/27 03:47:08   initial_state_dropout 0.0
12/27 03:47:08   initializer          None
12/27 03:47:08   input_layer_dropout  0.0
12/27 03:47:08   input_layers         None
12/27 03:47:08   keep_best            5
12/27 03:47:08   keep_every_n_hours   0
12/27 03:47:08   label                'default'
12/27 03:47:08   layer_norm           False
12/27 03:47:08   layers               1
12/27 03:47:08   learning_rate        0.5
12/27 03:47:08   learning_rate_decay_factor 0.95
12/27 03:47:08   len_normalization    1.0
12/27 03:47:08   log_file             'log.txt'
12/27 03:47:08   loss_function        'xent'
12/27 03:47:08   max_dev_size         0
12/27 03:47:08   max_epochs           100
12/27 03:47:08   max_gradient_norm    5.0
12/27 03:47:08   max_len              50
12/27 03:47:08   max_steps            600000
12/27 03:47:08   max_test_size        0
12/27 03:47:08   max_to_keep          1
12/27 03:47:08   max_train_size       0
12/27 03:47:08   maxout_stride        None
12/27 03:47:08   mem_fraction         1.0
12/27 03:47:08   min_learning_rate    1e-06
12/27 03:47:08   model_dir            'models/6_fold_hybrid_pnl'
12/27 03:47:08   moving_average       None
12/27 03:47:08   no_gpu               False
12/27 03:47:08   optimizer            'sgd'
12/27 03:47:08   orthogonal_init      False
12/27 03:47:08   output               None
12/27 03:47:08   output_dropout       0.0
12/27 03:47:08   parallel_iterations  16
12/27 03:47:08   pervasive_dropout    False
12/27 03:47:08   pooling_avg          True
12/27 03:47:08   post_process_script  None
12/27 03:47:08   pred_deep_layer      False
12/27 03:47:08   pred_edits           False
12/27 03:47:08   pred_embed_proj      True
12/27 03:47:08   pred_maxout_layer    True
12/27 03:47:08   purge                False
12/27 03:47:08   raw_output           False
12/27 03:47:08   read_ahead           1
12/27 03:47:08   reconstruction_attn_weight 0.05
12/27 03:47:08   reconstruction_decoders False
12/27 03:47:08   reconstruction_weight 1.0
12/27 03:47:08   reinforce_after_n_epoch None
12/27 03:47:08   remove_unk           False
12/27 03:47:08   reverse              False
12/27 03:47:08   reverse_input        True
12/27 03:47:08   reward_function      'sentence_bleu'
12/27 03:47:08   rnn_feed_attn        True
12/27 03:47:08   rnn_input_dropout    0.0
12/27 03:47:08   rnn_output_dropout   0.0
12/27 03:47:08   rnn_state_dropout    0.0
12/27 03:47:08   save                 False
12/27 03:47:08   score_function       'corpus_bleu'
12/27 03:47:08   score_functions      ['bleu', 'loss']
12/27 03:47:08   script_dir           'scripts'
12/27 03:47:08   sgd_after_n_epoch    None
12/27 03:47:08   sgd_learning_rate    1.0
12/27 03:47:08   shuffle              True
12/27 03:47:08   softmax_temperature  1.0
12/27 03:47:08   steps_per_checkpoint 2000
12/27 03:47:08   steps_per_eval       2000
12/27 03:47:08   swap_memory          True
12/27 03:47:08   tie_embeddings       False
12/27 03:47:08   time_pooling         None
12/27 03:47:08   train                True
12/27 03:47:08   train_initial_states True
12/27 03:47:08   train_prefix         'train'
12/27 03:47:08   truncate_lines       True
12/27 03:47:08   update_first         False
12/27 03:47:08   use_baseline         False
12/27 03:47:08   use_dropout          False
12/27 03:47:08   use_lstm_full_state  False
12/27 03:47:08   use_previous_word    True
12/27 03:47:08   verbose              True
12/27 03:47:08   vocab_prefix         'vocab'
12/27 03:47:08   weight_scale         None
12/27 03:47:08   word_dropout         0.0
12/27 03:47:08 python random seed: 2991635175520595013
12/27 03:47:08 tf random seed:     5640955238570597305
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:203: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

12/27 03:47:08 creating model
12/27 03:47:08 using device: /gpu:3
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:230: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

12/27 03:47:08 copying vocab to models/6_fold_hybrid_pnl/data/vocab.code
12/27 03:47:08 copying vocab to models/6_fold_hybrid_pnl/data/vocab.pnl
12/27 03:47:08 copying vocab to models/6_fold_hybrid_pnl/data/vocab.nl
12/27 03:47:08 reading vocabularies
12/27 03:47:08 creating model
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:33: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f2f9557ac18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f2f9557ac18>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:226: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f2f9557ad68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f2f9557ad68>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f301c03dcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f301c03dcf8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f301c03dcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f301c03dcc0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301be6ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301be6ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:838: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bce7c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bce7c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bce7c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bce7c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:432: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:435: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bc3e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bc3e128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bc3e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bc3e128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bac2ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301bac2ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301ba79fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301ba79fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301984be80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f301984be80>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3019758da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3019758da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30197b49b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30197b49b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30197907b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30197907b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30197907b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30197907b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:919: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f3019639198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f3019639198>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:10: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:131: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:223: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f2fb92619e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f2fb92619e8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb91ffac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb91ffac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb9296780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb9296780>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb9271f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb9271f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30198944a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f30198944a8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb9168668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb9168668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb909dcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb909dcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb909dcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2fb909dcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
12/27 03:47:15 model parameters (45)
12/27 03:47:15   baseline_step:0 ()
12/27 03:47:15   decoder_nl/attention_code/U_a/kernel:0 (512, 128)
12/27 03:47:15   decoder_nl/attention_code/W_a/bias:0 (128,)
12/27 03:47:15   decoder_nl/attention_code/W_a/kernel:0 (256, 128)
12/27 03:47:15   decoder_nl/attention_code/v_a:0 (128,)
12/27 03:47:15   decoder_nl/attention_pnl/U_a/kernel:0 (512, 128)
12/27 03:47:15   decoder_nl/attention_pnl/W_a/bias:0 (128,)
12/27 03:47:15   decoder_nl/attention_pnl/W_a/kernel:0 (256, 128)
12/27 03:47:15   decoder_nl/attention_pnl/v_a:0 (128,)
12/27 03:47:15   decoder_nl/code_pnl/initial_state_projection/bias:0 (256,)
12/27 03:47:15   decoder_nl/code_pnl/initial_state_projection/kernel:0 (512, 256)
12/27 03:47:15   decoder_nl/gru_cell/candidate/bias:0 (256,)
12/27 03:47:15   decoder_nl/gru_cell/candidate/kernel:0 (1024, 256)
12/27 03:47:15   decoder_nl/gru_cell/gates/bias:0 (512,)
12/27 03:47:15   decoder_nl/gru_cell/gates/kernel:0 (1024, 512)
12/27 03:47:15   decoder_nl/maxout/bias:0 (256,)
12/27 03:47:15   decoder_nl/maxout/kernel:0 (1024, 256)
12/27 03:47:15   decoder_nl/softmax0/kernel:0 (128, 256)
12/27 03:47:15   decoder_nl/softmax1/bias:0 (37989,)
12/27 03:47:15   decoder_nl/softmax1/kernel:0 (256, 37989)
12/27 03:47:15   embedding_code:0 (50000, 256)
12/27 03:47:15   embedding_nl:0 (37989, 256)
12/27 03:47:15   embedding_pnl:0 (37459, 256)
12/27 03:47:15   encoder_code/initial_state_bw:0 (256,)
12/27 03:47:15   encoder_code/initial_state_fw:0 (256,)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
12/27 03:47:15   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
12/27 03:47:15   encoder_pnl/initial_state_bw:0 (256,)
12/27 03:47:15   encoder_pnl/initial_state_fw:0 (256,)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
12/27 03:47:15   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
12/27 03:47:15   global_step:0 ()
12/27 03:47:15   learning_rate:0 ()
12/27 03:47:15 number of parameters: 44.87M
WARNING:tensorflow:From /root/icpc/icpc/translate/translation_model.py:666: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

12/27 03:47:16 global step: 0
12/27 03:47:16 baseline step: 0
12/27 03:47:16 reading training data
12/27 03:47:16 total line count: 156721
12/27 03:47:22   lines read: 100000
12/27 03:47:25 files: data/gooddata/6_fold/train.code data/gooddata/6_fold/train.pnl data/gooddata/6_fold/train.nl
12/27 03:47:25 lines reads: 156721
12/27 03:47:25 reading development data
12/27 03:47:26 files: data/gooddata/6_fold/test.code data/gooddata/6_fold/test.pnl data/gooddata/6_fold/test.nl
12/27 03:47:26 lines reads: 17413
12/27 03:47:26 starting training
12/27 04:16:35 step 2000 epoch 1 learning rate 0.5 step-time 0.873 loss 81.150
12/27 04:16:35 starting evaluation
12/27 04:21:56 test bleu=0.64 loss=64.65 penalty=0.875 ratio=0.883
12/27 04:21:56 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 04:21:56 finished saving model
12/27 04:21:56 new best model
12/27 04:28:33   decaying learning rate to: 0.475
12/27 04:51:05 step 4000 epoch 2 learning rate 0.475 step-time 0.872 loss 59.819
12/27 04:51:05 starting evaluation
12/27 04:56:07 test bleu=5.30 loss=55.26 penalty=0.768 ratio=0.791
12/27 04:56:07 saving model to models/6_fold_hybrid_pnl/checkpoints
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
12/27 04:56:07 finished saving model
12/27 04:56:07 new best model
12/27 05:09:15   decaying learning rate to: 0.451
12/27 05:25:15 step 6000 epoch 3 learning rate 0.451 step-time 0.872 loss 52.034
12/27 05:25:15 starting evaluation
12/27 05:29:54 test bleu=7.89 loss=50.71 penalty=0.653 ratio=0.701
12/27 05:29:54 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 05:29:54 finished saving model
12/27 05:29:54 new best model
12/27 05:49:37   decaying learning rate to: 0.429
12/27 05:58:58 step 8000 epoch 4 learning rate 0.429 step-time 0.870 loss 46.685
12/27 05:58:58 starting evaluation
12/27 06:03:34 test bleu=12.18 loss=46.21 penalty=0.689 ratio=0.729
12/27 06:03:34 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 06:03:34 finished saving model
12/27 06:03:34 new best model
12/27 06:29:51   decaying learning rate to: 0.407
12/27 06:32:41 step 10000 epoch 5 learning rate 0.407 step-time 0.871 loss 42.536
12/27 06:32:41 starting evaluation
12/27 06:37:55 test bleu=15.64 loss=42.94 penalty=0.849 ratio=0.859
12/27 06:37:55 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 06:37:55 finished saving model
12/27 06:37:55 new best model
12/27 07:07:02 step 12000 epoch 5 learning rate 0.407 step-time 0.871 loss 38.944
12/27 07:07:02 starting evaluation
12/27 07:12:07 test bleu=17.25 loss=41.06 penalty=0.820 ratio=0.834
12/27 07:12:07 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 07:12:07 finished saving model
12/27 07:12:07 new best model
12/27 07:15:42   decaying learning rate to: 0.387
12/27 07:41:11 step 14000 epoch 6 learning rate 0.387 step-time 0.870 loss 35.789
12/27 07:41:11 starting evaluation
12/27 07:46:28 test bleu=19.73 loss=39.69 penalty=0.890 ratio=0.895
12/27 07:46:28 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 07:46:28 finished saving model
12/27 07:46:28 new best model
12/27 07:56:39   decaying learning rate to: 0.368
12/27 08:15:33 step 16000 epoch 7 learning rate 0.368 step-time 0.870 loss 33.420
12/27 08:15:33 starting evaluation
12/27 08:20:54 test bleu=22.65 loss=38.84 penalty=0.924 ratio=0.927
12/27 08:20:54 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 08:20:54 finished saving model
12/27 08:20:54 new best model
12/27 08:37:36   decaying learning rate to: 0.349
12/27 08:49:55 step 18000 epoch 8 learning rate 0.349 step-time 0.868 loss 31.176
12/27 08:49:55 starting evaluation
12/27 08:54:54 test bleu=23.93 loss=38.24 penalty=0.832 ratio=0.845
12/27 08:54:54 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 08:54:54 finished saving model
12/27 08:54:54 new best model
12/27 09:18:09   decaying learning rate to: 0.332
12/27 09:23:56 step 20000 epoch 9 learning rate 0.332 step-time 0.869 loss 29.127
12/27 09:23:56 starting evaluation
12/27 09:28:58 test bleu=24.49 loss=37.83 penalty=0.807 ratio=0.823
12/27 09:28:58 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 09:28:58 finished saving model
12/27 09:28:58 new best model
12/27 09:58:02 step 22000 epoch 9 learning rate 0.332 step-time 0.870 loss 27.264
12/27 09:58:02 starting evaluation
12/27 10:03:11 test bleu=24.89 loss=36.99 penalty=0.838 ratio=0.850
12/27 10:03:11 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 10:03:12 finished saving model
12/27 10:03:12 new best model
12/27 10:03:48   decaying learning rate to: 0.315
12/27 10:32:16 step 24000 epoch 10 learning rate 0.315 step-time 0.870 loss 24.635
12/27 10:32:16 starting evaluation
12/27 10:37:39 test bleu=26.50 loss=37.30 penalty=1.000 ratio=1.033
12/27 10:37:39 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 10:37:39 finished saving model
12/27 10:37:39 new best model
12/27 10:44:51   decaying learning rate to: 0.299
12/27 11:06:43 step 26000 epoch 11 learning rate 0.299 step-time 0.870 loss 22.728
12/27 11:06:43 starting evaluation
12/27 11:11:57 test bleu=28.07 loss=37.65 penalty=0.921 ratio=0.924
12/27 11:11:57 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 11:11:57 finished saving model
12/27 11:11:57 new best model
12/27 11:25:39   decaying learning rate to: 0.284
12/27 11:40:58 step 28000 epoch 12 learning rate 0.284 step-time 0.868 loss 21.159
12/27 11:40:58 starting evaluation
12/27 11:46:07 test bleu=29.31 loss=38.32 penalty=0.900 ratio=0.904
12/27 11:46:07 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 11:46:07 finished saving model
12/27 11:46:07 new best model
12/27 12:06:27   decaying learning rate to: 0.27
12/27 12:15:07 step 30000 epoch 13 learning rate 0.27 step-time 0.868 loss 19.525
12/27 12:15:07 starting evaluation
12/27 12:19:58 test bleu=29.34 loss=39.54 penalty=0.829 ratio=0.842
12/27 12:19:58 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 12:19:58 finished saving model
12/27 12:19:58 new best model
12/27 12:46:42   decaying learning rate to: 0.257
12/27 12:49:02 step 32000 epoch 14 learning rate 0.257 step-time 0.870 loss 18.201
12/27 12:49:02 starting evaluation
12/27 12:54:03 test bleu=30.51 loss=40.16 penalty=0.882 ratio=0.889
12/27 12:54:03 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 12:54:04 finished saving model
12/27 12:54:04 new best model
12/27 13:23:06 step 34000 epoch 14 learning rate 0.257 step-time 0.869 loss 16.195
12/27 13:23:06 starting evaluation
12/27 13:28:19 test bleu=31.50 loss=39.40 penalty=0.944 ratio=0.945
12/27 13:28:19 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 13:28:20 finished saving model
12/27 13:28:20 new best model
12/27 13:32:31   decaying learning rate to: 0.244
12/27 13:57:24 step 36000 epoch 15 learning rate 0.244 step-time 0.870 loss 14.573
12/27 13:57:24 starting evaluation
12/27 14:02:25 test bleu=30.96 loss=41.21 penalty=0.864 ratio=0.872
12/27 14:02:25 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 14:02:25 finished saving model
12/27 14:13:12   decaying learning rate to: 0.232
12/27 14:31:27 step 38000 epoch 16 learning rate 0.232 step-time 0.869 loss 13.295
12/27 14:31:27 starting evaluation
12/27 14:36:39 test bleu=31.94 loss=42.84 penalty=0.950 ratio=0.951
12/27 14:36:39 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 14:36:39 finished saving model
12/27 14:36:39 new best model
12/27 14:54:01   decaying learning rate to: 0.22
12/27 15:05:42 step 40000 epoch 17 learning rate 0.22 step-time 0.869 loss 12.288
12/27 15:05:42 starting evaluation
12/27 15:10:57 test bleu=32.34 loss=45.40 penalty=0.946 ratio=0.948
12/27 15:10:57 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 15:10:57 finished saving model
12/27 15:10:57 new best model
12/27 15:34:51   decaying learning rate to: 0.209
12/27 15:40:01 step 42000 epoch 18 learning rate 0.209 step-time 0.870 loss 11.143
12/27 15:40:01 starting evaluation
12/27 15:45:07 test bleu=32.31 loss=46.60 penalty=0.903 ratio=0.908
12/27 15:45:07 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 15:45:07 finished saving model
12/27 16:14:05 step 44000 epoch 18 learning rate 0.209 step-time 0.867 loss 10.092
12/27 16:14:05 starting evaluation
12/27 16:19:12 test bleu=33.14 loss=45.54 penalty=0.903 ratio=0.907
12/27 16:19:12 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 16:19:12 finished saving model
12/27 16:19:12 new best model
12/27 16:20:25   decaying learning rate to: 0.199
12/27 16:48:14 step 46000 epoch 19 learning rate 0.199 step-time 0.869 loss 8.620
12/27 16:48:14 starting evaluation
12/27 16:53:22 test bleu=33.19 loss=48.66 penalty=0.926 ratio=0.929
12/27 16:53:22 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 16:53:22 finished saving model
12/27 16:53:22 new best model
12/27 17:01:10   decaying learning rate to: 0.189
12/27 17:22:22 step 48000 epoch 20 learning rate 0.189 step-time 0.868 loss 7.837
12/27 17:22:22 starting evaluation
12/27 17:27:32 test bleu=33.43 loss=50.55 penalty=0.945 ratio=0.946
12/27 17:27:32 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 17:27:33 finished saving model
12/27 17:27:33 new best model
12/27 17:41:53   decaying learning rate to: 0.179
12/27 17:56:35 step 50000 epoch 21 learning rate 0.179 step-time 0.869 loss 7.119
12/27 17:56:35 starting evaluation
12/27 18:01:42 test bleu=33.38 loss=54.29 penalty=0.927 ratio=0.930
12/27 18:01:42 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 18:01:43 finished saving model
12/27 18:22:38   decaying learning rate to: 0.17
12/27 18:30:43 step 52000 epoch 22 learning rate 0.17 step-time 0.868 loss 6.437
12/27 18:30:43 starting evaluation
12/27 18:35:57 test bleu=34.18 loss=56.08 penalty=0.989 ratio=0.989
12/27 18:35:57 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 18:35:58 finished saving model
12/27 18:35:58 new best model
12/27 19:03:16   decaying learning rate to: 0.162
12/27 19:05:01 step 54000 epoch 23 learning rate 0.162 step-time 0.869 loss 5.833
12/27 19:05:01 starting evaluation
12/27 19:10:11 test bleu=33.80 loss=57.96 penalty=0.954 ratio=0.955
12/27 19:10:11 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 19:10:11 finished saving model
12/27 19:39:15 step 56000 epoch 23 learning rate 0.162 step-time 0.870 loss 4.963
12/27 19:39:15 starting evaluation
12/27 19:44:25 test bleu=35.03 loss=58.98 penalty=0.974 ratio=0.974
12/27 19:44:25 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 19:44:25 finished saving model
12/27 19:44:25 new best model
12/27 19:49:13   decaying learning rate to: 0.154
12/27 20:13:27 step 58000 epoch 24 learning rate 0.154 step-time 0.869 loss 4.362
12/27 20:13:27 starting evaluation
12/27 20:18:41 test bleu=34.66 loss=62.00 penalty=1.000 ratio=1.002
12/27 20:18:41 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 20:18:41 finished saving model
12/27 20:30:05   decaying learning rate to: 0.146
12/27 20:47:38 step 60000 epoch 25 learning rate 0.146 step-time 0.867 loss 3.975
12/27 20:47:38 starting evaluation
12/27 20:52:52 test bleu=35.00 loss=64.96 penalty=0.967 ratio=0.967
12/27 20:52:52 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 20:52:52 finished saving model
12/27 21:10:48   decaying learning rate to: 0.139
12/27 21:21:52 step 62000 epoch 26 learning rate 0.139 step-time 0.868 loss 3.565
12/27 21:21:52 starting evaluation
12/27 21:27:08 test bleu=34.95 loss=67.30 penalty=1.000 ratio=1.001
12/27 21:27:08 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 21:27:08 finished saving model
12/27 21:51:30   decaying learning rate to: 0.132
12/27 21:56:07 step 64000 epoch 27 learning rate 0.132 step-time 0.867 loss 3.236
12/27 21:56:07 starting evaluation
12/27 22:01:17 test bleu=35.25 loss=69.99 penalty=0.957 ratio=0.958
12/27 22:01:17 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 22:01:18 finished saving model
12/27 22:01:18 new best model
12/27 22:30:20 step 66000 epoch 27 learning rate 0.132 step-time 0.869 loss 2.853
12/27 22:30:20 starting evaluation
12/27 22:35:29 test bleu=35.23 loss=70.78 penalty=0.968 ratio=0.969
12/27 22:35:29 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 22:35:29 finished saving model
12/27 22:37:17   decaying learning rate to: 0.125
12/27 23:04:27 step 68000 epoch 28 learning rate 0.125 step-time 0.867 loss 2.418
12/27 23:04:27 starting evaluation
12/27 23:09:38 test bleu=35.35 loss=73.75 penalty=0.965 ratio=0.966
12/27 23:09:38 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 23:09:38 finished saving model
12/27 23:09:38 new best model
12/27 23:18:05   decaying learning rate to: 0.119
12/27 23:38:38 step 70000 epoch 29 learning rate 0.119 step-time 0.868 loss 2.204
12/27 23:38:38 starting evaluation
12/27 23:43:54 test bleu=35.47 loss=75.65 penalty=1.000 ratio=1.006
12/27 23:43:54 saving model to models/6_fold_hybrid_pnl/checkpoints
12/27 23:43:54 finished saving model
12/27 23:43:54 new best model
12/27 23:58:50   decaying learning rate to: 0.113
12/28 00:12:57 step 72000 epoch 30 learning rate 0.113 step-time 0.869 loss 2.008
12/28 00:12:57 starting evaluation
12/28 00:18:13 test bleu=35.47 loss=78.17 penalty=1.000 ratio=1.002
12/28 00:18:13 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 00:18:13 finished saving model
12/28 00:39:45   decaying learning rate to: 0.107
12/28 00:47:14 step 74000 epoch 31 learning rate 0.107 step-time 0.868 loss 1.821
12/28 00:47:14 starting evaluation
12/28 00:52:30 test bleu=34.33 loss=79.91 penalty=1.000 ratio=1.043
12/28 00:52:30 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 00:52:30 finished saving model
12/28 01:20:18   decaying learning rate to: 0.102
12/28 01:21:29 step 76000 epoch 32 learning rate 0.102 step-time 0.867 loss 1.655
12/28 01:21:29 starting evaluation
12/28 01:26:45 test bleu=35.49 loss=82.60 penalty=1.000 ratio=1.021
12/28 01:26:45 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 01:26:45 finished saving model
12/28 01:26:45 new best model
12/28 01:55:49 step 78000 epoch 32 learning rate 0.102 step-time 0.869 loss 1.411
12/28 01:55:49 starting evaluation
12/28 02:01:05 test bleu=36.12 loss=83.81 penalty=0.981 ratio=0.981
12/28 02:01:05 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 02:01:05 finished saving model
12/28 02:01:05 new best model
12/28 02:06:43   decaying learning rate to: 0.0969
12/28 02:31:16 step 80000 epoch 33 learning rate 0.0969 step-time 0.903 loss 1.275
12/28 02:31:16 starting evaluation
12/28 02:36:32 test bleu=36.35 loss=85.79 penalty=0.987 ratio=0.987
12/28 02:36:32 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 02:36:32 finished saving model
12/28 02:36:32 new best model
12/28 02:48:58   decaying learning rate to: 0.092
12/28 03:06:44 step 82000 epoch 34 learning rate 0.092 step-time 0.904 loss 1.175
12/28 03:06:44 starting evaluation
12/28 03:12:04 test bleu=35.39 loss=88.04 penalty=1.000 ratio=1.014
12/28 03:12:04 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 03:12:04 finished saving model
12/28 03:31:20   decaying learning rate to: 0.0874
12/28 03:42:24 step 84000 epoch 35 learning rate 0.0874 step-time 0.908 loss 1.082
12/28 03:42:24 starting evaluation
12/28 03:47:45 test bleu=36.36 loss=89.54 penalty=0.999 ratio=0.999
12/28 03:47:45 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 03:47:46 finished saving model
12/28 03:47:46 new best model
12/28 04:13:41   decaying learning rate to: 0.083
12/28 04:18:00 step 86000 epoch 36 learning rate 0.083 step-time 0.905 loss 1.000
12/28 04:18:00 starting evaluation
12/28 04:23:16 test bleu=36.34 loss=90.77 penalty=0.980 ratio=0.980
12/28 04:23:16 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 04:23:16 finished saving model
12/28 04:52:46 step 88000 epoch 36 learning rate 0.083 step-time 0.883 loss 0.914
12/28 04:52:46 starting evaluation
12/28 04:58:02 test bleu=35.79 loss=92.41 penalty=1.000 ratio=1.022
12/28 04:58:02 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 04:58:02 finished saving model
12/28 05:00:26   decaying learning rate to: 0.0789
12/28 05:27:03 step 90000 epoch 37 learning rate 0.0789 step-time 0.868 loss 0.807
12/28 05:27:03 starting evaluation
12/28 05:32:17 test bleu=36.19 loss=93.81 penalty=1.000 ratio=1.010
12/28 05:32:17 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 05:32:17 finished saving model
12/28 05:41:17   decaying learning rate to: 0.0749
12/28 06:01:17 step 92000 epoch 38 learning rate 0.0749 step-time 0.868 loss 0.750
12/28 06:01:17 starting evaluation
12/28 06:06:32 test bleu=36.33 loss=94.45 penalty=1.000 ratio=1.009
12/28 06:06:32 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 06:06:33 finished saving model
12/28 06:22:09   decaying learning rate to: 0.0712
12/28 06:35:56 step 94000 epoch 39 learning rate 0.0712 step-time 0.880 loss 0.710
12/28 06:35:56 starting evaluation
12/28 06:41:10 test bleu=36.28 loss=95.93 penalty=1.000 ratio=1.014
12/28 06:41:10 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 06:41:10 finished saving model
12/28 07:03:31   decaying learning rate to: 0.0676
12/28 07:10:35 step 96000 epoch 40 learning rate 0.0676 step-time 0.880 loss 0.660
12/28 07:10:35 starting evaluation
12/28 07:15:48 test bleu=36.87 loss=97.21 penalty=1.000 ratio=1.001
12/28 07:15:48 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 07:15:49 finished saving model
12/28 07:15:49 new best model
12/28 07:44:43   decaying learning rate to: 0.0643
12/28 07:45:19 step 98000 epoch 41 learning rate 0.0643 step-time 0.883 loss 0.631
12/28 07:45:19 starting evaluation
12/28 07:50:37 test bleu=35.95 loss=98.33 penalty=1.000 ratio=1.025
12/28 07:50:37 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 07:50:37 finished saving model
12/28 08:20:04 step 100000 epoch 41 learning rate 0.0643 step-time 0.882 loss 0.558
12/28 08:20:04 starting evaluation
12/28 08:25:21 test bleu=36.38 loss=98.85 penalty=1.000 ratio=1.005
12/28 08:25:21 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 08:25:21 finished saving model
12/28 08:31:25   decaying learning rate to: 0.061
12/28 08:54:51 step 102000 epoch 42 learning rate 0.061 step-time 0.883 loss 0.527
12/28 08:54:51 starting evaluation
12/28 09:00:02 test bleu=37.00 loss=100.06 penalty=0.985 ratio=0.985
12/28 09:00:02 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 09:00:03 finished saving model
12/28 09:00:03 new best model
12/28 09:12:48   decaying learning rate to: 0.058
12/28 09:29:30 step 104000 epoch 43 learning rate 0.058 step-time 0.881 loss 0.502
12/28 09:29:30 starting evaluation
12/28 09:34:45 test bleu=35.90 loss=101.38 penalty=1.000 ratio=1.019
12/28 09:34:45 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 09:34:45 finished saving model
12/28 09:54:12   decaying learning rate to: 0.0551
12/28 10:04:15 step 106000 epoch 44 learning rate 0.0551 step-time 0.883 loss 0.476
12/28 10:04:15 starting evaluation
12/28 10:09:31 test bleu=36.34 loss=101.83 penalty=1.000 ratio=1.022
12/28 10:09:31 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 10:09:31 finished saving model
12/28 10:35:20   decaying learning rate to: 0.0523
12/28 10:38:58 step 108000 epoch 45 learning rate 0.0523 step-time 0.882 loss 0.458
12/28 10:38:58 starting evaluation
12/28 10:44:15 test bleu=36.20 loss=101.80 penalty=1.000 ratio=1.027
12/28 10:44:15 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 10:44:15 finished saving model
12/28 11:13:44 step 110000 epoch 45 learning rate 0.0523 step-time 0.882 loss 0.426
12/28 11:13:44 starting evaluation
12/28 11:18:57 test bleu=37.13 loss=102.03 penalty=0.999 ratio=0.999
12/28 11:18:57 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 11:18:58 finished saving model
12/28 11:18:58 new best model
12/28 11:22:01   decaying learning rate to: 0.0497
12/28 11:48:29 step 112000 epoch 46 learning rate 0.0497 step-time 0.883 loss 0.384
12/28 11:48:29 starting evaluation
12/28 11:53:41 test bleu=37.06 loss=103.54 penalty=0.988 ratio=0.988
12/28 11:53:41 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 11:53:41 finished saving model
12/28 12:03:18   decaying learning rate to: 0.0472
12/28 12:22:31 step 114000 epoch 47 learning rate 0.0472 step-time 0.863 loss 0.372
12/28 12:22:31 starting evaluation
12/28 12:27:45 test bleu=36.99 loss=102.76 penalty=1.000 ratio=1.004
12/28 12:27:45 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 12:27:45 finished saving model
12/28 12:43:35   decaying learning rate to: 0.0449
12/28 12:56:16 step 116000 epoch 48 learning rate 0.0449 step-time 0.854 loss 0.357
12/28 12:56:16 starting evaluation
12/28 13:01:28 test bleu=37.26 loss=103.65 penalty=0.987 ratio=0.987
12/28 13:01:28 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 13:01:28 finished saving model
12/28 13:01:28 new best model
12/28 13:23:36   decaying learning rate to: 0.0426
12/28 13:30:00 step 118000 epoch 49 learning rate 0.0426 step-time 0.854 loss 0.340
12/28 13:30:00 starting evaluation
12/28 13:35:11 test bleu=37.39 loss=103.56 penalty=0.999 ratio=0.999
12/28 13:35:11 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 13:35:11 finished saving model
12/28 13:35:11 new best model
12/28 14:03:41 step 120000 epoch 50 learning rate 0.0426 step-time 0.853 loss 0.323
12/28 14:03:41 starting evaluation
12/28 14:08:54 test bleu=37.31 loss=103.56 penalty=0.999 ratio=0.999
12/28 14:08:54 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 14:08:54 finished saving model
12/28 14:08:55   decaying learning rate to: 0.0405
12/28 14:37:28 step 122000 epoch 50 learning rate 0.0405 step-time 0.855 loss 0.289
12/28 14:37:28 starting evaluation
12/28 14:42:38 test bleu=37.31 loss=103.29 penalty=1.000 ratio=1.003
12/28 14:42:38 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 14:42:38 finished saving model
12/28 14:49:07   decaying learning rate to: 0.0385
12/28 15:11:13 step 124000 epoch 51 learning rate 0.0385 step-time 0.856 loss 0.278
12/28 15:11:13 starting evaluation
12/28 15:16:28 test bleu=35.93 loss=103.43 penalty=1.000 ratio=1.040
12/28 15:16:28 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 15:16:29 finished saving model
12/28 15:29:22   decaying learning rate to: 0.0365
12/28 15:44:59 step 126000 epoch 52 learning rate 0.0365 step-time 0.853 loss 0.264
12/28 15:44:59 starting evaluation
12/28 15:50:11 test bleu=37.31 loss=103.87 penalty=1.000 ratio=1.000
12/28 15:50:11 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 15:50:11 finished saving model
12/28 16:09:35   decaying learning rate to: 0.0347
12/28 16:18:51 step 128000 epoch 53 learning rate 0.0347 step-time 0.858 loss 0.251
12/28 16:18:51 starting evaluation
12/28 16:24:06 test bleu=36.69 loss=103.43 penalty=1.000 ratio=1.023
12/28 16:24:06 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 16:24:06 finished saving model
12/28 16:50:07   decaying learning rate to: 0.033
12/28 16:53:07 step 130000 epoch 54 learning rate 0.033 step-time 0.868 loss 0.246
12/28 16:53:07 starting evaluation
12/28 16:58:22 test bleu=36.68 loss=103.30 penalty=1.000 ratio=1.021
12/28 16:58:22 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 16:58:22 finished saving model
12/28 17:27:27 step 132000 epoch 54 learning rate 0.033 step-time 0.870 loss 0.222
12/28 17:27:27 starting evaluation
12/28 17:32:38 test bleu=37.62 loss=103.59 penalty=0.989 ratio=0.990
12/28 17:32:38 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 17:32:38 finished saving model
12/28 17:32:38 new best model
12/28 17:36:13   decaying learning rate to: 0.0313
12/28 18:01:28 step 134000 epoch 55 learning rate 0.0313 step-time 0.863 loss 0.208
12/28 18:01:28 starting evaluation
12/28 18:06:40 test bleu=37.33 loss=103.82 penalty=1.000 ratio=1.006
12/28 18:06:40 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 18:06:41 finished saving model
12/28 18:16:28   decaying learning rate to: 0.0298
12/28 18:34:31 step 136000 epoch 56 learning rate 0.0298 step-time 0.833 loss 0.202
12/28 18:34:31 starting evaluation
12/28 18:39:42 test bleu=37.30 loss=104.04 penalty=1.000 ratio=1.005
12/28 18:39:42 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 18:39:42 finished saving model
12/28 18:55:49   decaying learning rate to: 0.0283
12/28 19:07:37 step 138000 epoch 57 learning rate 0.0283 step-time 0.836 loss 0.195
12/28 19:07:37 starting evaluation
12/28 19:12:48 test bleu=37.50 loss=103.65 penalty=0.996 ratio=0.996
12/28 19:12:48 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 19:12:48 finished saving model
12/28 19:34:55   decaying learning rate to: 0.0269
12/28 19:40:40 step 140000 epoch 58 learning rate 0.0269 step-time 0.834 loss 0.187
12/28 19:40:40 starting evaluation
12/28 19:45:53 test bleu=36.61 loss=103.37 penalty=1.000 ratio=1.028
12/28 19:45:53 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 19:45:53 finished saving model
12/28 20:13:48 step 142000 epoch 58 learning rate 0.0269 step-time 0.836 loss 0.180
12/28 20:13:48 starting evaluation
12/28 20:19:00 test bleu=37.06 loss=104.30 penalty=1.000 ratio=1.016
12/28 20:19:00 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 20:19:00 finished saving model
12/28 20:19:36   decaying learning rate to: 0.0255
12/28 20:46:55 step 144000 epoch 59 learning rate 0.0255 step-time 0.836 loss 0.163
12/28 20:46:55 starting evaluation
12/28 20:52:07 test bleu=36.92 loss=104.18 penalty=1.000 ratio=1.015
12/28 20:52:07 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 20:52:08 finished saving model
12/28 20:59:00   decaying learning rate to: 0.0242
12/28 21:19:58 step 146000 epoch 60 learning rate 0.0242 step-time 0.833 loss 0.156
12/28 21:19:58 starting evaluation
12/28 21:25:06 test bleu=37.38 loss=104.23 penalty=1.000 ratio=1.004
12/28 21:25:06 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 21:25:06 finished saving model
12/28 21:38:22   decaying learning rate to: 0.023
12/28 21:53:02 step 148000 epoch 61 learning rate 0.023 step-time 0.836 loss 0.154
12/28 21:53:02 starting evaluation
12/28 21:58:13 test bleu=37.27 loss=104.26 penalty=1.000 ratio=1.009
12/28 21:58:13 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 21:58:13 finished saving model
12/28 22:17:32   decaying learning rate to: 0.0219
12/28 22:26:04 step 150000 epoch 62 learning rate 0.0219 step-time 0.833 loss 0.156
12/28 22:26:04 starting evaluation
12/28 22:31:16 test bleu=37.51 loss=104.20 penalty=1.000 ratio=1.008
12/28 22:31:16 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 22:31:16 finished saving model
12/28 22:56:53   decaying learning rate to: 0.0208
12/28 22:59:10 step 152000 epoch 63 learning rate 0.0208 step-time 0.835 loss 0.149
12/28 22:59:10 starting evaluation
12/28 23:04:23 test bleu=37.04 loss=104.21 penalty=1.000 ratio=1.016
12/28 23:04:23 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 23:04:23 finished saving model
12/28 23:32:15 step 154000 epoch 63 learning rate 0.0208 step-time 0.834 loss 0.139
12/28 23:32:15 starting evaluation
12/28 23:37:24 test bleu=37.80 loss=104.11 penalty=1.000 ratio=1.000
12/28 23:37:24 saving model to models/6_fold_hybrid_pnl/checkpoints
12/28 23:37:24 finished saving model
12/28 23:37:24 new best model
12/28 23:41:28   decaying learning rate to: 0.0197
12/29 00:05:17 step 156000 epoch 64 learning rate 0.0197 step-time 0.834 loss 0.131
12/29 00:05:17 starting evaluation
12/29 00:10:28 test bleu=37.73 loss=104.74 penalty=0.997 ratio=0.997
12/29 00:10:28 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 00:10:29 finished saving model
12/29 00:20:51   decaying learning rate to: 0.0188
12/29 00:38:23 step 158000 epoch 65 learning rate 0.0188 step-time 0.835 loss 0.127
12/29 00:38:23 starting evaluation
12/29 00:43:33 test bleu=37.40 loss=104.94 penalty=1.000 ratio=1.008
12/29 00:43:33 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 00:43:33 finished saving model
12/29 01:00:04   decaying learning rate to: 0.0178
12/29 01:11:28 step 160000 epoch 66 learning rate 0.0178 step-time 0.835 loss 0.127
12/29 01:11:28 starting evaluation
12/29 01:16:39 test bleu=37.81 loss=105.25 penalty=1.000 ratio=1.000
12/29 01:16:39 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 01:16:39 finished saving model
12/29 01:16:39 new best model
12/29 01:39:22   decaying learning rate to: 0.0169
12/29 01:44:31 step 162000 epoch 67 learning rate 0.0169 step-time 0.834 loss 0.125
12/29 01:44:31 starting evaluation
12/29 01:49:43 test bleu=37.24 loss=105.12 penalty=1.000 ratio=1.015
12/29 01:49:43 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 01:49:43 finished saving model
12/29 02:18:40 step 164000 epoch 67 learning rate 0.0169 step-time 0.866 loss 0.120
12/29 02:18:40 starting evaluation
12/29 02:23:54 test bleu=37.60 loss=104.63 penalty=1.000 ratio=1.005
12/29 02:23:54 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 02:23:54 finished saving model
12/29 02:25:11   decaying learning rate to: 0.0161
12/29 02:54:08 step 166000 epoch 68 learning rate 0.0161 step-time 0.904 loss 0.111
12/29 02:54:08 starting evaluation
12/29 02:59:22 test bleu=37.13 loss=105.19 penalty=1.000 ratio=1.017
12/29 02:59:22 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 02:59:22 finished saving model
12/29 03:07:15   decaying learning rate to: 0.0153
12/29 03:29:04 step 168000 epoch 69 learning rate 0.0153 step-time 0.889 loss 0.111
12/29 03:29:04 starting evaluation
12/29 03:34:18 test bleu=37.75 loss=105.35 penalty=0.998 ratio=0.998
12/29 03:34:18 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 03:34:18 finished saving model
12/29 03:48:08   decaying learning rate to: 0.0145
12/29 04:02:13 step 170000 epoch 70 learning rate 0.0145 step-time 0.835 loss 0.109
12/29 04:02:13 starting evaluation
12/29 04:07:25 test bleu=37.40 loss=105.79 penalty=1.000 ratio=1.012
12/29 04:07:25 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 04:07:25 finished saving model
12/29 04:27:14   decaying learning rate to: 0.0138
12/29 04:35:35 step 172000 epoch 71 learning rate 0.0138 step-time 0.843 loss 0.107
12/29 04:35:35 starting evaluation
12/29 04:40:48 test bleu=37.68 loss=106.14 penalty=0.997 ratio=0.997
12/29 04:40:48 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 04:40:48 finished saving model
12/29 05:08:09   decaying learning rate to: 0.0131
12/29 05:09:56 step 174000 epoch 72 learning rate 0.0131 step-time 0.872 loss 0.106
12/29 05:09:56 starting evaluation
12/29 05:15:11 test bleu=37.57 loss=105.89 penalty=1.000 ratio=1.006
12/29 05:15:11 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 05:15:11 finished saving model
12/29 05:44:19 step 176000 epoch 72 learning rate 0.0131 step-time 0.872 loss 0.100
12/29 05:44:19 starting evaluation
12/29 05:49:34 test bleu=37.38 loss=106.26 penalty=1.000 ratio=1.008
12/29 05:49:34 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 05:49:34 finished saving model
12/29 05:54:23   decaying learning rate to: 0.0124
12/29 06:18:39 step 178000 epoch 73 learning rate 0.0124 step-time 0.871 loss 0.096
12/29 06:18:39 starting evaluation
12/29 06:23:53 test bleu=37.30 loss=106.09 penalty=1.000 ratio=1.009
12/29 06:23:53 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 06:23:53 finished saving model
12/29 06:35:16   decaying learning rate to: 0.0118
12/29 06:53:02 step 180000 epoch 74 learning rate 0.0118 step-time 0.873 loss 0.096
12/29 06:53:02 starting evaluation
12/29 06:57:18 test bleu=37.57 loss=106.43 penalty=1.000 ratio=1.004
12/29 06:57:18 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 06:57:18 finished saving model
12/29 07:11:59   decaying learning rate to: 0.0112
12/29 07:21:09 step 182000 epoch 75 learning rate 0.0112 step-time 0.714 loss 0.093
12/29 07:21:09 starting evaluation
12/29 07:24:43 test bleu=37.13 loss=106.48 penalty=1.000 ratio=1.016
12/29 07:24:43 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 07:24:44 finished saving model
12/29 07:44:42   decaying learning rate to: 0.0107
12/29 07:48:34 step 184000 epoch 76 learning rate 0.0107 step-time 0.714 loss 0.094
12/29 07:48:34 starting evaluation
12/29 07:52:06 test bleu=37.75 loss=106.92 penalty=0.996 ratio=0.996
12/29 07:52:06 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 07:52:06 finished saving model
12/29 08:15:38 step 186000 epoch 76 learning rate 0.0107 step-time 0.704 loss 0.092
12/29 08:15:38 starting evaluation
12/29 08:19:07 test bleu=37.21 loss=106.54 penalty=1.000 ratio=1.013
12/29 08:19:07 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 08:19:07 finished saving model
12/29 08:20:33   decaying learning rate to: 0.0101
12/29 08:42:09 step 188000 epoch 77 learning rate 0.0101 step-time 0.689 loss 0.087
12/29 08:42:09 starting evaluation
12/29 08:45:35 test bleu=37.21 loss=106.70 penalty=1.000 ratio=1.013
12/29 08:45:35 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 08:45:35 finished saving model
12/29 08:52:28   decaying learning rate to: 0.00963
12/29 09:09:55 step 190000 epoch 78 learning rate 0.00963 step-time 0.728 loss 0.084
12/29 09:09:55 starting evaluation
12/29 09:13:28 test bleu=37.54 loss=106.86 penalty=1.000 ratio=1.007
12/29 09:13:28 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 09:13:28 finished saving model
12/29 09:25:48   decaying learning rate to: 0.00915
12/29 09:37:38 step 192000 epoch 79 learning rate 0.00915 step-time 0.723 loss 0.086
12/29 09:37:38 starting evaluation
12/29 09:41:06 test bleu=37.58 loss=107.25 penalty=1.000 ratio=1.004
12/29 09:41:07 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 09:41:07 finished saving model
12/29 09:58:55   decaying learning rate to: 0.00869
12/29 10:05:07 step 194000 epoch 80 learning rate 0.00869 step-time 0.718 loss 0.084
12/29 10:05:07 starting evaluation
12/29 10:09:09 test bleu=37.29 loss=107.33 penalty=1.000 ratio=1.012
12/29 10:09:09 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 10:09:09 finished saving model
12/29 10:35:14   decaying learning rate to: 0.00826
12/29 10:36:22 step 196000 epoch 81 learning rate 0.00826 step-time 0.815 loss 0.085
12/29 10:36:22 starting evaluation
12/29 10:41:20 test bleu=37.64 loss=107.26 penalty=1.000 ratio=1.004
12/29 10:41:20 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 10:41:20 finished saving model
12/29 11:08:28 step 198000 epoch 81 learning rate 0.00826 step-time 0.812 loss 0.079
12/29 11:08:28 starting evaluation
12/29 11:13:27 test bleu=37.38 loss=107.37 penalty=1.000 ratio=1.011
12/29 11:13:27 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 11:13:27 finished saving model
12/29 11:18:29   decaying learning rate to: 0.00784
12/29 11:40:37 step 200000 epoch 82 learning rate 0.00784 step-time 0.813 loss 0.077
12/29 11:40:37 starting evaluation
12/29 11:45:37 test bleu=37.58 loss=107.74 penalty=1.000 ratio=1.004
12/29 11:45:37 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 11:45:37 finished saving model
12/29 11:56:43   decaying learning rate to: 0.00745
12/29 12:12:46 step 202000 epoch 83 learning rate 0.00745 step-time 0.813 loss 0.080
12/29 12:12:46 starting evaluation
12/29 12:17:45 test bleu=37.26 loss=107.82 penalty=1.000 ratio=1.012
12/29 12:17:45 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 12:17:45 finished saving model
12/29 12:34:57   decaying learning rate to: 0.00708
12/29 12:44:46 step 204000 epoch 84 learning rate 0.00708 step-time 0.809 loss 0.077
12/29 12:44:46 starting evaluation
12/29 12:49:45 test bleu=37.55 loss=108.02 penalty=1.000 ratio=1.004
12/29 12:49:45 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 12:49:45 finished saving model
12/29 13:13:07   decaying learning rate to: 0.00673
12/29 13:16:57 step 206000 epoch 85 learning rate 0.00673 step-time 0.814 loss 0.077
12/29 13:16:57 starting evaluation
12/29 13:21:53 test bleu=37.51 loss=107.89 penalty=1.000 ratio=1.009
12/29 13:21:53 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 13:21:53 finished saving model
12/29 13:49:02 step 208000 epoch 85 learning rate 0.00673 step-time 0.812 loss 0.076
12/29 13:49:02 starting evaluation
12/29 13:53:48 test bleu=37.74 loss=108.12 penalty=1.000 ratio=1.000
12/29 13:53:48 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 13:53:48 finished saving model
12/29 13:56:03   decaying learning rate to: 0.00639
12/29 14:20:50 step 210000 epoch 86 learning rate 0.00639 step-time 0.809 loss 0.072
12/29 14:20:50 starting evaluation
12/29 14:25:56 test bleu=37.05 loss=108.19 penalty=1.000 ratio=1.019
12/29 14:25:56 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 14:25:56 finished saving model
12/29 14:34:14   decaying learning rate to: 0.00607
12/29 14:53:02 step 212000 epoch 87 learning rate 0.00607 step-time 0.811 loss 0.072
12/29 14:53:02 starting evaluation
12/29 14:58:02 test bleu=37.55 loss=108.27 penalty=1.000 ratio=1.006
12/29 14:58:02 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 14:58:02 finished saving model
12/29 15:12:29   decaying learning rate to: 0.00577
12/29 15:25:11 step 214000 epoch 88 learning rate 0.00577 step-time 0.813 loss 0.072
12/29 15:25:11 starting evaluation
12/29 15:30:10 test bleu=37.59 loss=108.65 penalty=1.000 ratio=1.004
12/29 15:30:10 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 15:30:11 finished saving model
12/29 15:50:47   decaying learning rate to: 0.00548
12/29 15:57:19 step 216000 epoch 89 learning rate 0.00548 step-time 0.812 loss 0.073
12/29 15:57:19 starting evaluation
12/29 16:02:18 test bleu=37.67 loss=108.56 penalty=1.000 ratio=1.001
12/29 16:02:18 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 16:02:18 finished saving model
12/29 16:28:56   decaying learning rate to: 0.0052
12/29 16:29:28 step 218000 epoch 90 learning rate 0.0052 step-time 0.813 loss 0.072
12/29 16:29:28 starting evaluation
12/29 16:34:27 test bleu=37.68 loss=108.49 penalty=1.000 ratio=1.002
12/29 16:34:27 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 16:34:27 finished saving model
12/29 17:01:41 step 220000 epoch 90 learning rate 0.0052 step-time 0.815 loss 0.069
12/29 17:01:41 starting evaluation
12/29 17:06:40 test bleu=37.47 loss=108.72 penalty=1.000 ratio=1.008
12/29 17:06:40 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 17:06:40 finished saving model
12/29 17:12:19   decaying learning rate to: 0.00494
12/29 17:33:46 step 222000 epoch 91 learning rate 0.00494 step-time 0.811 loss 0.067
12/29 17:33:46 starting evaluation
12/29 17:38:32 test bleu=37.33 loss=108.72 penalty=1.000 ratio=1.010
12/29 17:38:32 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 17:38:32 finished saving model
12/29 17:50:22   decaying learning rate to: 0.0047
12/29 18:05:47 step 224000 epoch 92 learning rate 0.0047 step-time 0.816 loss 0.069
12/29 18:05:47 starting evaluation
12/29 18:10:37 test bleu=37.63 loss=108.93 penalty=1.000 ratio=1.003
12/29 18:10:37 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 18:10:37 finished saving model
12/29 18:28:25   decaying learning rate to: 0.00446
12/29 18:37:46 step 226000 epoch 93 learning rate 0.00446 step-time 0.813 loss 0.067
12/29 18:37:46 starting evaluation
12/29 18:42:46 test bleu=37.69 loss=109.01 penalty=1.000 ratio=1.003
12/29 18:42:46 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 18:42:46 finished saving model
12/29 19:06:40   decaying learning rate to: 0.00424
12/29 19:09:55 step 228000 epoch 94 learning rate 0.00424 step-time 0.813 loss 0.069
12/29 19:09:55 starting evaluation
12/29 19:14:56 test bleu=37.11 loss=109.05 penalty=1.000 ratio=1.015
12/29 19:14:56 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 19:14:56 finished saving model
12/29 19:42:05 step 230000 epoch 94 learning rate 0.00424 step-time 0.812 loss 0.066
12/29 19:42:05 starting evaluation
12/29 19:47:04 test bleu=37.31 loss=109.12 penalty=1.000 ratio=1.010
12/29 19:47:04 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 19:47:04 finished saving model
12/29 19:49:52   decaying learning rate to: 0.00403
12/29 20:14:13 step 232000 epoch 95 learning rate 0.00403 step-time 0.812 loss 0.066
12/29 20:14:13 starting evaluation
12/29 20:19:13 test bleu=37.39 loss=109.11 penalty=1.000 ratio=1.009
12/29 20:19:13 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 20:19:13 finished saving model
12/29 20:28:02   decaying learning rate to: 0.00383
12/29 20:46:18 step 234000 epoch 96 learning rate 0.00383 step-time 0.811 loss 0.065
12/29 20:46:18 starting evaluation
12/29 20:51:17 test bleu=37.62 loss=109.32 penalty=1.000 ratio=1.004
12/29 20:51:17 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 20:51:17 finished saving model
12/29 21:06:24   decaying learning rate to: 0.00363
12/29 21:18:24 step 236000 epoch 97 learning rate 0.00363 step-time 0.812 loss 0.065
12/29 21:18:24 starting evaluation
12/29 21:23:22 test bleu=37.40 loss=109.42 penalty=1.000 ratio=1.008
12/29 21:23:22 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 21:23:22 finished saving model
12/29 21:44:38   decaying learning rate to: 0.00345
12/29 21:50:37 step 238000 epoch 98 learning rate 0.00345 step-time 0.815 loss 0.065
12/29 21:50:37 starting evaluation
12/29 21:55:24 test bleu=37.28 loss=109.37 penalty=1.000 ratio=1.011
12/29 21:55:24 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 21:55:24 finished saving model
12/29 22:22:27 step 240000 epoch 99 learning rate 0.00345 step-time 0.809 loss 0.065
12/29 22:22:27 starting evaluation
12/29 22:27:24 test bleu=37.58 loss=109.55 penalty=1.000 ratio=1.004
12/29 22:27:24 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 22:27:24 finished saving model
12/29 22:27:26   decaying learning rate to: 0.00328
12/29 22:54:33 step 242000 epoch 99 learning rate 0.00328 step-time 0.813 loss 0.063
12/29 22:54:33 starting evaluation
12/29 22:59:32 test bleu=37.34 loss=109.54 penalty=1.000 ratio=1.011
12/29 22:59:32 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 22:59:32 finished saving model
12/29 23:05:43   decaying learning rate to: 0.00312
12/29 23:26:41 step 244000 epoch 100 learning rate 0.00312 step-time 0.812 loss 0.062
12/29 23:26:41 starting evaluation
12/29 23:31:40 test bleu=37.23 loss=109.63 penalty=1.000 ratio=1.012
12/29 23:31:40 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 23:31:40 finished saving model
12/29 23:43:36 finished training
12/29 23:43:36 exiting...
12/29 23:43:36 saving model to models/6_fold_hybrid_pnl/checkpoints
12/29 23:43:36 finished saving model
