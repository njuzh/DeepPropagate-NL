nohup: ignoring input
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:107: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:30: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

12/26 11:05:01 label: default
12/26 11:05:01 description:
  default configuration
  next line of description
  last line
12/26 11:05:01 /root/icpc/icpc/translate/__main__.py config/10-folds/3_fold/hybrid_pnl/config.yaml --train -v
12/26 11:05:01 commit hash 74e0554cb3eb5df835cef993ad570ff8de651f71
12/26 11:05:01 tensorflow version: 1.14.0
12/26 11:05:01 program arguments
12/26 11:05:01   aggregation_method   'sum'
12/26 11:05:01   align_encoder_id     0
12/26 11:05:01   allow_growth         True
12/26 11:05:01   attention_type       'global'
12/26 11:05:01   attn_filter_length   0
12/26 11:05:01   attn_filters         0
12/26 11:05:01   attn_prev_word       False
12/26 11:05:01   attn_size            128
12/26 11:05:01   attn_temperature     1.0
12/26 11:05:01   attn_window_size     0
12/26 11:05:01   average              False
12/26 11:05:01   baseline_activation  None
12/26 11:05:01   baseline_learning_rate 0.001
12/26 11:05:01   baseline_optimizer   'adam'
12/26 11:05:01   baseline_steps       0
12/26 11:05:01   batch_mode           'standard'
12/26 11:05:01   batch_size           64
12/26 11:05:01   beam_size            5
12/26 11:05:01   bidir                True
12/26 11:05:01   bidir_projection     False
12/26 11:05:01   binary               False
12/26 11:05:01   cell_size            256
12/26 11:05:01   cell_type            'GRU'
12/26 11:05:01   character_level      False
12/26 11:05:01   checkpoints          []
12/26 11:05:01   conditional_rnn      False
12/26 11:05:01   config               'config/10-folds/3_fold/hybrid_pnl/config.yaml'
12/26 11:05:01   convolutions         None
12/26 11:05:01   data_dir             'data/gooddata/3_fold'
12/26 11:05:01   debug                False
12/26 11:05:01   decay_after_n_epoch  1
12/26 11:05:01   decay_every_n_epoch  1
12/26 11:05:01   decay_if_no_progress None
12/26 11:05:01   decoders             [{'max_len': 40, 'name': 'nl'}]
12/26 11:05:01   description          'default configuration\nnext line of description\nlast line\n'
12/26 11:05:01   dev_prefix           'test'
12/26 11:05:01   early_stopping       True
12/26 11:05:01   embedding_dropout    0.0
12/26 11:05:01   embedding_initializer None
12/26 11:05:01   embedding_size       256
12/26 11:05:01   embedding_weight_scale None
12/26 11:05:01   embeddings_on_cpu    True
12/26 11:05:01   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 80, 'name': 'pnl'}]
12/26 11:05:01   ensemble             False
12/26 11:05:01   eval_burn_in         0
12/26 11:05:01   feed_previous        0.0
12/26 11:05:01   final_state          'last'
12/26 11:05:01   freeze_variables     []
12/26 11:05:01   generate_first       True
12/26 11:05:01   gpu_id               0
12/26 11:05:01   highway_layers       0
12/26 11:05:01   initial_state_dropout 0.0
12/26 11:05:01   initializer          None
12/26 11:05:01   input_layer_dropout  0.0
12/26 11:05:01   input_layers         None
12/26 11:05:01   keep_best            5
12/26 11:05:01   keep_every_n_hours   0
12/26 11:05:01   label                'default'
12/26 11:05:01   layer_norm           False
12/26 11:05:01   layers               1
12/26 11:05:01   learning_rate        0.5
12/26 11:05:01   learning_rate_decay_factor 0.95
12/26 11:05:01   len_normalization    1.0
12/26 11:05:01   log_file             'log.txt'
12/26 11:05:01   loss_function        'xent'
12/26 11:05:01   max_dev_size         0
12/26 11:05:01   max_epochs           100
12/26 11:05:01   max_gradient_norm    5.0
12/26 11:05:01   max_len              50
12/26 11:05:01   max_steps            600000
12/26 11:05:01   max_test_size        0
12/26 11:05:01   max_to_keep          1
12/26 11:05:01   max_train_size       0
12/26 11:05:01   maxout_stride        None
12/26 11:05:01   mem_fraction         1.0
12/26 11:05:01   min_learning_rate    1e-06
12/26 11:05:01   model_dir            'models/3_fold_hybrid_pnl'
12/26 11:05:01   moving_average       None
12/26 11:05:01   no_gpu               False
12/26 11:05:01   optimizer            'sgd'
12/26 11:05:01   orthogonal_init      False
12/26 11:05:01   output               None
12/26 11:05:01   output_dropout       0.0
12/26 11:05:01   parallel_iterations  16
12/26 11:05:01   pervasive_dropout    False
12/26 11:05:01   pooling_avg          True
12/26 11:05:01   post_process_script  None
12/26 11:05:01   pred_deep_layer      False
12/26 11:05:01   pred_edits           False
12/26 11:05:01   pred_embed_proj      True
12/26 11:05:01   pred_maxout_layer    True
12/26 11:05:01   purge                False
12/26 11:05:01   raw_output           False
12/26 11:05:01   read_ahead           1
12/26 11:05:01   reconstruction_attn_weight 0.05
12/26 11:05:01   reconstruction_decoders False
12/26 11:05:01   reconstruction_weight 1.0
12/26 11:05:01   reinforce_after_n_epoch None
12/26 11:05:01   remove_unk           False
12/26 11:05:01   reverse              False
12/26 11:05:01   reverse_input        True
12/26 11:05:01   reward_function      'sentence_bleu'
12/26 11:05:01   rnn_feed_attn        True
12/26 11:05:01   rnn_input_dropout    0.0
12/26 11:05:01   rnn_output_dropout   0.0
12/26 11:05:01   rnn_state_dropout    0.0
12/26 11:05:01   save                 False
12/26 11:05:01   score_function       'corpus_bleu'
12/26 11:05:01   score_functions      ['bleu', 'loss']
12/26 11:05:01   script_dir           'scripts'
12/26 11:05:01   sgd_after_n_epoch    None
12/26 11:05:01   sgd_learning_rate    1.0
12/26 11:05:01   shuffle              True
12/26 11:05:01   softmax_temperature  1.0
12/26 11:05:01   steps_per_checkpoint 2000
12/26 11:05:01   steps_per_eval       2000
12/26 11:05:01   swap_memory          True
12/26 11:05:01   tie_embeddings       False
12/26 11:05:01   time_pooling         None
12/26 11:05:01   train                True
12/26 11:05:01   train_initial_states True
12/26 11:05:01   train_prefix         'train'
12/26 11:05:01   truncate_lines       True
12/26 11:05:01   update_first         False
12/26 11:05:01   use_baseline         False
12/26 11:05:01   use_dropout          False
12/26 11:05:01   use_lstm_full_state  False
12/26 11:05:01   use_previous_word    True
12/26 11:05:01   verbose              True
12/26 11:05:01   vocab_prefix         'vocab'
12/26 11:05:01   weight_scale         None
12/26 11:05:01   word_dropout         0.0
12/26 11:05:01 python random seed: 2293275965323605977
12/26 11:05:01 tf random seed:     1152672021315564647
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:203: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

12/26 11:05:01 creating model
12/26 11:05:01 using device: /gpu:0
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:230: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

12/26 11:05:01 copying vocab to models/3_fold_hybrid_pnl/data/vocab.code
12/26 11:05:01 copying vocab to models/3_fold_hybrid_pnl/data/vocab.pnl
12/26 11:05:01 copying vocab to models/3_fold_hybrid_pnl/data/vocab.nl
12/26 11:05:01 reading vocabularies
12/26 11:05:01 creating model
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:33: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f4035416c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f4035416c18>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:226: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f4035416d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f4035416d68>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f40b3e9cf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f40b3e9cf60>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f40b3e9cef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f40b3e9cef0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3cd90f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3cd90f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:838: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3b3bbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3b3bbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3b657f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3b657f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:432: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:435: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3a9ac88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3a9ac88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3a73828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3a73828>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b391b358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b391b358>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b38d6a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b38d6a58>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3636f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3636f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b35b4fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b35b4fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3612c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b3612c88>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b358ca20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b358ca20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b358ca20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b358ca20>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:919: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f40b3495080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f40b3495080>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:10: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:131: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:223: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f405b0bcc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f405b0bcc88>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405b057f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405b057f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405b00aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405b00aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405afbcf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405afbcf98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b35c3470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f40b35c3470>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405b11c7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405b11c7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405af18e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405af18e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405af18e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f405af18e10>>: AssertionError: Bad argument number for Name: 3, expecting 4
12/26 11:05:08 model parameters (45)
12/26 11:05:08   baseline_step:0 ()
12/26 11:05:08   decoder_nl/attention_code/U_a/kernel:0 (512, 128)
12/26 11:05:08   decoder_nl/attention_code/W_a/bias:0 (128,)
12/26 11:05:08   decoder_nl/attention_code/W_a/kernel:0 (256, 128)
12/26 11:05:08   decoder_nl/attention_code/v_a:0 (128,)
12/26 11:05:08   decoder_nl/attention_pnl/U_a/kernel:0 (512, 128)
12/26 11:05:08   decoder_nl/attention_pnl/W_a/bias:0 (128,)
12/26 11:05:08   decoder_nl/attention_pnl/W_a/kernel:0 (256, 128)
12/26 11:05:08   decoder_nl/attention_pnl/v_a:0 (128,)
12/26 11:05:08   decoder_nl/code_pnl/initial_state_projection/bias:0 (256,)
12/26 11:05:08   decoder_nl/code_pnl/initial_state_projection/kernel:0 (512, 256)
12/26 11:05:08   decoder_nl/gru_cell/candidate/bias:0 (256,)
12/26 11:05:08   decoder_nl/gru_cell/candidate/kernel:0 (1024, 256)
12/26 11:05:08   decoder_nl/gru_cell/gates/bias:0 (512,)
12/26 11:05:08   decoder_nl/gru_cell/gates/kernel:0 (1024, 512)
12/26 11:05:08   decoder_nl/maxout/bias:0 (256,)
12/26 11:05:08   decoder_nl/maxout/kernel:0 (1024, 256)
12/26 11:05:08   decoder_nl/softmax0/kernel:0 (128, 256)
12/26 11:05:08   decoder_nl/softmax1/bias:0 (37948,)
12/26 11:05:08   decoder_nl/softmax1/kernel:0 (256, 37948)
12/26 11:05:08   embedding_code:0 (50000, 256)
12/26 11:05:08   embedding_nl:0 (37948, 256)
12/26 11:05:08   embedding_pnl:0 (37630, 256)
12/26 11:05:08   encoder_code/initial_state_bw:0 (256,)
12/26 11:05:08   encoder_code/initial_state_fw:0 (256,)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
12/26 11:05:08   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
12/26 11:05:08   encoder_pnl/initial_state_bw:0 (256,)
12/26 11:05:08   encoder_pnl/initial_state_fw:0 (256,)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
12/26 11:05:08   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
12/26 11:05:08   global_step:0 ()
12/26 11:05:08   learning_rate:0 ()
12/26 11:05:08 number of parameters: 44.89M
WARNING:tensorflow:From /root/icpc/icpc/translate/translation_model.py:666: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

12/26 11:05:09 global step: 0
12/26 11:05:09 baseline step: 0
12/26 11:05:09 reading training data
12/26 11:05:09 total line count: 156721
12/26 11:05:14   lines read: 100000
12/26 11:05:17 files: data/gooddata/3_fold/train.code data/gooddata/3_fold/train.pnl data/gooddata/3_fold/train.nl
12/26 11:05:17 lines reads: 156721
12/26 11:05:17 reading development data
12/26 11:05:18 files: data/gooddata/3_fold/test.code data/gooddata/3_fold/test.pnl data/gooddata/3_fold/test.nl
12/26 11:05:18 lines reads: 17413
12/26 11:05:18 starting training
12/26 11:30:28 step 2000 epoch 1 learning rate 0.5 step-time 0.753 loss 80.529
12/26 11:30:28 starting evaluation
12/26 11:35:39 test bleu=1.54 loss=65.80 penalty=0.797 ratio=0.815
12/26 11:35:39 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 11:35:39 finished saving model
12/26 11:35:39 new best model
12/26 11:42:07   decaying learning rate to: 0.475
12/26 12:04:11 step 4000 epoch 2 learning rate 0.475 step-time 0.854 loss 59.346
12/26 12:04:11 starting evaluation
12/26 12:09:23 test bleu=4.03 loss=55.60 penalty=1.000 ratio=1.106
12/26 12:09:23 saving model to models/3_fold_hybrid_pnl/checkpoints
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
12/26 12:09:24 finished saving model
12/26 12:09:24 new best model
12/26 12:22:18   decaying learning rate to: 0.451
12/26 12:37:55 step 6000 epoch 3 learning rate 0.451 step-time 0.854 loss 51.943
12/26 12:37:55 starting evaluation
12/26 12:42:46 test bleu=7.80 loss=50.49 penalty=0.689 ratio=0.729
12/26 12:42:46 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 12:42:46 finished saving model
12/26 12:42:46 new best model
12/26 13:01:54   decaying learning rate to: 0.429
12/26 13:11:16 step 8000 epoch 4 learning rate 0.429 step-time 0.853 loss 46.527
12/26 13:11:16 starting evaluation
12/26 13:16:25 test bleu=12.87 loss=46.01 penalty=0.929 ratio=0.931
12/26 13:16:25 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 13:16:26 finished saving model
12/26 13:16:26 new best model
12/26 13:42:02   decaying learning rate to: 0.407
12/26 13:44:59 step 10000 epoch 5 learning rate 0.407 step-time 0.854 loss 42.427
12/26 13:44:59 starting evaluation
12/26 13:50:10 test bleu=15.79 loss=43.40 penalty=0.836 ratio=0.848
12/26 13:50:10 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 13:50:10 finished saving model
12/26 13:50:10 new best model
12/26 14:18:41 step 12000 epoch 5 learning rate 0.407 step-time 0.853 loss 38.898
12/26 14:18:41 starting evaluation
12/26 14:23:41 test bleu=18.57 loss=41.13 penalty=0.806 ratio=0.822
12/26 14:23:41 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 14:23:42 finished saving model
12/26 14:23:42 new best model
12/26 14:27:13   decaying learning rate to: 0.387
12/26 14:52:13 step 14000 epoch 6 learning rate 0.387 step-time 0.854 loss 35.911
12/26 14:52:13 starting evaluation
12/26 14:57:13 test bleu=19.66 loss=39.73 penalty=0.874 ratio=0.882
12/26 14:57:13 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 14:57:13 finished saving model
12/26 14:57:13 new best model
12/26 15:07:12   decaying learning rate to: 0.368
12/26 15:25:45 step 16000 epoch 7 learning rate 0.368 step-time 0.854 loss 33.389
12/26 15:25:45 starting evaluation
12/26 15:30:50 test bleu=22.43 loss=38.63 penalty=0.933 ratio=0.935
12/26 15:30:50 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 15:30:50 finished saving model
12/26 15:30:50 new best model
12/26 15:47:05   decaying learning rate to: 0.349
12/26 15:59:24 step 18000 epoch 8 learning rate 0.349 step-time 0.854 loss 31.300
12/26 15:59:24 starting evaluation
12/26 16:04:28 test bleu=23.69 loss=38.16 penalty=0.900 ratio=0.905
12/26 16:04:28 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 16:04:29 finished saving model
12/26 16:04:29 new best model
12/26 16:27:03   decaying learning rate to: 0.332
12/26 16:32:59 step 20000 epoch 9 learning rate 0.332 step-time 0.853 loss 29.127
12/26 16:32:59 starting evaluation
12/26 16:38:10 test bleu=25.31 loss=37.93 penalty=0.942 ratio=0.943
12/26 16:38:10 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 16:38:10 finished saving model
12/26 16:38:10 new best model
12/26 17:06:37 step 22000 epoch 9 learning rate 0.332 step-time 0.852 loss 27.408
12/26 17:06:37 starting evaluation
12/26 17:11:49 test bleu=25.31 loss=37.19 penalty=1.000 ratio=1.032
12/26 17:11:49 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 17:11:49 finished saving model
12/26 17:11:49 new best model
12/26 17:12:25   decaying learning rate to: 0.315
12/26 17:40:20 step 24000 epoch 10 learning rate 0.315 step-time 0.853 loss 24.689
12/26 17:40:20 starting evaluation
12/26 17:45:06 test bleu=25.96 loss=37.08 penalty=0.783 ratio=0.803
12/26 17:45:06 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 17:45:06 finished saving model
12/26 17:45:06 new best model
12/26 17:52:10   decaying learning rate to: 0.299
12/26 18:13:38 step 26000 epoch 11 learning rate 0.299 step-time 0.854 loss 23.045
12/26 18:13:38 starting evaluation
12/26 18:18:37 test bleu=27.93 loss=37.53 penalty=0.874 ratio=0.882
12/26 18:18:37 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 18:18:38 finished saving model
12/26 18:18:38 new best model
12/26 18:32:08   decaying learning rate to: 0.284
12/26 18:47:11 step 28000 epoch 12 learning rate 0.284 step-time 0.855 loss 21.142
12/26 18:47:11 starting evaluation
12/26 18:52:16 test bleu=29.20 loss=37.93 penalty=0.906 ratio=0.910
12/26 18:52:16 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 18:52:16 finished saving model
12/26 18:52:16 new best model
12/26 19:11:57   decaying learning rate to: 0.27
12/26 19:20:46 step 30000 epoch 13 learning rate 0.27 step-time 0.853 loss 19.761
12/26 19:20:46 starting evaluation
12/26 19:25:52 test bleu=29.95 loss=38.94 penalty=0.943 ratio=0.945
12/26 19:25:52 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 19:25:52 finished saving model
12/26 19:25:52 new best model
12/26 19:51:59   decaying learning rate to: 0.257
12/26 19:54:21 step 32000 epoch 14 learning rate 0.257 step-time 0.852 loss 18.255
12/26 19:54:21 starting evaluation
12/26 19:59:23 test bleu=30.78 loss=39.69 penalty=0.913 ratio=0.917
12/26 19:59:23 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 19:59:23 finished saving model
12/26 19:59:23 new best model
12/26 20:27:51 step 34000 epoch 14 learning rate 0.257 step-time 0.851 loss 16.242
12/26 20:27:51 starting evaluation
12/26 20:33:01 test bleu=30.88 loss=39.35 penalty=0.989 ratio=0.989
12/26 20:33:01 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 20:33:01 finished saving model
12/26 20:33:01 new best model
12/26 20:37:07   decaying learning rate to: 0.244
12/26 21:01:32 step 36000 epoch 15 learning rate 0.244 step-time 0.854 loss 14.681
12/26 21:01:32 starting evaluation
12/26 21:06:29 test bleu=31.37 loss=40.78 penalty=0.890 ratio=0.896
12/26 21:06:29 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 21:06:29 finished saving model
12/26 21:06:29 new best model
12/26 21:17:03   decaying learning rate to: 0.232
12/26 21:34:58 step 38000 epoch 16 learning rate 0.232 step-time 0.852 loss 13.438
12/26 21:34:58 starting evaluation
12/26 21:39:59 test bleu=31.89 loss=42.74 penalty=0.908 ratio=0.912
12/26 21:39:59 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 21:39:59 finished saving model
12/26 21:39:59 new best model
12/26 21:56:55   decaying learning rate to: 0.22
12/26 22:08:31 step 40000 epoch 17 learning rate 0.22 step-time 0.854 loss 12.270
12/26 22:08:31 starting evaluation
12/26 22:13:32 test bleu=32.08 loss=44.68 penalty=0.882 ratio=0.889
12/26 22:13:32 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 22:13:32 finished saving model
12/26 22:13:32 new best model
12/26 22:36:44   decaying learning rate to: 0.209
12/26 22:42:02 step 42000 epoch 18 learning rate 0.209 step-time 0.853 loss 11.237
12/26 22:42:02 starting evaluation
12/26 22:47:08 test bleu=33.27 loss=46.15 penalty=0.953 ratio=0.954
12/26 22:47:08 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 22:47:08 finished saving model
12/26 22:47:08 new best model
12/26 23:15:25 step 44000 epoch 18 learning rate 0.209 step-time 0.846 loss 10.125
12/26 23:15:25 starting evaluation
12/26 23:20:27 test bleu=33.71 loss=45.77 penalty=0.946 ratio=0.948
12/26 23:20:27 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 23:20:27 finished saving model
12/26 23:20:27 new best model
12/26 23:21:37   decaying learning rate to: 0.199
12/26 23:48:29 step 46000 epoch 19 learning rate 0.199 step-time 0.839 loss 8.647
12/26 23:48:29 starting evaluation
12/26 23:53:33 test bleu=33.33 loss=48.39 penalty=0.956 ratio=0.957
12/26 23:53:33 saving model to models/3_fold_hybrid_pnl/checkpoints
12/26 23:53:33 finished saving model
12/27 00:01:05   decaying learning rate to: 0.189
12/27 00:21:37 step 48000 epoch 20 learning rate 0.189 step-time 0.840 loss 7.872
12/27 00:21:37 starting evaluation
12/27 00:26:38 test bleu=33.73 loss=50.70 penalty=0.938 ratio=0.939
12/27 00:26:38 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 00:26:38 finished saving model
12/27 00:26:38 new best model
12/27 00:40:32   decaying learning rate to: 0.179
12/27 00:54:42 step 50000 epoch 21 learning rate 0.179 step-time 0.840 loss 7.090
12/27 00:54:42 starting evaluation
12/27 00:59:40 test bleu=34.22 loss=53.44 penalty=0.942 ratio=0.944
12/27 00:59:40 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 00:59:40 finished saving model
12/27 00:59:40 new best model
12/27 01:19:35   decaying learning rate to: 0.17
12/27 01:27:41 step 52000 epoch 22 learning rate 0.17 step-time 0.838 loss 6.457
12/27 01:27:41 starting evaluation
12/27 01:32:44 test bleu=34.09 loss=55.89 penalty=0.950 ratio=0.952
12/27 01:32:44 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 01:32:44 finished saving model
12/27 01:59:02   decaying learning rate to: 0.162
12/27 02:00:45 step 54000 epoch 23 learning rate 0.162 step-time 0.839 loss 5.829
12/27 02:00:45 starting evaluation
12/27 02:05:48 test bleu=34.61 loss=57.35 penalty=0.952 ratio=0.953
12/27 02:05:48 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 02:05:48 finished saving model
12/27 02:05:48 new best model
12/27 02:33:50 step 56000 epoch 23 learning rate 0.162 step-time 0.839 loss 4.940
12/27 02:33:50 starting evaluation
12/27 02:38:57 test bleu=33.77 loss=58.85 penalty=1.000 ratio=1.034
12/27 02:38:57 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 02:38:57 finished saving model
12/27 02:43:37   decaying learning rate to: 0.154
12/27 03:07:03 step 58000 epoch 24 learning rate 0.154 step-time 0.841 loss 4.377
12/27 03:07:03 starting evaluation
12/27 03:12:10 test bleu=34.86 loss=61.22 penalty=0.989 ratio=0.989
12/27 03:12:10 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 03:12:10 finished saving model
12/27 03:12:10 new best model
12/27 03:23:09   decaying learning rate to: 0.146
12/27 03:40:12 step 60000 epoch 25 learning rate 0.146 step-time 0.839 loss 3.950
12/27 03:40:12 starting evaluation
12/27 03:45:17 test bleu=35.25 loss=63.86 penalty=0.999 ratio=0.999
12/27 03:45:17 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 03:45:17 finished saving model
12/27 03:45:17 new best model
12/27 04:03:01   decaying learning rate to: 0.139
12/27 04:14:10 step 62000 epoch 26 learning rate 0.139 step-time 0.864 loss 3.558
12/27 04:14:10 starting evaluation
12/27 04:19:16 test bleu=35.19 loss=66.06 penalty=0.973 ratio=0.973
12/27 04:19:16 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 04:19:17 finished saving model
12/27 04:43:30   decaying learning rate to: 0.132
12/27 04:48:17 step 64000 epoch 27 learning rate 0.132 step-time 0.868 loss 3.237
12/27 04:48:17 starting evaluation
12/27 04:53:23 test bleu=35.26 loss=67.91 penalty=0.963 ratio=0.964
12/27 04:53:23 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 04:53:23 finished saving model
12/27 04:53:23 new best model
12/27 05:22:24 step 66000 epoch 27 learning rate 0.132 step-time 0.868 loss 2.832
12/27 05:22:24 starting evaluation
12/27 05:27:35 test bleu=35.68 loss=69.13 penalty=0.992 ratio=0.992
12/27 05:27:35 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 05:27:35 finished saving model
12/27 05:27:35 new best model
12/27 05:29:22   decaying learning rate to: 0.125
12/27 05:56:33 step 68000 epoch 28 learning rate 0.125 step-time 0.867 loss 2.392
12/27 05:56:33 starting evaluation
12/27 06:01:41 test bleu=35.47 loss=72.77 penalty=1.000 ratio=1.001
12/27 06:01:41 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 06:01:41 finished saving model
12/27 06:10:03   decaying learning rate to: 0.119
12/27 06:30:38 step 70000 epoch 29 learning rate 0.119 step-time 0.867 loss 2.186
12/27 06:30:38 starting evaluation
12/27 06:35:45 test bleu=35.60 loss=75.82 penalty=0.987 ratio=0.987
12/27 06:35:45 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 06:35:46 finished saving model
12/27 06:50:43   decaying learning rate to: 0.113
12/27 07:04:44 step 72000 epoch 30 learning rate 0.113 step-time 0.867 loss 1.975
12/27 07:04:44 starting evaluation
12/27 07:09:54 test bleu=35.52 loss=78.29 penalty=1.000 ratio=1.011
12/27 07:09:54 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 07:09:54 finished saving model
12/27 07:31:06   decaying learning rate to: 0.107
12/27 07:38:54 step 74000 epoch 31 learning rate 0.107 step-time 0.868 loss 1.820
12/27 07:38:54 starting evaluation
12/27 07:44:02 test bleu=35.64 loss=80.26 penalty=1.000 ratio=1.002
12/27 07:44:02 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 07:44:02 finished saving model
12/27 08:11:52   decaying learning rate to: 0.102
12/27 08:13:02 step 76000 epoch 32 learning rate 0.102 step-time 0.868 loss 1.661
12/27 08:13:02 starting evaluation
12/27 08:18:08 test bleu=36.40 loss=80.66 penalty=0.989 ratio=0.989
12/27 08:18:08 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 08:18:09 finished saving model
12/27 08:18:09 new best model
12/27 08:47:03 step 78000 epoch 32 learning rate 0.102 step-time 0.865 loss 1.400
12/27 08:47:03 starting evaluation
12/27 08:52:13 test bleu=35.72 loss=83.20 penalty=1.000 ratio=1.016
12/27 08:52:13 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 08:52:13 finished saving model
12/27 08:57:36   decaying learning rate to: 0.0969
12/27 09:21:13 step 80000 epoch 33 learning rate 0.0969 step-time 0.868 loss 1.262
12/27 09:21:13 starting evaluation
12/27 09:26:20 test bleu=36.33 loss=85.42 penalty=0.993 ratio=0.993
12/27 09:26:20 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 09:26:20 finished saving model
12/27 09:38:12   decaying learning rate to: 0.092
12/27 09:55:19 step 82000 epoch 34 learning rate 0.092 step-time 0.867 loss 1.177
12/27 09:55:19 starting evaluation
12/27 10:00:28 test bleu=35.52 loss=86.95 penalty=1.000 ratio=1.023
12/27 10:00:28 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 10:00:29 finished saving model
12/27 10:18:49   decaying learning rate to: 0.0874
12/27 10:29:26 step 84000 epoch 35 learning rate 0.0874 step-time 0.867 loss 1.082
12/27 10:29:26 starting evaluation
12/27 10:34:34 test bleu=36.19 loss=88.56 penalty=1.000 ratio=1.011
12/27 10:34:34 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 10:34:34 finished saving model
12/27 10:59:20   decaying learning rate to: 0.083
12/27 11:03:32 step 86000 epoch 36 learning rate 0.083 step-time 0.867 loss 0.985
12/27 11:03:32 starting evaluation
12/27 11:08:42 test bleu=35.95 loss=89.81 penalty=1.000 ratio=1.020
12/27 11:08:42 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 11:08:42 finished saving model
12/27 11:37:40 step 88000 epoch 36 learning rate 0.083 step-time 0.867 loss 0.900
12/27 11:37:40 starting evaluation
12/27 11:42:48 test bleu=36.06 loss=91.05 penalty=1.000 ratio=1.021
12/27 11:42:48 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 11:42:48 finished saving model
12/27 11:45:11   decaying learning rate to: 0.0789
12/27 12:11:49 step 90000 epoch 37 learning rate 0.0789 step-time 0.868 loss 0.797
12/27 12:11:49 starting evaluation
12/27 12:16:54 test bleu=36.34 loss=92.84 penalty=1.000 ratio=1.005
12/27 12:16:54 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 12:16:54 finished saving model
12/27 12:25:51   decaying learning rate to: 0.0749
12/27 12:45:52 step 92000 epoch 38 learning rate 0.0749 step-time 0.867 loss 0.752
12/27 12:45:52 starting evaluation
12/27 12:51:02 test bleu=36.07 loss=94.36 penalty=1.000 ratio=1.019
12/27 12:51:02 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 12:51:02 finished saving model
12/27 13:06:34   decaying learning rate to: 0.0712
12/27 13:19:56 step 94000 epoch 39 learning rate 0.0712 step-time 0.865 loss 0.699
12/27 13:19:56 starting evaluation
12/27 13:25:03 test bleu=36.90 loss=95.24 penalty=0.989 ratio=0.989
12/27 13:25:03 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 13:25:04 finished saving model
12/27 13:25:04 new best model
12/27 13:46:56   decaying learning rate to: 0.0676
12/27 13:54:07 step 96000 epoch 40 learning rate 0.0676 step-time 0.870 loss 0.654
12/27 13:54:07 starting evaluation
12/27 13:59:15 test bleu=36.96 loss=97.17 penalty=1.000 ratio=1.000
12/27 13:59:15 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 13:59:15 finished saving model
12/27 13:59:15 new best model
12/27 14:27:38   decaying learning rate to: 0.0643
12/27 14:28:13 step 98000 epoch 41 learning rate 0.0643 step-time 0.867 loss 0.622
12/27 14:28:13 starting evaluation
12/27 14:33:20 test bleu=36.89 loss=96.98 penalty=0.996 ratio=0.996
12/27 14:33:20 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 14:33:20 finished saving model
12/27 15:02:18 step 100000 epoch 41 learning rate 0.0643 step-time 0.867 loss 0.547
12/27 15:02:18 starting evaluation
12/27 15:07:28 test bleu=36.39 loss=98.39 penalty=1.000 ratio=1.017
12/27 15:07:28 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 15:07:28 finished saving model
12/27 15:13:26   decaying learning rate to: 0.061
12/27 15:36:25 step 102000 epoch 42 learning rate 0.061 step-time 0.866 loss 0.526
12/27 15:36:25 starting evaluation
12/27 15:41:34 test bleu=36.91 loss=99.00 penalty=1.000 ratio=1.006
12/27 15:41:34 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 15:41:34 finished saving model
12/27 15:54:02   decaying learning rate to: 0.058
12/27 16:10:30 step 104000 epoch 43 learning rate 0.058 step-time 0.866 loss 0.489
12/27 16:10:30 starting evaluation
12/27 16:15:38 test bleu=37.12 loss=99.52 penalty=1.000 ratio=1.001
12/27 16:15:38 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 16:15:38 finished saving model
12/27 16:15:38 new best model
12/27 16:34:35   decaying learning rate to: 0.0551
12/27 16:44:37 step 106000 epoch 44 learning rate 0.0551 step-time 0.867 loss 0.469
12/27 16:44:37 starting evaluation
12/27 16:49:42 test bleu=37.14 loss=100.20 penalty=0.993 ratio=0.993
12/27 16:49:42 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 16:49:42 finished saving model
12/27 16:49:42 new best model
12/27 17:15:03   decaying learning rate to: 0.0523
12/27 17:18:38 step 108000 epoch 45 learning rate 0.0523 step-time 0.866 loss 0.447
12/27 17:18:38 starting evaluation
12/27 17:23:45 test bleu=37.36 loss=101.31 penalty=0.995 ratio=0.995
12/27 17:23:45 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 17:23:45 finished saving model
12/27 17:23:45 new best model
12/27 17:52:42 step 110000 epoch 45 learning rate 0.0523 step-time 0.867 loss 0.414
12/27 17:52:42 starting evaluation
12/27 17:57:52 test bleu=36.52 loss=102.13 penalty=1.000 ratio=1.023
12/27 17:57:52 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 17:57:52 finished saving model
12/27 18:00:51   decaying learning rate to: 0.0497
12/27 18:26:50 step 112000 epoch 46 learning rate 0.0497 step-time 0.867 loss 0.380
12/27 18:26:50 starting evaluation
12/27 18:31:57 test bleu=37.28 loss=101.78 penalty=1.000 ratio=1.001
12/27 18:31:57 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 18:31:57 finished saving model
12/27 18:41:30   decaying learning rate to: 0.0472
12/27 19:00:57 step 114000 epoch 47 learning rate 0.0472 step-time 0.868 loss 0.372
12/27 19:00:57 starting evaluation
12/27 19:06:03 test bleu=37.53 loss=102.49 penalty=0.997 ratio=0.997
12/27 19:06:03 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 19:06:03 finished saving model
12/27 19:06:03 new best model
12/27 19:22:14   decaying learning rate to: 0.0449
12/27 19:35:03 step 116000 epoch 48 learning rate 0.0449 step-time 0.867 loss 0.344
12/27 19:35:03 starting evaluation
12/27 19:40:10 test bleu=37.58 loss=102.66 penalty=0.998 ratio=0.998
12/27 19:40:10 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 19:40:10 finished saving model
12/27 19:40:10 new best model
12/27 20:02:33   decaying learning rate to: 0.0426
12/27 20:09:09 step 118000 epoch 49 learning rate 0.0426 step-time 0.867 loss 0.331
12/27 20:09:09 starting evaluation
12/27 20:14:18 test bleu=36.97 loss=102.58 penalty=1.000 ratio=1.019
12/27 20:14:18 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 20:14:18 finished saving model
12/27 20:43:14 step 120000 epoch 50 learning rate 0.0426 step-time 0.866 loss 0.322
12/27 20:43:14 starting evaluation
12/27 20:48:22 test bleu=36.84 loss=101.78 penalty=1.000 ratio=1.020
12/27 20:48:22 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 20:48:22 finished saving model
12/27 20:48:23   decaying learning rate to: 0.0405
12/27 21:17:20 step 122000 epoch 50 learning rate 0.0405 step-time 0.867 loss 0.282
12/27 21:17:20 starting evaluation
12/27 21:22:29 test bleu=37.06 loss=102.42 penalty=1.000 ratio=1.020
12/27 21:22:29 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 21:22:29 finished saving model
12/27 21:29:03   decaying learning rate to: 0.0385
12/27 21:51:26 step 124000 epoch 51 learning rate 0.0385 step-time 0.867 loss 0.270
12/27 21:51:26 starting evaluation
12/27 21:56:35 test bleu=37.43 loss=102.41 penalty=1.000 ratio=1.009
12/27 21:56:35 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 21:56:35 finished saving model
12/27 22:09:41   decaying learning rate to: 0.0365
12/27 22:25:37 step 126000 epoch 52 learning rate 0.0365 step-time 0.869 loss 0.260
12/27 22:25:37 starting evaluation
12/27 22:30:46 test bleu=35.81 loss=102.60 penalty=1.000 ratio=1.049
12/27 22:30:46 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 22:30:47 finished saving model
12/27 22:50:17   decaying learning rate to: 0.0347
12/27 22:59:44 step 128000 epoch 53 learning rate 0.0347 step-time 0.867 loss 0.245
12/27 22:59:44 starting evaluation
12/27 23:04:48 test bleu=37.83 loss=102.85 penalty=0.999 ratio=0.999
12/27 23:04:48 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 23:04:48 finished saving model
12/27 23:04:48 new best model
12/27 23:30:48   decaying learning rate to: 0.033
12/27 23:33:46 step 130000 epoch 54 learning rate 0.033 step-time 0.867 loss 0.237
12/27 23:33:46 starting evaluation
12/27 23:38:54 test bleu=37.42 loss=102.66 penalty=1.000 ratio=1.010
12/27 23:38:54 saving model to models/3_fold_hybrid_pnl/checkpoints
12/27 23:38:55 finished saving model
12/28 00:07:54 step 132000 epoch 54 learning rate 0.033 step-time 0.868 loss 0.218
12/28 00:07:54 starting evaluation
12/28 00:13:04 test bleu=37.08 loss=102.73 penalty=1.000 ratio=1.018
12/28 00:13:04 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 00:13:04 finished saving model
12/28 00:16:39   decaying learning rate to: 0.0313
12/28 00:42:01 step 134000 epoch 55 learning rate 0.0313 step-time 0.867 loss 0.207
12/28 00:42:01 starting evaluation
12/28 00:47:08 test bleu=37.37 loss=102.69 penalty=1.000 ratio=1.007
12/28 00:47:08 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 00:47:09 finished saving model
12/28 00:57:15   decaying learning rate to: 0.0298
12/28 01:16:05 step 136000 epoch 56 learning rate 0.0298 step-time 0.866 loss 0.193
12/28 01:16:05 starting evaluation
12/28 01:21:13 test bleu=37.68 loss=102.61 penalty=1.000 ratio=1.007
12/28 01:21:13 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 01:21:13 finished saving model
12/28 01:37:58   decaying learning rate to: 0.0283
12/28 01:50:12 step 138000 epoch 57 learning rate 0.0283 step-time 0.867 loss 0.190
12/28 01:50:12 starting evaluation
12/28 01:55:22 test bleu=36.64 loss=103.09 penalty=1.000 ratio=1.032
12/28 01:55:22 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 01:55:22 finished saving model
12/28 02:19:20   decaying learning rate to: 0.0269
12/28 02:25:34 step 140000 epoch 58 learning rate 0.0269 step-time 0.904 loss 0.183
12/28 02:25:34 starting evaluation
12/28 02:30:47 test bleu=37.72 loss=103.22 penalty=1.000 ratio=1.005
12/28 02:30:47 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 02:30:48 finished saving model
12/28 03:01:03 step 142000 epoch 58 learning rate 0.0269 step-time 0.905 loss 0.180
12/28 03:01:03 starting evaluation
12/28 03:06:15 test bleu=37.24 loss=102.85 penalty=1.000 ratio=1.015
12/28 03:06:15 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 03:06:15 finished saving model
12/28 03:06:53   decaying learning rate to: 0.0255
12/28 03:36:29 step 144000 epoch 59 learning rate 0.0255 step-time 0.904 loss 0.160
12/28 03:36:29 starting evaluation
12/28 03:41:41 test bleu=37.66 loss=103.02 penalty=1.000 ratio=1.006
12/28 03:41:41 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 03:41:41 finished saving model
12/28 03:49:11   decaying learning rate to: 0.0242
12/28 04:12:05 step 146000 epoch 60 learning rate 0.0242 step-time 0.909 loss 0.154
12/28 04:12:05 starting evaluation
12/28 04:17:14 test bleu=37.90 loss=102.95 penalty=1.000 ratio=1.001
12/28 04:17:14 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 04:17:14 finished saving model
12/28 04:17:14 new best model
12/28 04:31:29   decaying learning rate to: 0.023
12/28 04:47:05 step 148000 epoch 61 learning rate 0.023 step-time 0.893 loss 0.156
12/28 04:47:05 starting evaluation
12/28 04:52:12 test bleu=38.03 loss=103.07 penalty=1.000 ratio=1.000
12/28 04:52:12 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 04:52:12 finished saving model
12/28 04:52:12 new best model
12/28 05:12:16   decaying learning rate to: 0.0219
12/28 05:21:09 step 150000 epoch 62 learning rate 0.0219 step-time 0.866 loss 0.145
12/28 05:21:09 starting evaluation
12/28 05:26:15 test bleu=37.50 loss=103.23 penalty=1.000 ratio=1.014
12/28 05:26:15 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 05:26:16 finished saving model
12/28 05:52:48   decaying learning rate to: 0.0208
12/28 05:55:10 step 152000 epoch 63 learning rate 0.0208 step-time 0.865 loss 0.146
12/28 05:55:10 starting evaluation
12/28 06:00:17 test bleu=37.72 loss=103.54 penalty=1.000 ratio=1.008
12/28 06:00:17 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 06:00:17 finished saving model
12/28 06:29:34 step 154000 epoch 63 learning rate 0.0208 step-time 0.876 loss 0.135
12/28 06:29:34 starting evaluation
12/28 06:34:42 test bleu=37.71 loss=103.34 penalty=1.000 ratio=1.007
12/28 06:34:42 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 06:34:42 finished saving model
12/28 06:38:57   decaying learning rate to: 0.0197
12/28 07:04:09 step 156000 epoch 64 learning rate 0.0197 step-time 0.882 loss 0.129
12/28 07:04:09 starting evaluation
12/28 07:09:17 test bleu=37.63 loss=103.34 penalty=1.000 ratio=1.009
12/28 07:09:17 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 07:09:17 finished saving model
12/28 07:20:11   decaying learning rate to: 0.0188
12/28 07:38:43 step 158000 epoch 65 learning rate 0.0188 step-time 0.881 loss 0.129
12/28 07:38:43 starting evaluation
12/28 07:43:49 test bleu=38.04 loss=104.03 penalty=1.000 ratio=1.003
12/28 07:43:49 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 07:43:49 finished saving model
12/28 07:43:49 new best model
12/28 08:01:24   decaying learning rate to: 0.0178
12/28 08:13:14 step 160000 epoch 66 learning rate 0.0178 step-time 0.880 loss 0.121
12/28 08:13:14 starting evaluation
12/28 08:18:23 test bleu=37.22 loss=104.08 penalty=1.000 ratio=1.018
12/28 08:18:23 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 08:18:24 finished saving model
12/28 08:42:23   decaying learning rate to: 0.0169
12/28 08:47:50 step 162000 epoch 67 learning rate 0.0169 step-time 0.881 loss 0.125
12/28 08:47:50 starting evaluation
12/28 08:52:59 test bleu=37.95 loss=104.20 penalty=1.000 ratio=1.004
12/28 08:52:59 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 08:52:59 finished saving model
12/28 09:22:26 step 164000 epoch 67 learning rate 0.0169 step-time 0.881 loss 0.119
12/28 09:22:26 starting evaluation
12/28 09:27:33 test bleu=37.72 loss=103.93 penalty=1.000 ratio=1.006
12/28 09:27:33 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 09:27:33 finished saving model
12/28 09:28:46   decaying learning rate to: 0.0161
12/28 09:56:59 step 166000 epoch 68 learning rate 0.0161 step-time 0.881 loss 0.111
12/28 09:56:59 starting evaluation
12/28 10:02:07 test bleu=37.92 loss=104.16 penalty=0.998 ratio=0.998
12/28 10:02:07 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 10:02:07 finished saving model
12/28 10:10:01   decaying learning rate to: 0.0153
12/28 10:31:33 step 168000 epoch 69 learning rate 0.0153 step-time 0.881 loss 0.107
12/28 10:31:33 starting evaluation
12/28 10:36:42 test bleu=37.97 loss=104.50 penalty=1.000 ratio=1.002
12/28 10:36:42 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 10:36:42 finished saving model
12/28 10:51:13   decaying learning rate to: 0.0145
12/28 11:06:07 step 170000 epoch 70 learning rate 0.0145 step-time 0.881 loss 0.104
12/28 11:06:07 starting evaluation
12/28 11:11:16 test bleu=37.47 loss=104.89 penalty=1.000 ratio=1.010
12/28 11:11:16 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 11:11:16 finished saving model
12/28 11:32:16   decaying learning rate to: 0.0138
12/28 11:40:42 step 172000 epoch 71 learning rate 0.0138 step-time 0.881 loss 0.108
12/28 11:40:42 starting evaluation
12/28 11:45:51 test bleu=37.72 loss=104.88 penalty=1.000 ratio=1.008
12/28 11:45:51 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 11:45:51 finished saving model
12/28 12:13:14   decaying learning rate to: 0.0131
12/28 12:14:58 step 174000 epoch 72 learning rate 0.0131 step-time 0.871 loss 0.103
12/28 12:14:58 starting evaluation
12/28 12:20:01 test bleu=37.68 loss=104.69 penalty=1.000 ratio=1.006
12/28 12:20:01 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 12:20:02 finished saving model
12/28 12:48:28 step 176000 epoch 72 learning rate 0.0131 step-time 0.851 loss 0.099
12/28 12:48:28 starting evaluation
12/28 12:53:36 test bleu=37.15 loss=104.93 penalty=1.000 ratio=1.020
12/28 12:53:36 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 12:53:36 finished saving model
12/28 12:58:19   decaying learning rate to: 0.0124
12/28 13:22:05 step 178000 epoch 73 learning rate 0.0124 step-time 0.852 loss 0.094
12/28 13:22:05 starting evaluation
12/28 13:27:09 test bleu=37.55 loss=105.03 penalty=1.000 ratio=1.008
12/28 13:27:09 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 13:27:09 finished saving model
12/28 13:38:20   decaying learning rate to: 0.0118
12/28 13:55:40 step 180000 epoch 74 learning rate 0.0118 step-time 0.854 loss 0.094
12/28 13:55:40 starting evaluation
12/28 14:00:47 test bleu=37.37 loss=105.45 penalty=1.000 ratio=1.015
12/28 14:00:47 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 14:00:47 finished saving model
12/28 14:18:25   decaying learning rate to: 0.0112
12/28 14:29:19 step 182000 epoch 75 learning rate 0.0112 step-time 0.854 loss 0.094
12/28 14:29:19 starting evaluation
12/28 14:34:23 test bleu=37.73 loss=105.74 penalty=1.000 ratio=1.005
12/28 14:34:23 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 14:34:24 finished saving model
12/28 14:58:13   decaying learning rate to: 0.0107
12/28 15:02:54 step 184000 epoch 76 learning rate 0.0107 step-time 0.853 loss 0.092
12/28 15:02:54 starting evaluation
12/28 15:08:00 test bleu=37.83 loss=105.58 penalty=1.000 ratio=1.003
12/28 15:08:00 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 15:08:00 finished saving model
12/28 15:36:31 step 186000 epoch 76 learning rate 0.0107 step-time 0.854 loss 0.089
12/28 15:36:31 starting evaluation
12/28 15:41:37 test bleu=37.29 loss=105.53 penalty=1.000 ratio=1.017
12/28 15:41:37 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 15:41:37 finished saving model
12/28 15:43:26   decaying learning rate to: 0.0101
12/28 16:10:09 step 188000 epoch 77 learning rate 0.0101 step-time 0.854 loss 0.085
12/28 16:10:09 starting evaluation
12/28 16:15:12 test bleu=38.00 loss=105.70 penalty=0.999 ratio=0.999
12/28 16:15:12 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 16:15:12 finished saving model
12/28 16:23:34   decaying learning rate to: 0.00963
12/28 16:44:08 step 190000 epoch 78 learning rate 0.00963 step-time 0.866 loss 0.083
12/28 16:44:08 starting evaluation
12/28 16:49:16 test bleu=37.76 loss=106.08 penalty=1.000 ratio=1.006
12/28 16:49:16 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 16:49:16 finished saving model
12/28 17:04:16   decaying learning rate to: 0.00915
12/28 17:18:16 step 192000 epoch 79 learning rate 0.00915 step-time 0.868 loss 0.082
12/28 17:18:16 starting evaluation
12/28 17:23:23 test bleu=37.56 loss=106.18 penalty=1.000 ratio=1.012
12/28 17:23:23 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 17:23:24 finished saving model
12/28 17:44:40   decaying learning rate to: 0.00869
12/28 17:52:19 step 194000 epoch 80 learning rate 0.00869 step-time 0.866 loss 0.083
12/28 17:52:19 starting evaluation
12/28 17:57:24 test bleu=37.87 loss=106.27 penalty=1.000 ratio=1.005
12/28 17:57:24 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 17:57:25 finished saving model
12/28 18:24:11   decaying learning rate to: 0.00826
12/28 18:25:19 step 196000 epoch 81 learning rate 0.00826 step-time 0.835 loss 0.083
12/28 18:25:19 starting evaluation
12/28 18:30:20 test bleu=37.63 loss=106.30 penalty=1.000 ratio=1.009
12/28 18:30:20 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 18:30:20 finished saving model
12/28 18:58:03 step 198000 epoch 81 learning rate 0.00826 step-time 0.830 loss 0.079
12/28 18:58:03 starting evaluation
12/28 19:03:05 test bleu=37.73 loss=106.37 penalty=1.000 ratio=1.005
12/28 19:03:05 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 19:03:05 finished saving model
12/28 19:08:17   decaying learning rate to: 0.00784
12/28 19:30:52 step 200000 epoch 82 learning rate 0.00784 step-time 0.831 loss 0.077
12/28 19:30:52 starting evaluation
12/28 19:35:54 test bleu=37.95 loss=106.55 penalty=1.000 ratio=1.000
12/28 19:35:54 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 19:35:54 finished saving model
12/28 19:47:23   decaying learning rate to: 0.00745
12/28 20:03:38 step 202000 epoch 83 learning rate 0.00745 step-time 0.830 loss 0.075
12/28 20:03:38 starting evaluation
12/28 20:08:39 test bleu=37.73 loss=106.77 penalty=1.000 ratio=1.006
12/28 20:08:39 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 20:08:40 finished saving model
12/28 20:26:22   decaying learning rate to: 0.00708
12/28 20:36:25 step 204000 epoch 84 learning rate 0.00708 step-time 0.831 loss 0.076
12/28 20:36:25 starting evaluation
12/28 20:41:28 test bleu=37.64 loss=106.90 penalty=1.000 ratio=1.010
12/28 20:41:28 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 20:41:28 finished saving model
12/28 21:05:11   decaying learning rate to: 0.00673
12/28 21:09:10 step 206000 epoch 85 learning rate 0.00673 step-time 0.829 loss 0.076
12/28 21:09:10 starting evaluation
12/28 21:14:12 test bleu=37.67 loss=106.95 penalty=1.000 ratio=1.006
12/28 21:14:12 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 21:14:12 finished saving model
12/28 21:41:58 step 208000 epoch 85 learning rate 0.00673 step-time 0.831 loss 0.074
12/28 21:41:58 starting evaluation
12/28 21:46:59 test bleu=37.93 loss=106.96 penalty=1.000 ratio=1.002
12/28 21:46:59 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 21:46:59 finished saving model
12/28 21:49:18   decaying learning rate to: 0.00639
12/28 22:14:43 step 210000 epoch 86 learning rate 0.00639 step-time 0.830 loss 0.072
12/28 22:14:43 starting evaluation
12/28 22:19:44 test bleu=37.67 loss=107.17 penalty=1.000 ratio=1.008
12/28 22:19:44 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 22:19:44 finished saving model
12/28 22:28:21   decaying learning rate to: 0.00607
12/28 22:47:27 step 212000 epoch 87 learning rate 0.00607 step-time 0.830 loss 0.072
12/28 22:47:27 starting evaluation
12/28 22:52:28 test bleu=37.79 loss=107.25 penalty=1.000 ratio=1.005
12/28 22:52:28 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 22:52:29 finished saving model
12/28 23:07:23   decaying learning rate to: 0.00577
12/28 23:20:11 step 214000 epoch 88 learning rate 0.00577 step-time 0.830 loss 0.071
12/28 23:20:11 starting evaluation
12/28 23:25:13 test bleu=37.69 loss=107.37 penalty=1.000 ratio=1.008
12/28 23:25:13 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 23:25:14 finished saving model
12/28 23:46:11   decaying learning rate to: 0.00548
12/28 23:52:59 step 216000 epoch 89 learning rate 0.00548 step-time 0.831 loss 0.071
12/28 23:52:59 starting evaluation
12/28 23:58:01 test bleu=37.65 loss=107.45 penalty=1.000 ratio=1.008
12/28 23:58:01 saving model to models/3_fold_hybrid_pnl/checkpoints
12/28 23:58:01 finished saving model
12/29 00:25:12   decaying learning rate to: 0.0052
12/29 00:25:44 step 218000 epoch 90 learning rate 0.0052 step-time 0.830 loss 0.070
12/29 00:25:44 starting evaluation
12/29 00:30:47 test bleu=37.78 loss=107.49 penalty=1.000 ratio=1.005
12/29 00:30:47 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 00:30:47 finished saving model
12/29 00:58:32 step 220000 epoch 90 learning rate 0.0052 step-time 0.830 loss 0.068
12/29 00:58:32 starting evaluation
12/29 01:03:33 test bleu=37.85 loss=107.52 penalty=1.000 ratio=1.003
12/29 01:03:33 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 01:03:33 finished saving model
12/29 01:09:18   decaying learning rate to: 0.00494
12/29 01:31:16 step 222000 epoch 91 learning rate 0.00494 step-time 0.830 loss 0.066
12/29 01:31:16 starting evaluation
12/29 01:36:18 test bleu=37.70 loss=107.74 penalty=1.000 ratio=1.008
12/29 01:36:18 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 01:36:19 finished saving model
12/29 01:48:23   decaying learning rate to: 0.0047
12/29 02:04:30 step 224000 epoch 92 learning rate 0.0047 step-time 0.844 loss 0.068
12/29 02:04:30 starting evaluation
12/29 02:09:34 test bleu=37.70 loss=107.76 penalty=1.000 ratio=1.008
12/29 02:09:34 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 02:09:34 finished saving model
12/29 02:29:02   decaying learning rate to: 0.00446
12/29 02:39:50 step 226000 epoch 93 learning rate 0.00446 step-time 0.905 loss 0.067
12/29 02:39:50 starting evaluation
12/29 02:45:00 test bleu=37.68 loss=107.95 penalty=1.000 ratio=1.008
12/29 02:45:00 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 02:45:00 finished saving model
12/29 03:11:18   decaying learning rate to: 0.00424
12/29 03:14:58 step 228000 epoch 94 learning rate 0.00424 step-time 0.897 loss 0.067
12/29 03:14:58 starting evaluation
12/29 03:20:05 test bleu=37.64 loss=107.99 penalty=1.000 ratio=1.009
12/29 03:20:05 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 03:20:05 finished saving model
12/29 03:48:36 step 230000 epoch 94 learning rate 0.00424 step-time 0.853 loss 0.066
12/29 03:48:36 starting evaluation
12/29 03:53:39 test bleu=37.56 loss=107.92 penalty=1.000 ratio=1.010
12/29 03:53:39 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 03:53:39 finished saving model
12/29 03:56:31   decaying learning rate to: 0.00403
12/29 04:21:24 step 232000 epoch 95 learning rate 0.00403 step-time 0.830 loss 0.064
12/29 04:21:24 starting evaluation
12/29 04:26:25 test bleu=37.83 loss=108.13 penalty=1.000 ratio=1.005
12/29 04:26:25 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 04:26:25 finished saving model
12/29 04:36:00   decaying learning rate to: 0.00383
12/29 04:55:32 step 234000 epoch 96 learning rate 0.00383 step-time 0.871 loss 0.064
12/29 04:55:32 starting evaluation
12/29 05:00:39 test bleu=37.49 loss=108.24 penalty=1.000 ratio=1.011
12/29 05:00:39 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 05:00:39 finished saving model
12/29 05:16:53   decaying learning rate to: 0.00363
12/29 05:29:46 step 236000 epoch 97 learning rate 0.00363 step-time 0.871 loss 0.064
12/29 05:29:46 starting evaluation
12/29 05:34:54 test bleu=37.55 loss=108.28 penalty=1.000 ratio=1.008
12/29 05:34:54 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 05:34:54 finished saving model
12/29 05:57:26   decaying learning rate to: 0.00345
12/29 06:03:58 step 238000 epoch 98 learning rate 0.00345 step-time 0.870 loss 0.064
12/29 06:03:58 starting evaluation
12/29 06:09:06 test bleu=37.78 loss=108.43 penalty=1.000 ratio=1.004
12/29 06:09:06 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 06:09:06 finished saving model
12/29 06:38:13 step 240000 epoch 99 learning rate 0.00345 step-time 0.871 loss 0.064
12/29 06:38:13 starting evaluation
12/29 06:43:22 test bleu=37.60 loss=108.22 penalty=1.000 ratio=1.010
12/29 06:43:22 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 06:43:23 finished saving model
12/29 06:43:24   decaying learning rate to: 0.00328
12/29 07:12:13 step 242000 epoch 99 learning rate 0.00328 step-time 0.863 loss 0.062
12/29 07:12:13 starting evaluation
12/29 07:17:20 test bleu=37.57 loss=108.51 penalty=1.000 ratio=1.011
12/29 07:17:20 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 07:17:20 finished saving model
12/29 07:23:52   decaying learning rate to: 0.00312
12/29 07:45:59 step 244000 epoch 100 learning rate 0.00312 step-time 0.857 loss 0.061
12/29 07:45:59 starting evaluation
12/29 07:51:05 test bleu=37.57 loss=108.52 penalty=1.000 ratio=1.009
12/29 07:51:05 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 07:51:05 finished saving model
12/29 08:03:43 finished training
12/29 08:03:43 exiting...
12/29 08:03:43 saving model to models/3_fold_hybrid_pnl/checkpoints
12/29 08:03:44 finished saving model
