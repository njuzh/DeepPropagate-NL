nohup: ignoring input
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:107: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:30: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

12/29 10:04:58 label: default
12/29 10:04:58 description:
  default configuration
  next line of description
  last line
12/29 10:04:58 /root/icpc/icpc/translate/__main__.py config/10-folds/9_fold/hybrid_pnl/config.yaml --train -v
12/29 10:04:58 commit hash 74e0554cb3eb5df835cef993ad570ff8de651f71
12/29 10:04:58 tensorflow version: 1.14.0
12/29 10:04:58 program arguments
12/29 10:04:58   aggregation_method   'sum'
12/29 10:04:58   align_encoder_id     0
12/29 10:04:58   allow_growth         True
12/29 10:04:58   attention_type       'global'
12/29 10:04:58   attn_filter_length   0
12/29 10:04:58   attn_filters         0
12/29 10:04:58   attn_prev_word       False
12/29 10:04:58   attn_size            128
12/29 10:04:58   attn_temperature     1.0
12/29 10:04:58   attn_window_size     0
12/29 10:04:58   average              False
12/29 10:04:58   baseline_activation  None
12/29 10:04:58   baseline_learning_rate 0.001
12/29 10:04:58   baseline_optimizer   'adam'
12/29 10:04:58   baseline_steps       0
12/29 10:04:58   batch_mode           'standard'
12/29 10:04:58   batch_size           64
12/29 10:04:58   beam_size            5
12/29 10:04:58   bidir                True
12/29 10:04:58   bidir_projection     False
12/29 10:04:58   binary               False
12/29 10:04:58   cell_size            256
12/29 10:04:58   cell_type            'GRU'
12/29 10:04:58   character_level      False
12/29 10:04:58   checkpoints          []
12/29 10:04:58   conditional_rnn      False
12/29 10:04:58   config               'config/10-folds/9_fold/hybrid_pnl/config.yaml'
12/29 10:04:58   convolutions         None
12/29 10:04:58   data_dir             'data/gooddata/9_fold'
12/29 10:04:58   debug                False
12/29 10:04:58   decay_after_n_epoch  1
12/29 10:04:58   decay_every_n_epoch  1
12/29 10:04:58   decay_if_no_progress None
12/29 10:04:58   decoders             [{'max_len': 40, 'name': 'nl'}]
12/29 10:04:58   description          'default configuration\nnext line of description\nlast line\n'
12/29 10:04:58   dev_prefix           'test'
12/29 10:04:58   early_stopping       True
12/29 10:04:58   embedding_dropout    0.0
12/29 10:04:58   embedding_initializer None
12/29 10:04:58   embedding_size       256
12/29 10:04:58   embedding_weight_scale None
12/29 10:04:58   embeddings_on_cpu    True
12/29 10:04:58   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 80, 'name': 'pnl'}]
12/29 10:04:58   ensemble             False
12/29 10:04:58   eval_burn_in         0
12/29 10:04:58   feed_previous        0.0
12/29 10:04:58   final_state          'last'
12/29 10:04:58   freeze_variables     []
12/29 10:04:58   generate_first       True
12/29 10:04:58   gpu_id               2
12/29 10:04:58   highway_layers       0
12/29 10:04:58   initial_state_dropout 0.0
12/29 10:04:58   initializer          None
12/29 10:04:58   input_layer_dropout  0.0
12/29 10:04:58   input_layers         None
12/29 10:04:58   keep_best            5
12/29 10:04:58   keep_every_n_hours   0
12/29 10:04:58   label                'default'
12/29 10:04:58   layer_norm           False
12/29 10:04:58   layers               1
12/29 10:04:58   learning_rate        0.5
12/29 10:04:58   learning_rate_decay_factor 0.95
12/29 10:04:58   len_normalization    1.0
12/29 10:04:58   log_file             'log.txt'
12/29 10:04:58   loss_function        'xent'
12/29 10:04:58   max_dev_size         0
12/29 10:04:58   max_epochs           100
12/29 10:04:58   max_gradient_norm    5.0
12/29 10:04:58   max_len              50
12/29 10:04:58   max_steps            600000
12/29 10:04:58   max_test_size        0
12/29 10:04:58   max_to_keep          1
12/29 10:04:58   max_train_size       0
12/29 10:04:58   maxout_stride        None
12/29 10:04:58   mem_fraction         1.0
12/29 10:04:58   min_learning_rate    1e-06
12/29 10:04:58   model_dir            'models/9_fold_hybrid_pnl'
12/29 10:04:58   moving_average       None
12/29 10:04:58   no_gpu               False
12/29 10:04:58   optimizer            'sgd'
12/29 10:04:58   orthogonal_init      False
12/29 10:04:58   output               None
12/29 10:04:58   output_dropout       0.0
12/29 10:04:58   parallel_iterations  16
12/29 10:04:58   pervasive_dropout    False
12/29 10:04:58   pooling_avg          True
12/29 10:04:58   post_process_script  None
12/29 10:04:58   pred_deep_layer      False
12/29 10:04:58   pred_edits           False
12/29 10:04:58   pred_embed_proj      True
12/29 10:04:58   pred_maxout_layer    True
12/29 10:04:58   purge                False
12/29 10:04:58   raw_output           False
12/29 10:04:58   read_ahead           1
12/29 10:04:58   reconstruction_attn_weight 0.05
12/29 10:04:58   reconstruction_decoders False
12/29 10:04:58   reconstruction_weight 1.0
12/29 10:04:58   reinforce_after_n_epoch None
12/29 10:04:58   remove_unk           False
12/29 10:04:58   reverse              False
12/29 10:04:58   reverse_input        True
12/29 10:04:58   reward_function      'sentence_bleu'
12/29 10:04:58   rnn_feed_attn        True
12/29 10:04:58   rnn_input_dropout    0.0
12/29 10:04:58   rnn_output_dropout   0.0
12/29 10:04:58   rnn_state_dropout    0.0
12/29 10:04:58   save                 False
12/29 10:04:58   score_function       'corpus_bleu'
12/29 10:04:58   score_functions      ['bleu', 'loss']
12/29 10:04:58   script_dir           'scripts'
12/29 10:04:58   sgd_after_n_epoch    None
12/29 10:04:58   sgd_learning_rate    1.0
12/29 10:04:58   shuffle              True
12/29 10:04:58   softmax_temperature  1.0
12/29 10:04:58   steps_per_checkpoint 2000
12/29 10:04:58   steps_per_eval       2000
12/29 10:04:58   swap_memory          True
12/29 10:04:58   tie_embeddings       False
12/29 10:04:58   time_pooling         None
12/29 10:04:58   train                True
12/29 10:04:58   train_initial_states True
12/29 10:04:58   train_prefix         'train'
12/29 10:04:58   truncate_lines       True
12/29 10:04:58   update_first         False
12/29 10:04:58   use_baseline         False
12/29 10:04:58   use_dropout          False
12/29 10:04:58   use_lstm_full_state  False
12/29 10:04:58   use_previous_word    True
12/29 10:04:58   verbose              True
12/29 10:04:58   vocab_prefix         'vocab'
12/29 10:04:58   weight_scale         None
12/29 10:04:58   word_dropout         0.0
12/29 10:04:58 python random seed: 847812307029723298
12/29 10:04:58 tf random seed:     4923639167149049604
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:203: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

12/29 10:04:58 creating model
12/29 10:04:58 using device: /gpu:2
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:230: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

12/29 10:04:58 copying vocab to models/9_fold_hybrid_pnl/data/vocab.code
12/29 10:04:58 copying vocab to models/9_fold_hybrid_pnl/data/vocab.pnl
12/29 10:04:58 copying vocab to models/9_fold_hybrid_pnl/data/vocab.nl
12/29 10:04:58 reading vocabularies
12/29 10:04:58 creating model
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:33: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18385d0828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18385d0828>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:226: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18385d0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18385d0fd0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18bf020ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18bf020ba8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18bf020c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18bf020c50>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18c14d67f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18c14d67f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:838: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18becc52b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18becc52b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18becb45f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18becb45f8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:432: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:435: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18bebddf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18bebddf60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18bebddb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18bebddb38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18beaa4fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18beaa4fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18bea5ab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18bea5ab70>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be7a9ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be7a9ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be73c898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be73c898>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be7968d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be7968d0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be705b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be705b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be705b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f18be705b38>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:919: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18be609fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f18be609fd0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:10: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:131: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:223: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f185c26ff28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f185c26ff28>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c22a668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c22a668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c29ddd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c29ddd8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c1e5240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c1e5240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c1e5240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c1e5240>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c172cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c172cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c121668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c121668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c121668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f185c121668>>: AssertionError: Bad argument number for Name: 3, expecting 4
12/29 10:05:05 model parameters (45)
12/29 10:05:05   baseline_step:0 ()
12/29 10:05:05   decoder_nl/attention_code/U_a/kernel:0 (512, 128)
12/29 10:05:05   decoder_nl/attention_code/W_a/bias:0 (128,)
12/29 10:05:05   decoder_nl/attention_code/W_a/kernel:0 (256, 128)
12/29 10:05:05   decoder_nl/attention_code/v_a:0 (128,)
12/29 10:05:05   decoder_nl/attention_pnl/U_a/kernel:0 (512, 128)
12/29 10:05:05   decoder_nl/attention_pnl/W_a/bias:0 (128,)
12/29 10:05:05   decoder_nl/attention_pnl/W_a/kernel:0 (256, 128)
12/29 10:05:05   decoder_nl/attention_pnl/v_a:0 (128,)
12/29 10:05:05   decoder_nl/code_pnl/initial_state_projection/bias:0 (256,)
12/29 10:05:05   decoder_nl/code_pnl/initial_state_projection/kernel:0 (512, 256)
12/29 10:05:05   decoder_nl/gru_cell/candidate/bias:0 (256,)
12/29 10:05:05   decoder_nl/gru_cell/candidate/kernel:0 (1024, 256)
12/29 10:05:05   decoder_nl/gru_cell/gates/bias:0 (512,)
12/29 10:05:05   decoder_nl/gru_cell/gates/kernel:0 (1024, 512)
12/29 10:05:05   decoder_nl/maxout/bias:0 (256,)
12/29 10:05:05   decoder_nl/maxout/kernel:0 (1024, 256)
12/29 10:05:05   decoder_nl/softmax0/kernel:0 (128, 256)
12/29 10:05:05   decoder_nl/softmax1/bias:0 (38060,)
12/29 10:05:05   decoder_nl/softmax1/kernel:0 (256, 38060)
12/29 10:05:05   embedding_code:0 (50000, 256)
12/29 10:05:05   embedding_nl:0 (38060, 256)
12/29 10:05:05   embedding_pnl:0 (37652, 256)
12/29 10:05:05   encoder_code/initial_state_bw:0 (256,)
12/29 10:05:05   encoder_code/initial_state_fw:0 (256,)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
12/29 10:05:05   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
12/29 10:05:05   encoder_pnl/initial_state_bw:0 (256,)
12/29 10:05:05   encoder_pnl/initial_state_fw:0 (256,)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
12/29 10:05:05   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
12/29 10:05:05   global_step:0 ()
12/29 10:05:05   learning_rate:0 ()
12/29 10:05:05 number of parameters: 44.95M
WARNING:tensorflow:From /root/icpc/icpc/translate/translation_model.py:666: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

12/29 10:05:06 global step: 0
12/29 10:05:07 baseline step: 0
12/29 10:05:07 reading training data
12/29 10:05:07 total line count: 156721
12/29 10:05:12   lines read: 100000
12/29 10:05:15 files: data/gooddata/9_fold/train.code data/gooddata/9_fold/train.pnl data/gooddata/9_fold/train.nl
12/29 10:05:15 lines reads: 156721
12/29 10:05:15 reading development data
12/29 10:05:16 files: data/gooddata/9_fold/test.code data/gooddata/9_fold/test.pnl data/gooddata/9_fold/test.nl
12/29 10:05:16 lines reads: 17413
12/29 10:05:16 starting training
12/29 10:32:24 step 2000 epoch 1 learning rate 0.5 step-time 0.812 loss 82.139
12/29 10:32:24 starting evaluation
12/29 10:37:18 test bleu=0.87 loss=66.95 penalty=0.875 ratio=0.882
12/29 10:37:18 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 10:37:18 finished saving model
12/29 10:37:18 new best model
12/29 10:43:24   decaying learning rate to: 0.475
12/29 11:04:13 step 4000 epoch 2 learning rate 0.475 step-time 0.805 loss 59.623
12/29 11:04:13 starting evaluation
12/29 11:08:43 test bleu=5.20 loss=55.68 penalty=0.706 ratio=0.742
12/29 11:08:43 saving model to models/9_fold_hybrid_pnl/checkpoints
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
12/29 11:08:43 finished saving model
12/29 11:08:43 new best model
12/29 11:20:51   decaying learning rate to: 0.451
12/29 11:35:47 step 6000 epoch 3 learning rate 0.451 step-time 0.810 loss 52.322
12/29 11:35:47 starting evaluation
12/29 11:40:39 test bleu=8.00 loss=50.04 penalty=0.715 ratio=0.749
12/29 11:40:39 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 11:40:39 finished saving model
12/29 11:40:39 new best model
12/29 11:58:42   decaying learning rate to: 0.429
12/29 12:07:42 step 8000 epoch 4 learning rate 0.429 step-time 0.809 loss 46.746
12/29 12:07:42 starting evaluation
12/29 12:12:42 test bleu=7.11 loss=47.25 penalty=1.000 ratio=1.813
12/29 12:12:42 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 12:12:43 finished saving model
12/29 12:37:01   decaying learning rate to: 0.407
12/29 12:39:46 step 10000 epoch 5 learning rate 0.407 step-time 0.810 loss 42.649
12/29 12:39:46 starting evaluation
12/29 12:44:46 test bleu=15.43 loss=43.32 penalty=0.918 ratio=0.921
12/29 12:44:46 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 12:44:46 finished saving model
12/29 12:44:46 new best model
12/29 13:11:47 step 12000 epoch 5 learning rate 0.407 step-time 0.808 loss 39.106
12/29 13:11:47 starting evaluation
12/29 13:16:46 test bleu=19.00 loss=41.09 penalty=0.944 ratio=0.946
12/29 13:16:46 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 13:16:47 finished saving model
12/29 13:16:47 new best model
12/29 13:20:01   decaying learning rate to: 0.387
12/29 13:43:44 step 14000 epoch 6 learning rate 0.387 step-time 0.807 loss 35.959
12/29 13:43:44 starting evaluation
12/29 13:48:32 test bleu=19.79 loss=39.78 penalty=0.802 ratio=0.819
12/29 13:48:32 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 13:48:32 finished saving model
12/29 13:48:32 new best model
12/29 13:57:58   decaying learning rate to: 0.368
12/29 14:15:33 step 16000 epoch 7 learning rate 0.368 step-time 0.808 loss 33.521
12/29 14:15:33 starting evaluation
12/29 14:20:26 test bleu=22.08 loss=38.44 penalty=0.855 ratio=0.865
12/29 14:20:26 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 14:20:26 finished saving model
12/29 14:20:26 new best model
12/29 14:35:59   decaying learning rate to: 0.349
12/29 14:47:28 step 18000 epoch 8 learning rate 0.349 step-time 0.809 loss 31.228
12/29 14:47:28 starting evaluation
12/29 14:52:19 test bleu=24.01 loss=37.82 penalty=0.927 ratio=0.930
12/29 14:52:19 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 14:52:20 finished saving model
12/29 14:52:20 new best model
12/29 15:13:52   decaying learning rate to: 0.332
12/29 15:19:19 step 20000 epoch 9 learning rate 0.332 step-time 0.807 loss 29.253
12/29 15:19:19 starting evaluation
12/29 15:24:14 test bleu=24.90 loss=37.34 penalty=0.808 ratio=0.825
12/29 15:24:14 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 15:24:14 finished saving model
12/29 15:24:14 new best model
12/29 15:51:21 step 22000 epoch 9 learning rate 0.332 step-time 0.811 loss 27.381
12/29 15:51:21 starting evaluation
12/29 15:56:16 test bleu=26.11 loss=36.61 penalty=0.872 ratio=0.879
12/29 15:56:16 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 15:56:16 finished saving model
12/29 15:56:16 new best model
12/29 15:56:51   decaying learning rate to: 0.315
12/29 16:23:20 step 24000 epoch 10 learning rate 0.315 step-time 0.810 loss 24.657
12/29 16:23:20 starting evaluation
12/29 16:28:12 test bleu=27.66 loss=36.99 penalty=0.870 ratio=0.878
12/29 16:28:12 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 16:28:12 finished saving model
12/29 16:28:12 new best model
12/29 16:34:47   decaying learning rate to: 0.299
12/29 16:55:18 step 26000 epoch 11 learning rate 0.299 step-time 0.811 loss 22.879
12/29 16:55:18 starting evaluation
12/29 17:00:13 test bleu=28.61 loss=37.09 penalty=0.892 ratio=0.897
12/29 17:00:13 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 17:00:13 finished saving model
12/29 17:00:13 new best model
12/29 17:12:48   decaying learning rate to: 0.284
12/29 17:27:16 step 28000 epoch 12 learning rate 0.284 step-time 0.809 loss 21.286
12/29 17:27:16 starting evaluation
12/29 17:32:12 test bleu=29.28 loss=38.24 penalty=0.904 ratio=0.908
12/29 17:32:12 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 17:32:12 finished saving model
12/29 17:32:12 new best model
12/29 17:51:02   decaying learning rate to: 0.27
12/29 17:59:16 step 30000 epoch 13 learning rate 0.27 step-time 0.810 loss 19.698
12/29 17:59:16 starting evaluation
12/29 18:04:05 test bleu=29.24 loss=39.23 penalty=0.858 ratio=0.867
12/29 18:04:05 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 18:04:06 finished saving model
12/29 18:29:00   decaying learning rate to: 0.257
12/29 18:31:11 step 32000 epoch 14 learning rate 0.257 step-time 0.811 loss 18.250
12/29 18:31:11 starting evaluation
12/29 18:35:52 test bleu=30.55 loss=39.47 penalty=0.855 ratio=0.864
12/29 18:35:52 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 18:35:52 finished saving model
12/29 18:35:52 new best model
12/29 19:03:02 step 34000 epoch 14 learning rate 0.257 step-time 0.813 loss 16.354
12/29 19:03:02 starting evaluation
12/29 19:07:49 test bleu=30.36 loss=39.23 penalty=0.906 ratio=0.910
12/29 19:07:49 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 19:07:49 finished saving model
12/29 19:11:40   decaying learning rate to: 0.244
12/29 19:34:47 step 36000 epoch 15 learning rate 0.244 step-time 0.807 loss 14.621
12/29 19:34:47 starting evaluation
12/29 19:39:47 test bleu=31.04 loss=40.99 penalty=0.898 ratio=0.903
12/29 19:39:47 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 19:39:47 finished saving model
12/29 19:39:47 new best model
12/29 19:49:46   decaying learning rate to: 0.232
12/29 20:06:59 step 38000 epoch 16 learning rate 0.232 step-time 0.813 loss 13.531
12/29 20:06:59 starting evaluation
12/29 20:11:51 test bleu=31.92 loss=42.13 penalty=0.899 ratio=0.904
12/29 20:11:51 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 20:11:51 finished saving model
12/29 20:11:51 new best model
12/29 20:27:47   decaying learning rate to: 0.22
12/29 20:38:54 step 40000 epoch 17 learning rate 0.22 step-time 0.809 loss 12.307
12/29 20:38:54 starting evaluation
12/29 20:43:50 test bleu=32.73 loss=44.04 penalty=0.966 ratio=0.966
12/29 20:43:50 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 20:43:51 finished saving model
12/29 20:43:51 new best model
12/29 21:06:00   decaying learning rate to: 0.209
12/29 21:10:57 step 42000 epoch 18 learning rate 0.209 step-time 0.811 loss 11.317
12/29 21:10:57 starting evaluation
12/29 21:15:53 test bleu=32.84 loss=46.16 penalty=0.919 ratio=0.922
12/29 21:15:53 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 21:15:53 finished saving model
12/29 21:15:53 new best model
12/29 21:42:59 step 44000 epoch 18 learning rate 0.209 step-time 0.811 loss 10.204
12/29 21:42:59 starting evaluation
12/29 21:47:55 test bleu=33.14 loss=45.47 penalty=0.961 ratio=0.962
12/29 21:47:55 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 21:47:55 finished saving model
12/29 21:47:55 new best model
12/29 21:49:02   decaying learning rate to: 0.199
12/29 22:15:10 step 46000 epoch 19 learning rate 0.199 step-time 0.815 loss 8.695
12/29 22:15:10 starting evaluation
12/29 22:20:06 test bleu=33.52 loss=48.06 penalty=0.945 ratio=0.946
12/29 22:20:06 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 22:20:06 finished saving model
12/29 22:20:06 new best model
12/29 22:27:21   decaying learning rate to: 0.189
12/29 22:47:12 step 48000 epoch 20 learning rate 0.189 step-time 0.811 loss 7.896
12/29 22:47:12 starting evaluation
12/29 22:51:57 test bleu=34.06 loss=50.71 penalty=0.985 ratio=0.985
12/29 22:51:57 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 22:51:57 finished saving model
12/29 22:51:57 new best model
12/29 23:05:20   decaying learning rate to: 0.179
12/29 23:19:03 step 50000 epoch 21 learning rate 0.179 step-time 0.811 loss 7.195
12/29 23:19:03 starting evaluation
12/29 23:23:55 test bleu=33.99 loss=52.93 penalty=0.973 ratio=0.974
12/29 23:23:55 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 23:23:55 finished saving model
12/29 23:43:16   decaying learning rate to: 0.17
12/29 23:50:54 step 52000 epoch 22 learning rate 0.17 step-time 0.807 loss 6.486
12/29 23:50:54 starting evaluation
12/29 23:55:48 test bleu=34.51 loss=54.80 penalty=0.981 ratio=0.981
12/29 23:55:48 saving model to models/9_fold_hybrid_pnl/checkpoints
12/29 23:55:49 finished saving model
12/29 23:55:49 new best model
12/30 00:20:39   decaying learning rate to: 0.162
12/30 00:22:16 step 54000 epoch 23 learning rate 0.162 step-time 0.792 loss 5.883
12/30 00:22:16 starting evaluation
12/30 00:27:07 test bleu=34.48 loss=57.78 penalty=0.949 ratio=0.950
12/30 00:27:07 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 00:27:08 finished saving model
12/30 00:53:32 step 56000 epoch 23 learning rate 0.162 step-time 0.790 loss 4.964
12/30 00:53:32 starting evaluation
12/30 00:58:24 test bleu=34.98 loss=58.11 penalty=0.949 ratio=0.950
12/30 00:58:24 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 00:58:24 finished saving model
12/30 00:58:24 new best model
12/30 01:02:38   decaying learning rate to: 0.154
12/30 01:24:51 step 58000 epoch 24 learning rate 0.154 step-time 0.791 loss 4.428
12/30 01:24:51 starting evaluation
12/30 01:29:43 test bleu=34.84 loss=61.72 penalty=0.977 ratio=0.977
12/30 01:29:43 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 01:29:44 finished saving model
12/30 01:39:52   decaying learning rate to: 0.146
12/30 01:56:08 step 60000 epoch 25 learning rate 0.146 step-time 0.790 loss 4.000
12/30 01:56:08 starting evaluation
12/30 02:01:01 test bleu=35.52 loss=63.77 penalty=0.980 ratio=0.980
12/30 02:01:01 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 02:01:01 finished saving model
12/30 02:01:01 new best model
12/30 02:17:15   decaying learning rate to: 0.139
12/30 02:27:24 step 62000 epoch 26 learning rate 0.139 step-time 0.789 loss 3.573
12/30 02:27:24 starting evaluation
12/30 02:32:18 test bleu=34.39 loss=66.72 penalty=1.000 ratio=1.028
12/30 02:32:18 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 02:32:18 finished saving model
12/30 02:54:16   decaying learning rate to: 0.132
12/30 02:58:30 step 64000 epoch 27 learning rate 0.132 step-time 0.784 loss 3.260
12/30 02:58:30 starting evaluation
12/30 03:03:24 test bleu=35.18 loss=68.15 penalty=1.000 ratio=1.014
12/30 03:03:24 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 03:03:24 finished saving model
12/30 03:30:23 step 66000 epoch 27 learning rate 0.132 step-time 0.807 loss 2.876
12/30 03:30:23 starting evaluation
12/30 03:35:13 test bleu=35.74 loss=70.30 penalty=0.996 ratio=0.996
12/30 03:35:13 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 03:35:13 finished saving model
12/30 03:35:13 new best model
12/30 03:36:53   decaying learning rate to: 0.125
12/30 04:02:18 step 68000 epoch 28 learning rate 0.125 step-time 0.810 loss 2.426
12/30 04:02:18 starting evaluation
12/30 04:07:25 test bleu=35.05 loss=72.54 penalty=1.000 ratio=1.028
12/30 04:07:25 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 04:07:25 finished saving model
12/30 04:14:59   decaying learning rate to: 0.119
12/30 04:34:22 step 70000 epoch 29 learning rate 0.119 step-time 0.807 loss 2.204
12/30 04:34:22 starting evaluation
12/30 04:39:22 test bleu=34.79 loss=74.68 penalty=1.000 ratio=1.036
12/30 04:39:22 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 04:39:22 finished saving model
12/30 04:53:00   decaying learning rate to: 0.113
12/30 05:06:19 step 72000 epoch 30 learning rate 0.113 step-time 0.807 loss 2.003
12/30 05:06:19 starting evaluation
12/30 05:11:18 test bleu=35.86 loss=77.13 penalty=1.000 ratio=1.007
12/30 05:11:18 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 05:11:18 finished saving model
12/30 05:11:18 new best model
12/30 05:31:06   decaying learning rate to: 0.107
12/30 05:38:18 step 74000 epoch 31 learning rate 0.107 step-time 0.808 loss 1.828
12/30 05:38:18 starting evaluation
12/30 05:43:17 test bleu=36.03 loss=79.83 penalty=0.998 ratio=0.998
12/30 05:43:17 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 05:43:17 finished saving model
12/30 05:43:17 new best model
12/30 06:09:15   decaying learning rate to: 0.102
12/30 06:10:20 step 76000 epoch 32 learning rate 0.102 step-time 0.809 loss 1.671
12/30 06:10:20 starting evaluation
12/30 06:15:19 test bleu=35.68 loss=80.56 penalty=1.000 ratio=1.026
12/30 06:15:19 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 06:15:19 finished saving model
12/30 06:42:22 step 78000 epoch 32 learning rate 0.102 step-time 0.810 loss 1.410
12/30 06:42:22 starting evaluation
12/30 06:47:22 test bleu=36.08 loss=82.78 penalty=1.000 ratio=1.015
12/30 06:47:22 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 06:47:22 finished saving model
12/30 06:47:22 new best model
12/30 06:52:20   decaying learning rate to: 0.0969
12/30 07:14:35 step 80000 epoch 33 learning rate 0.0969 step-time 0.814 loss 1.278
12/30 07:14:35 starting evaluation
12/30 07:19:25 test bleu=36.80 loss=85.00 penalty=0.986 ratio=0.986
12/30 07:19:25 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 07:19:25 finished saving model
12/30 07:19:25 new best model
12/30 07:30:50   decaying learning rate to: 0.092
12/30 07:50:10 step 82000 epoch 34 learning rate 0.092 step-time 0.920 loss 1.180
12/30 07:50:10 starting evaluation
12/30 07:55:40 test bleu=35.57 loss=87.30 penalty=1.000 ratio=1.027
12/30 07:55:40 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 07:55:40 finished saving model
12/30 08:16:26   decaying learning rate to: 0.0874
12/30 08:28:37 step 84000 epoch 35 learning rate 0.0874 step-time 0.985 loss 1.083
12/30 08:28:37 starting evaluation
12/30 08:34:02 test bleu=36.54 loss=89.14 penalty=1.000 ratio=1.006
12/30 08:34:02 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 08:34:03 finished saving model
12/30 09:00:43   decaying learning rate to: 0.083
12/30 09:04:55 step 86000 epoch 36 learning rate 0.083 step-time 0.924 loss 1.008
12/30 09:04:55 starting evaluation
12/30 09:09:52 test bleu=36.78 loss=90.24 penalty=1.000 ratio=1.001
12/30 09:09:52 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 09:09:52 finished saving model
12/30 09:37:02 step 88000 epoch 36 learning rate 0.083 step-time 0.813 loss 0.909
12/30 09:37:02 starting evaluation
12/30 09:42:01 test bleu=36.66 loss=91.17 penalty=1.000 ratio=1.006
12/30 09:42:01 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 09:42:01 finished saving model
12/30 09:44:13   decaying learning rate to: 0.0789
12/30 10:09:11 step 90000 epoch 37 learning rate 0.0789 step-time 0.813 loss 0.798
12/30 10:09:11 starting evaluation
12/30 10:14:01 test bleu=36.84 loss=92.41 penalty=0.990 ratio=0.990
12/30 10:14:01 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 10:14:01 finished saving model
12/30 10:14:01 new best model
12/30 10:22:28   decaying learning rate to: 0.0749
12/30 10:41:18 step 92000 epoch 38 learning rate 0.0749 step-time 0.816 loss 0.752
12/30 10:41:18 starting evaluation
12/30 10:46:10 test bleu=36.30 loss=94.12 penalty=1.000 ratio=1.024
12/30 10:46:10 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 10:46:10 finished saving model
12/30 11:00:30   decaying learning rate to: 0.0712
12/30 11:13:19 step 94000 epoch 39 learning rate 0.0712 step-time 0.813 loss 0.701
12/30 11:13:19 starting evaluation
12/30 11:18:21 test bleu=37.16 loss=95.13 penalty=1.000 ratio=1.004
12/30 11:18:21 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 11:18:22 finished saving model
12/30 11:18:22 new best model
12/30 11:38:47   decaying learning rate to: 0.0676
12/30 11:45:38 step 96000 epoch 40 learning rate 0.0676 step-time 0.816 loss 0.657
12/30 11:45:38 starting evaluation
12/30 11:50:33 test bleu=36.91 loss=95.75 penalty=1.000 ratio=1.008
12/30 11:50:33 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 11:50:33 finished saving model
12/30 12:17:17   decaying learning rate to: 0.0643
12/30 12:17:50 step 98000 epoch 41 learning rate 0.0643 step-time 0.816 loss 0.630
12/30 12:17:50 starting evaluation
12/30 12:22:47 test bleu=36.04 loss=97.07 penalty=1.000 ratio=1.035
12/30 12:22:47 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 12:22:47 finished saving model
12/30 12:50:05 step 100000 epoch 41 learning rate 0.0643 step-time 0.817 loss 0.552
12/30 12:50:05 starting evaluation
12/30 12:55:02 test bleu=37.35 loss=97.39 penalty=0.990 ratio=0.990
12/30 12:55:02 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 12:55:02 finished saving model
12/30 12:55:02 new best model
12/30 13:00:37   decaying learning rate to: 0.061
12/30 13:22:17 step 102000 epoch 42 learning rate 0.061 step-time 0.815 loss 0.521
12/30 13:22:17 starting evaluation
12/30 13:27:16 test bleu=37.17 loss=98.48 penalty=1.000 ratio=1.009
12/30 13:27:16 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 13:27:16 finished saving model
12/30 13:39:02   decaying learning rate to: 0.058
12/30 13:54:27 step 104000 epoch 43 learning rate 0.058 step-time 0.813 loss 0.501
12/30 13:54:27 starting evaluation
12/30 13:59:25 test bleu=37.25 loss=99.47 penalty=1.000 ratio=1.005
12/30 13:59:25 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 13:59:25 finished saving model
12/30 14:17:07   decaying learning rate to: 0.0551
12/30 14:26:32 step 106000 epoch 44 learning rate 0.0551 step-time 0.812 loss 0.474
12/30 14:26:32 starting evaluation
12/30 14:31:19 test bleu=37.37 loss=99.52 penalty=0.998 ratio=0.998
12/30 14:31:19 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 14:31:20 finished saving model
12/30 14:31:20 new best model
12/30 14:55:06   decaying learning rate to: 0.0523
12/30 14:58:22 step 108000 epoch 45 learning rate 0.0523 step-time 0.809 loss 0.458
12/30 14:58:22 starting evaluation
12/30 15:03:29 test bleu=36.53 loss=99.97 penalty=1.000 ratio=1.026
12/30 15:03:29 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 15:03:30 finished saving model
12/30 15:30:37 step 110000 epoch 45 learning rate 0.0523 step-time 0.812 loss 0.419
12/30 15:30:37 starting evaluation
12/30 15:35:34 test bleu=37.53 loss=101.84 penalty=0.992 ratio=0.992
12/30 15:35:34 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 15:35:34 finished saving model
12/30 15:35:34 new best model
12/30 15:38:18   decaying learning rate to: 0.0497
12/30 16:02:44 step 112000 epoch 46 learning rate 0.0497 step-time 0.813 loss 0.391
12/30 16:02:44 starting evaluation
12/30 16:07:41 test bleu=36.39 loss=101.42 penalty=1.000 ratio=1.039
12/30 16:07:41 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 16:07:41 finished saving model
12/30 16:16:27   decaying learning rate to: 0.0472
12/30 16:34:50 step 114000 epoch 47 learning rate 0.0472 step-time 0.813 loss 0.371
12/30 16:34:50 starting evaluation
12/30 16:39:47 test bleu=37.04 loss=101.80 penalty=1.000 ratio=1.017
12/30 16:39:47 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 16:39:48 finished saving model
12/30 16:54:52   decaying learning rate to: 0.0449
12/30 17:06:53 step 116000 epoch 48 learning rate 0.0449 step-time 0.811 loss 0.355
12/30 17:06:53 starting evaluation
12/30 17:11:52 test bleu=37.69 loss=102.08 penalty=0.998 ratio=0.998
12/30 17:11:52 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 17:11:52 finished saving model
12/30 17:11:52 new best model
12/30 17:32:51   decaying learning rate to: 0.0426
12/30 17:38:55 step 118000 epoch 49 learning rate 0.0426 step-time 0.809 loss 0.337
12/30 17:38:55 starting evaluation
12/30 17:43:54 test bleu=37.69 loss=102.18 penalty=0.999 ratio=0.999
12/30 17:43:54 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 17:43:54 finished saving model
12/30 18:11:01 step 120000 epoch 50 learning rate 0.0426 step-time 0.811 loss 0.320
12/30 18:11:01 starting evaluation
12/30 18:15:52 test bleu=37.12 loss=102.22 penalty=1.000 ratio=1.018
12/30 18:15:52 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 18:15:52 finished saving model
12/30 18:15:53   decaying learning rate to: 0.0405
12/30 18:42:56 step 122000 epoch 50 learning rate 0.0405 step-time 0.810 loss 0.286
12/30 18:42:56 starting evaluation
12/30 18:47:48 test bleu=37.60 loss=101.53 penalty=1.000 ratio=1.008
12/30 18:47:48 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 18:47:48 finished saving model
12/30 18:53:52   decaying learning rate to: 0.0385
12/30 19:14:56 step 124000 epoch 51 learning rate 0.0385 step-time 0.812 loss 0.270
12/30 19:14:56 starting evaluation
12/30 19:20:00 test bleu=37.53 loss=102.56 penalty=1.000 ratio=1.009
12/30 19:20:00 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 19:20:00 finished saving model
12/30 19:32:01   decaying learning rate to: 0.0365
12/30 19:47:06 step 126000 epoch 52 learning rate 0.0365 step-time 0.811 loss 0.258
12/30 19:47:06 starting evaluation
12/30 19:52:05 test bleu=37.07 loss=102.13 penalty=1.000 ratio=1.022
12/30 19:52:05 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 19:52:05 finished saving model
12/30 20:10:16   decaying learning rate to: 0.0347
12/30 20:19:15 step 128000 epoch 53 learning rate 0.0347 step-time 0.813 loss 0.250
12/30 20:19:15 starting evaluation
12/30 20:24:09 test bleu=37.97 loss=102.73 penalty=1.000 ratio=1.001
12/30 20:24:09 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 20:24:10 finished saving model
12/30 20:24:10 new best model
12/30 20:48:34   decaying learning rate to: 0.033
12/30 20:51:18 step 130000 epoch 54 learning rate 0.033 step-time 0.812 loss 0.238
12/30 20:51:18 starting evaluation
12/30 20:56:16 test bleu=37.89 loss=102.82 penalty=1.000 ratio=1.006
12/30 20:56:16 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 20:56:16 finished saving model
12/30 21:23:27 step 132000 epoch 54 learning rate 0.033 step-time 0.814 loss 0.220
12/30 21:23:27 starting evaluation
12/30 21:28:25 test bleu=38.11 loss=102.20 penalty=0.992 ratio=0.992
12/30 21:28:25 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 21:28:25 finished saving model
12/30 21:28:25 new best model
12/30 21:31:45   decaying learning rate to: 0.0313
12/30 21:55:33 step 134000 epoch 55 learning rate 0.0313 step-time 0.812 loss 0.206
12/30 21:55:33 starting evaluation
12/30 22:00:32 test bleu=37.89 loss=102.38 penalty=1.000 ratio=1.003
12/30 22:00:32 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 22:00:32 finished saving model
12/30 22:10:02   decaying learning rate to: 0.0298
12/30 22:27:40 step 136000 epoch 56 learning rate 0.0298 step-time 0.812 loss 0.199
12/30 22:27:40 starting evaluation
12/30 22:32:28 test bleu=37.85 loss=102.60 penalty=1.000 ratio=1.005
12/30 22:32:28 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 22:32:28 finished saving model
12/30 22:47:57   decaying learning rate to: 0.0283
12/30 22:59:28 step 138000 epoch 57 learning rate 0.0283 step-time 0.808 loss 0.191
12/30 22:59:28 starting evaluation
12/30 23:04:30 test bleu=38.03 loss=102.28 penalty=1.000 ratio=1.003
12/30 23:04:30 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 23:04:30 finished saving model
12/30 23:25:58   decaying learning rate to: 0.0269
12/30 23:31:37 step 140000 epoch 58 learning rate 0.0269 step-time 0.811 loss 0.185
12/30 23:31:37 starting evaluation
12/30 23:36:37 test bleu=37.46 loss=102.78 penalty=1.000 ratio=1.016
12/30 23:36:37 saving model to models/9_fold_hybrid_pnl/checkpoints
12/30 23:36:37 finished saving model
12/31 00:03:44 step 142000 epoch 58 learning rate 0.0269 step-time 0.811 loss 0.180
12/31 00:03:44 starting evaluation
12/31 00:08:44 test bleu=37.41 loss=102.25 penalty=1.000 ratio=1.017
12/31 00:08:44 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 00:08:44 finished saving model
12/31 00:09:18   decaying learning rate to: 0.0255
12/31 00:32:26 step 144000 epoch 59 learning rate 0.0255 step-time 0.709 loss 0.161
12/31 00:32:26 starting evaluation
12/31 00:35:56 test bleu=37.64 loss=102.48 penalty=1.000 ratio=1.009
12/31 00:35:56 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 00:35:56 finished saving model
12/31 00:41:38   decaying learning rate to: 0.0242
12/31 00:59:30 step 146000 epoch 60 learning rate 0.0242 step-time 0.705 loss 0.156
12/31 00:59:30 starting evaluation
12/31 01:03:03 test bleu=37.80 loss=102.77 penalty=1.000 ratio=1.009
12/31 01:03:03 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 01:03:03 finished saving model
12/31 01:14:05   decaying learning rate to: 0.023
12/31 01:26:33 step 148000 epoch 61 learning rate 0.023 step-time 0.703 loss 0.153
12/31 01:26:33 starting evaluation
12/31 01:30:06 test bleu=38.17 loss=103.46 penalty=1.000 ratio=1.001
12/31 01:30:06 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 01:30:06 finished saving model
12/31 01:30:06 new best model
12/31 01:46:23   decaying learning rate to: 0.0219
12/31 01:53:33 step 150000 epoch 62 learning rate 0.0219 step-time 0.701 loss 0.149
12/31 01:53:33 starting evaluation
12/31 01:57:07 test bleu=38.15 loss=102.83 penalty=1.000 ratio=1.002
12/31 01:57:07 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 01:57:07 finished saving model
12/31 02:18:41   decaying learning rate to: 0.0208
12/31 02:20:37 step 152000 epoch 63 learning rate 0.0208 step-time 0.703 loss 0.147
12/31 02:20:37 starting evaluation
12/31 02:24:07 test bleu=37.98 loss=103.31 penalty=1.000 ratio=1.005
12/31 02:24:07 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 02:24:08 finished saving model
12/31 02:47:45 step 154000 epoch 63 learning rate 0.0208 step-time 0.707 loss 0.137
12/31 02:47:45 starting evaluation
12/31 02:51:17 test bleu=37.71 loss=103.11 penalty=1.000 ratio=1.012
12/31 02:51:17 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 02:51:17 finished saving model
12/31 02:54:39   decaying learning rate to: 0.0197
12/31 03:14:51 step 156000 epoch 64 learning rate 0.0197 step-time 0.705 loss 0.129
12/31 03:14:51 starting evaluation
12/31 03:18:23 test bleu=37.27 loss=103.47 penalty=1.000 ratio=1.023
12/31 03:18:23 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 03:18:23 finished saving model
12/31 03:27:04   decaying learning rate to: 0.0188
12/31 03:42:02 step 158000 epoch 65 learning rate 0.0188 step-time 0.708 loss 0.125
12/31 03:42:02 starting evaluation
12/31 03:45:35 test bleu=37.76 loss=103.70 penalty=1.000 ratio=1.010
12/31 03:45:35 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 03:45:35 finished saving model
12/31 03:59:32   decaying learning rate to: 0.0178
12/31 04:09:11 step 160000 epoch 66 learning rate 0.0178 step-time 0.706 loss 0.129
12/31 04:09:11 starting evaluation
12/31 04:12:44 test bleu=37.85 loss=103.82 penalty=1.000 ratio=1.010
12/31 04:12:44 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 04:12:44 finished saving model
12/31 04:32:02   decaying learning rate to: 0.0169
12/31 04:36:23 step 162000 epoch 67 learning rate 0.0169 step-time 0.707 loss 0.122
12/31 04:36:23 starting evaluation
12/31 04:39:54 test bleu=38.07 loss=103.83 penalty=1.000 ratio=1.002
12/31 04:39:54 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 04:39:54 finished saving model
12/31 05:03:19 step 164000 epoch 67 learning rate 0.0169 step-time 0.700 loss 0.120
12/31 05:03:19 starting evaluation
12/31 05:06:49 test bleu=37.75 loss=103.73 penalty=1.000 ratio=1.011
12/31 05:06:49 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 05:06:49 finished saving model
12/31 05:07:48   decaying learning rate to: 0.0161
12/31 05:30:24 step 166000 epoch 68 learning rate 0.0161 step-time 0.705 loss 0.109
12/31 05:30:24 starting evaluation
12/31 05:33:54 test bleu=37.98 loss=104.19 penalty=1.000 ratio=1.003
12/31 05:33:54 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 05:33:54 finished saving model
12/31 05:40:14   decaying learning rate to: 0.0153
12/31 05:57:35 step 168000 epoch 69 learning rate 0.0153 step-time 0.709 loss 0.111
12/31 05:57:35 starting evaluation
12/31 06:01:07 test bleu=37.88 loss=104.14 penalty=1.000 ratio=1.009
12/31 06:01:07 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 06:01:07 finished saving model
12/31 06:12:43   decaying learning rate to: 0.0145
12/31 06:24:45 step 170000 epoch 70 learning rate 0.0145 step-time 0.707 loss 0.106
12/31 06:24:45 starting evaluation
12/31 06:28:16 test bleu=38.08 loss=104.37 penalty=1.000 ratio=1.005
12/31 06:28:16 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 06:28:17 finished saving model
12/31 06:45:17   decaying learning rate to: 0.0138
12/31 06:52:04 step 172000 epoch 71 learning rate 0.0138 step-time 0.712 loss 0.107
12/31 06:52:04 starting evaluation
12/31 06:55:36 test bleu=37.95 loss=104.91 penalty=1.000 ratio=1.007
12/31 06:55:36 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 06:55:37 finished saving model
12/31 07:17:55   decaying learning rate to: 0.0131
12/31 07:19:19 step 174000 epoch 72 learning rate 0.0131 step-time 0.709 loss 0.104
12/31 07:19:19 starting evaluation
12/31 07:22:49 test bleu=37.68 loss=104.54 penalty=1.000 ratio=1.011
12/31 07:22:49 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 07:22:49 finished saving model
12/31 07:46:34 step 176000 epoch 72 learning rate 0.0131 step-time 0.710 loss 0.098
12/31 07:46:34 starting evaluation
12/31 07:50:01 test bleu=38.14 loss=104.60 penalty=1.000 ratio=1.002
12/31 07:50:01 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 07:50:02 finished saving model
12/31 07:53:56   decaying learning rate to: 0.0124
12/31 08:13:49 step 178000 epoch 73 learning rate 0.0124 step-time 0.711 loss 0.097
12/31 08:13:49 starting evaluation
12/31 08:17:22 test bleu=37.65 loss=104.78 penalty=1.000 ratio=1.013
12/31 08:17:22 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 08:17:22 finished saving model
12/31 08:26:35   decaying learning rate to: 0.0118
12/31 08:41:02 step 180000 epoch 74 learning rate 0.0118 step-time 0.708 loss 0.095
12/31 08:41:02 starting evaluation
12/31 08:44:32 test bleu=38.17 loss=105.17 penalty=0.997 ratio=0.997
12/31 08:44:32 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 08:44:32 finished saving model
12/31 08:44:32 new best model
12/31 08:59:09   decaying learning rate to: 0.0112
12/31 09:08:14 step 182000 epoch 75 learning rate 0.0112 step-time 0.709 loss 0.094
12/31 09:08:14 starting evaluation
12/31 09:11:49 test bleu=37.60 loss=105.31 penalty=1.000 ratio=1.014
12/31 09:11:49 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 09:11:49 finished saving model
12/31 09:31:33   decaying learning rate to: 0.0107
12/31 09:35:28 step 184000 epoch 76 learning rate 0.0107 step-time 0.707 loss 0.093
12/31 09:35:28 starting evaluation
12/31 09:39:00 test bleu=38.21 loss=105.22 penalty=0.994 ratio=0.994
12/31 09:39:00 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 09:39:00 finished saving model
12/31 09:39:00 new best model
12/31 10:02:38 step 186000 epoch 76 learning rate 0.0107 step-time 0.707 loss 0.090
12/31 10:02:38 starting evaluation
12/31 10:06:15 test bleu=38.29 loss=105.61 penalty=0.994 ratio=0.994
12/31 10:06:15 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 10:06:15 finished saving model
12/31 10:06:15 new best model
12/31 10:07:44   decaying learning rate to: 0.0101
12/31 10:29:52 step 188000 epoch 77 learning rate 0.0101 step-time 0.706 loss 0.086
12/31 10:29:52 starting evaluation
12/31 10:33:27 test bleu=38.30 loss=105.69 penalty=0.997 ratio=0.997
12/31 10:33:27 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 10:33:27 finished saving model
12/31 10:33:27 new best model
12/31 10:40:16   decaying learning rate to: 0.00963
12/31 10:57:04 step 190000 epoch 78 learning rate 0.00963 step-time 0.707 loss 0.083
12/31 10:57:04 starting evaluation
12/31 11:00:39 test bleu=37.88 loss=105.73 penalty=1.000 ratio=1.008
12/31 11:00:39 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 11:00:39 finished saving model
12/31 11:12:48   decaying learning rate to: 0.00915
12/31 11:24:14 step 192000 epoch 79 learning rate 0.00915 step-time 0.706 loss 0.084
12/31 11:24:14 starting evaluation
12/31 11:27:48 test bleu=38.26 loss=105.86 penalty=0.997 ratio=0.997
12/31 11:27:48 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 11:27:48 finished saving model
12/31 11:45:19   decaying learning rate to: 0.00869
12/31 11:51:31 step 194000 epoch 80 learning rate 0.00869 step-time 0.709 loss 0.084
12/31 11:51:31 starting evaluation
12/31 11:55:04 test bleu=37.97 loss=106.18 penalty=1.000 ratio=1.006
12/31 11:55:04 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 11:55:04 finished saving model
12/31 12:17:45   decaying learning rate to: 0.00826
12/31 12:18:40 step 196000 epoch 81 learning rate 0.00826 step-time 0.706 loss 0.083
12/31 12:18:40 starting evaluation
12/31 12:22:13 test bleu=37.99 loss=105.89 penalty=1.000 ratio=1.007
12/31 12:22:13 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 12:22:13 finished saving model
12/31 12:45:54 step 198000 epoch 81 learning rate 0.00826 step-time 0.708 loss 0.078
12/31 12:45:54 starting evaluation
12/31 12:49:25 test bleu=38.14 loss=106.22 penalty=1.000 ratio=1.002
12/31 12:49:25 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 12:49:25 finished saving model
12/31 12:53:49   decaying learning rate to: 0.00784
12/31 13:13:07 step 200000 epoch 82 learning rate 0.00784 step-time 0.709 loss 0.077
12/31 13:13:07 starting evaluation
12/31 13:16:39 test bleu=38.23 loss=106.38 penalty=0.999 ratio=0.999
12/31 13:16:39 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 13:16:39 finished saving model
12/31 13:26:17   decaying learning rate to: 0.00745
12/31 13:40:18 step 202000 epoch 83 learning rate 0.00745 step-time 0.707 loss 0.078
12/31 13:40:18 starting evaluation
12/31 13:43:52 test bleu=38.05 loss=106.65 penalty=1.000 ratio=1.003
12/31 13:43:52 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 13:43:52 finished saving model
12/31 13:58:42   decaying learning rate to: 0.00708
12/31 14:07:10 step 204000 epoch 84 learning rate 0.00708 step-time 0.697 loss 0.077
12/31 14:07:10 starting evaluation
12/31 14:10:39 test bleu=38.01 loss=106.71 penalty=1.000 ratio=1.003
12/31 14:10:39 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 14:10:40 finished saving model
12/31 14:30:32   decaying learning rate to: 0.00673
12/31 14:33:47 step 206000 epoch 85 learning rate 0.00673 step-time 0.692 loss 0.077
12/31 14:33:47 starting evaluation
12/31 14:37:17 test bleu=37.88 loss=106.64 penalty=1.000 ratio=1.009
12/31 14:37:17 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 14:37:18 finished saving model
12/31 15:00:33 step 208000 epoch 85 learning rate 0.00673 step-time 0.696 loss 0.075
12/31 15:00:33 starting evaluation
12/31 15:04:02 test bleu=38.10 loss=106.71 penalty=1.000 ratio=1.002
12/31 15:04:02 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 15:04:02 finished saving model
12/31 15:05:58   decaying learning rate to: 0.00639
12/31 15:27:04 step 210000 epoch 86 learning rate 0.00639 step-time 0.689 loss 0.072
12/31 15:27:04 starting evaluation
12/31 15:30:33 test bleu=38.20 loss=106.90 penalty=0.999 ratio=0.999
12/31 15:30:33 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 15:30:34 finished saving model
12/31 15:37:37   decaying learning rate to: 0.00607
12/31 15:53:42 step 212000 epoch 87 learning rate 0.00607 step-time 0.692 loss 0.072
12/31 15:53:42 starting evaluation
12/31 15:57:10 test bleu=38.15 loss=107.15 penalty=1.000 ratio=1.002
12/31 15:57:10 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 15:57:10 finished saving model
12/31 16:09:33   decaying learning rate to: 0.00577
12/31 16:20:25 step 214000 epoch 88 learning rate 0.00577 step-time 0.695 loss 0.070
12/31 16:20:25 starting evaluation
12/31 16:23:53 test bleu=37.85 loss=107.20 penalty=1.000 ratio=1.007
12/31 16:23:53 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 16:23:53 finished saving model
12/31 16:41:33   decaying learning rate to: 0.00548
12/31 16:47:07 step 216000 epoch 89 learning rate 0.00548 step-time 0.695 loss 0.072
12/31 16:47:07 starting evaluation
12/31 16:50:37 test bleu=37.87 loss=107.34 penalty=1.000 ratio=1.008
12/31 16:50:37 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 16:50:37 finished saving model
12/31 17:13:23   decaying learning rate to: 0.0052
12/31 17:13:50 step 218000 epoch 90 learning rate 0.0052 step-time 0.695 loss 0.071
12/31 17:13:50 starting evaluation
12/31 17:17:16 test bleu=38.03 loss=107.32 penalty=1.000 ratio=1.004
12/31 17:17:16 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 17:17:17 finished saving model
12/31 17:40:29 step 220000 epoch 90 learning rate 0.0052 step-time 0.694 loss 0.068
12/31 17:40:29 starting evaluation
12/31 17:44:00 test bleu=37.62 loss=107.33 penalty=1.000 ratio=1.014
12/31 17:44:00 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 17:44:00 finished saving model
12/31 17:48:47   decaying learning rate to: 0.00494
12/31 18:07:18 step 222000 epoch 91 learning rate 0.00494 step-time 0.697 loss 0.068
12/31 18:07:18 starting evaluation
12/31 18:10:42 test bleu=38.14 loss=107.45 penalty=1.000 ratio=1.001
12/31 18:10:42 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 18:10:42 finished saving model
12/31 18:20:45   decaying learning rate to: 0.0047
12/31 18:33:53 step 224000 epoch 92 learning rate 0.0047 step-time 0.693 loss 0.067
12/31 18:33:53 starting evaluation
12/31 18:37:23 test bleu=38.03 loss=107.76 penalty=1.000 ratio=1.002
12/31 18:37:23 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 18:37:24 finished saving model
12/31 18:52:30   decaying learning rate to: 0.00446
12/31 19:00:24 step 226000 epoch 93 learning rate 0.00446 step-time 0.688 loss 0.068
12/31 19:00:24 starting evaluation
12/31 19:03:50 test bleu=38.05 loss=107.58 penalty=1.000 ratio=1.004
12/31 19:03:50 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 19:03:51 finished saving model
12/31 19:24:14   decaying learning rate to: 0.00424
12/31 19:27:02 step 228000 epoch 94 learning rate 0.00424 step-time 0.693 loss 0.068
12/31 19:27:02 starting evaluation
12/31 19:30:28 test bleu=38.05 loss=107.73 penalty=1.000 ratio=1.003
12/31 19:30:28 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 19:30:28 finished saving model
12/31 19:53:25 step 230000 epoch 94 learning rate 0.00424 step-time 0.686 loss 0.066
12/31 19:53:25 starting evaluation
12/31 19:56:51 test bleu=38.01 loss=107.82 penalty=1.000 ratio=1.004
12/31 19:56:51 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 19:56:51 finished saving model
12/31 19:59:14   decaying learning rate to: 0.00403
12/31 20:19:59 step 232000 epoch 95 learning rate 0.00403 step-time 0.692 loss 0.065
12/31 20:19:59 starting evaluation
12/31 20:23:27 test bleu=38.03 loss=107.90 penalty=1.000 ratio=1.002
12/31 20:23:27 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 20:23:27 finished saving model
12/31 20:31:12   decaying learning rate to: 0.00383
12/31 20:47:04 step 234000 epoch 96 learning rate 0.00383 step-time 0.707 loss 0.064
12/31 20:47:04 starting evaluation
12/31 20:50:37 test bleu=37.74 loss=108.04 penalty=1.000 ratio=1.010
12/31 20:50:37 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 20:50:37 finished saving model
12/31 21:03:34   decaying learning rate to: 0.00363
12/31 21:14:02 step 236000 epoch 97 learning rate 0.00363 step-time 0.701 loss 0.065
12/31 21:14:02 starting evaluation
12/31 21:17:36 test bleu=37.78 loss=108.03 penalty=1.000 ratio=1.009
12/31 21:17:36 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 21:17:37 finished saving model
12/31 21:37:21   decaying learning rate to: 0.00345
12/31 21:43:09 step 238000 epoch 98 learning rate 0.00345 step-time 0.763 loss 0.066
12/31 21:43:09 starting evaluation
12/31 21:47:01 test bleu=37.92 loss=108.26 penalty=1.000 ratio=1.006
12/31 21:47:01 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 21:47:02 finished saving model
12/31 22:13:10 step 240000 epoch 99 learning rate 0.00345 step-time 0.781 loss 0.065
12/31 22:13:10 starting evaluation
12/31 22:17:00 test bleu=37.75 loss=108.03 penalty=1.000 ratio=1.010
12/31 22:17:00 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 22:17:00 finished saving model
12/31 22:17:01   decaying learning rate to: 0.00328
12/31 22:43:00 step 242000 epoch 99 learning rate 0.00328 step-time 0.777 loss 0.063
12/31 22:43:00 starting evaluation
12/31 22:46:53 test bleu=37.79 loss=108.20 penalty=1.000 ratio=1.009
12/31 22:46:53 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 22:46:54 finished saving model
12/31 22:52:50   decaying learning rate to: 0.00312
12/31 23:13:08 step 244000 epoch 100 learning rate 0.00312 step-time 0.784 loss 0.063
12/31 23:13:08 starting evaluation
12/31 23:16:52 test bleu=37.74 loss=108.27 penalty=1.000 ratio=1.009
12/31 23:16:52 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 23:16:53 finished saving model
12/31 23:28:16 finished training
12/31 23:28:16 exiting...
12/31 23:28:16 saving model to models/9_fold_hybrid_pnl/checkpoints
12/31 23:28:16 finished saving model
