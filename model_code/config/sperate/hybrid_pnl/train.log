nohup: ignoring input
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:107: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:30: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

01/12 03:07:27 label: default
01/12 03:07:27 description:
  default configuration
  next line of description
  last line
01/12 03:07:27 /root/icpc/icpc/translate/__main__.py config/sperate/hybrid_pnl/config.yaml --train -v
01/12 03:07:27 commit hash 74e0554cb3eb5df835cef993ad570ff8de651f71
01/12 03:07:27 tensorflow version: 1.14.0
01/12 03:07:27 program arguments
01/12 03:07:27   aggregation_method   'sum'
01/12 03:07:27   align_encoder_id     0
01/12 03:07:27   allow_growth         True
01/12 03:07:27   attention_type       'global'
01/12 03:07:27   attn_filter_length   0
01/12 03:07:27   attn_filters         0
01/12 03:07:27   attn_prev_word       False
01/12 03:07:27   attn_size            128
01/12 03:07:27   attn_temperature     1.0
01/12 03:07:27   attn_window_size     0
01/12 03:07:27   average              False
01/12 03:07:27   baseline_activation  None
01/12 03:07:27   baseline_learning_rate 0.001
01/12 03:07:27   baseline_optimizer   'adam'
01/12 03:07:27   baseline_steps       0
01/12 03:07:27   batch_mode           'standard'
01/12 03:07:27   batch_size           64
01/12 03:07:27   beam_size            5
01/12 03:07:27   bidir                True
01/12 03:07:27   bidir_projection     False
01/12 03:07:27   binary               False
01/12 03:07:27   cell_size            256
01/12 03:07:27   cell_type            'GRU'
01/12 03:07:27   character_level      False
01/12 03:07:27   checkpoints          []
01/12 03:07:27   conditional_rnn      False
01/12 03:07:27   config               'config/sperate/hybrid_pnl/config.yaml'
01/12 03:07:27   convolutions         None
01/12 03:07:27   data_dir             'data/speratedata'
01/12 03:07:27   debug                False
01/12 03:07:27   decay_after_n_epoch  1
01/12 03:07:27   decay_every_n_epoch  1
01/12 03:07:27   decay_if_no_progress None
01/12 03:07:27   decoders             [{'max_len': 40, 'name': 'nl'}]
01/12 03:07:27   description          'default configuration\nnext line of description\nlast line\n'
01/12 03:07:27   dev_prefix           'test'
01/12 03:07:27   early_stopping       True
01/12 03:07:27   embedding_dropout    0.0
01/12 03:07:27   embedding_initializer None
01/12 03:07:27   embedding_size       256
01/12 03:07:27   embedding_weight_scale None
01/12 03:07:27   embeddings_on_cpu    True
01/12 03:07:27   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 80, 'name': 'pnl'}]
01/12 03:07:27   ensemble             False
01/12 03:07:27   eval_burn_in         0
01/12 03:07:27   feed_previous        0.0
01/12 03:07:27   final_state          'last'
01/12 03:07:27   freeze_variables     []
01/12 03:07:27   generate_first       True
01/12 03:07:27   gpu_id               3
01/12 03:07:27   highway_layers       0
01/12 03:07:27   initial_state_dropout 0.0
01/12 03:07:27   initializer          None
01/12 03:07:27   input_layer_dropout  0.0
01/12 03:07:27   input_layers         None
01/12 03:07:27   keep_best            5
01/12 03:07:27   keep_every_n_hours   0
01/12 03:07:27   label                'default'
01/12 03:07:27   layer_norm           False
01/12 03:07:27   layers               1
01/12 03:07:27   learning_rate        0.5
01/12 03:07:27   learning_rate_decay_factor 0.95
01/12 03:07:27   len_normalization    1.0
01/12 03:07:27   log_file             'log.txt'
01/12 03:07:27   loss_function        'xent'
01/12 03:07:27   max_dev_size         0
01/12 03:07:27   max_epochs           100
01/12 03:07:27   max_gradient_norm    5.0
01/12 03:07:27   max_len              50
01/12 03:07:27   max_steps            600000
01/12 03:07:27   max_test_size        0
01/12 03:07:27   max_to_keep          1
01/12 03:07:27   max_train_size       0
01/12 03:07:27   maxout_stride        None
01/12 03:07:27   mem_fraction         1.0
01/12 03:07:27   min_learning_rate    1e-06
01/12 03:07:27   model_dir            'models/sperate/hybrid_pnl'
01/12 03:07:27   moving_average       None
01/12 03:07:27   no_gpu               False
01/12 03:07:27   optimizer            'sgd'
01/12 03:07:27   orthogonal_init      False
01/12 03:07:27   output               None
01/12 03:07:27   output_dropout       0.0
01/12 03:07:27   parallel_iterations  16
01/12 03:07:27   pervasive_dropout    False
01/12 03:07:27   pooling_avg          True
01/12 03:07:27   post_process_script  None
01/12 03:07:27   pred_deep_layer      False
01/12 03:07:27   pred_edits           False
01/12 03:07:27   pred_embed_proj      True
01/12 03:07:27   pred_maxout_layer    True
01/12 03:07:27   purge                False
01/12 03:07:27   raw_output           False
01/12 03:07:27   read_ahead           1
01/12 03:07:27   reconstruction_attn_weight 0.05
01/12 03:07:27   reconstruction_decoders False
01/12 03:07:27   reconstruction_weight 1.0
01/12 03:07:27   reinforce_after_n_epoch None
01/12 03:07:27   remove_unk           False
01/12 03:07:27   reverse              False
01/12 03:07:27   reverse_input        True
01/12 03:07:27   reward_function      'sentence_bleu'
01/12 03:07:27   rnn_feed_attn        True
01/12 03:07:27   rnn_input_dropout    0.0
01/12 03:07:27   rnn_output_dropout   0.0
01/12 03:07:27   rnn_state_dropout    0.0
01/12 03:07:27   save                 False
01/12 03:07:27   score_function       'corpus_bleu'
01/12 03:07:27   score_functions      ['bleu', 'loss']
01/12 03:07:27   script_dir           'scripts'
01/12 03:07:27   sgd_after_n_epoch    None
01/12 03:07:27   sgd_learning_rate    1.0
01/12 03:07:27   shuffle              True
01/12 03:07:27   softmax_temperature  1.0
01/12 03:07:27   steps_per_checkpoint 2000
01/12 03:07:27   steps_per_eval       2000
01/12 03:07:27   swap_memory          True
01/12 03:07:27   tie_embeddings       False
01/12 03:07:27   time_pooling         None
01/12 03:07:27   train                True
01/12 03:07:27   train_initial_states True
01/12 03:07:27   train_prefix         'train'
01/12 03:07:27   truncate_lines       True
01/12 03:07:27   update_first         False
01/12 03:07:27   use_baseline         False
01/12 03:07:27   use_dropout          False
01/12 03:07:27   use_lstm_full_state  False
01/12 03:07:27   use_previous_word    True
01/12 03:07:27   verbose              True
01/12 03:07:27   vocab_prefix         'vocab'
01/12 03:07:27   weight_scale         None
01/12 03:07:27   word_dropout         0.0
01/12 03:07:27 python random seed: 3330237370944022393
01/12 03:07:27 tf random seed:     7655780450271501368
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:203: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

01/12 03:07:27 creating model
01/12 03:07:27 using device: /gpu:3
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:230: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

01/12 03:07:27 copying vocab to models/sperate/hybrid_pnl/data/vocab.code
01/12 03:07:27 copying vocab to models/sperate/hybrid_pnl/data/vocab.pnl
01/12 03:07:27 copying vocab to models/sperate/hybrid_pnl/data/vocab.nl
01/12 03:07:27 reading vocabularies
01/12 03:07:27 creating model
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:33: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fda9fad1828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fda9fad1828>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:226: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fda9fad1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fda9fad1fd0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdb22699b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdb22699b70>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdb22699860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdb22699860>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb224119e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb224119e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:838: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb222e56a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb222e56a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb2228b6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb2228b6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:432: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:435: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb221be390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb221be390>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb22130da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb22130da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb2200e128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb2200e128>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb220230f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb220230f0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd84f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd84f28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dcf7e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dcf7e48>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd56c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd56c18>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd08518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd08518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd08518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd08518>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:919: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdb1dbd1550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdb1dbd1550>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:10: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:131: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:223: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdac37b9898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7fdac37b9898>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac36f66d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac36f66d8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac371bd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac371bd68>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac37ceba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac37ceba8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd12a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdb1dd12a90>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac3774f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac3774f28>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac3658ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac3658ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac3658ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fdac3658ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
01/12 03:07:35 model parameters (45)
01/12 03:07:35   baseline_step:0 ()
01/12 03:07:35   decoder_nl/attention_code/U_a/kernel:0 (512, 128)
01/12 03:07:35   decoder_nl/attention_code/W_a/bias:0 (128,)
01/12 03:07:35   decoder_nl/attention_code/W_a/kernel:0 (256, 128)
01/12 03:07:35   decoder_nl/attention_code/v_a:0 (128,)
01/12 03:07:35   decoder_nl/attention_pnl/U_a/kernel:0 (512, 128)
01/12 03:07:35   decoder_nl/attention_pnl/W_a/bias:0 (128,)
01/12 03:07:35   decoder_nl/attention_pnl/W_a/kernel:0 (256, 128)
01/12 03:07:35   decoder_nl/attention_pnl/v_a:0 (128,)
01/12 03:07:35   decoder_nl/code_pnl/initial_state_projection/bias:0 (256,)
01/12 03:07:35   decoder_nl/code_pnl/initial_state_projection/kernel:0 (512, 256)
01/12 03:07:35   decoder_nl/gru_cell/candidate/bias:0 (256,)
01/12 03:07:35   decoder_nl/gru_cell/candidate/kernel:0 (1024, 256)
01/12 03:07:35   decoder_nl/gru_cell/gates/bias:0 (512,)
01/12 03:07:35   decoder_nl/gru_cell/gates/kernel:0 (1024, 512)
01/12 03:07:35   decoder_nl/maxout/bias:0 (256,)
01/12 03:07:35   decoder_nl/maxout/kernel:0 (1024, 256)
01/12 03:07:35   decoder_nl/softmax0/kernel:0 (128, 256)
01/12 03:07:35   decoder_nl/softmax1/bias:0 (37188,)
01/12 03:07:35   decoder_nl/softmax1/kernel:0 (256, 37188)
01/12 03:07:35   embedding_code:0 (50000, 256)
01/12 03:07:35   embedding_nl:0 (37188, 256)
01/12 03:07:35   embedding_pnl:0 (36244, 256)
01/12 03:07:35   encoder_code/initial_state_bw:0 (256,)
01/12 03:07:35   encoder_code/initial_state_fw:0 (256,)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
01/12 03:07:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:07:35   encoder_pnl/initial_state_bw:0 (256,)
01/12 03:07:35   encoder_pnl/initial_state_fw:0 (256,)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
01/12 03:07:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:07:35   global_step:0 ()
01/12 03:07:35   learning_rate:0 ()
01/12 03:07:35 number of parameters: 44.14M
WARNING:tensorflow:From /root/icpc/icpc/translate/translation_model.py:666: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

01/12 03:07:36 global step: 0
01/12 03:07:36 baseline step: 0
01/12 03:07:36 reading training data
01/12 03:07:36 total line count: 157832
01/12 03:07:41   lines read: 100000
01/12 03:07:44 files: data/speratedata/train.code data/speratedata/train.pnl data/speratedata/train.nl
01/12 03:07:44 lines reads: 157832
01/12 03:07:44 reading development data
01/12 03:07:45 files: data/speratedata/test.code data/speratedata/test.pnl data/speratedata/test.nl
01/12 03:07:45 lines reads: 16302
01/12 03:07:45 starting training
01/12 03:35:39 step 2000 epoch 1 learning rate 0.5 step-time 0.835 loss 81.087
01/12 03:35:39 starting evaluation
01/12 03:40:20 test bleu=0.13 loss=68.31 penalty=1.000 ratio=3.497
01/12 03:40:20 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 03:40:20 finished saving model
01/12 03:40:20 new best model
01/12 03:46:32   decaying learning rate to: 0.475
01/12 04:07:21 step 4000 epoch 2 learning rate 0.475 step-time 0.808 loss 59.808
01/12 04:07:21 starting evaluation
01/12 04:12:00 test bleu=1.69 loss=62.19 penalty=0.991 ratio=0.991
01/12 04:12:00 saving model to models/sperate/hybrid_pnl/checkpoints
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
01/12 04:12:01 finished saving model
01/12 04:12:01 new best model
01/12 04:24:31   decaying learning rate to: 0.451
01/12 04:39:02 step 6000 epoch 3 learning rate 0.451 step-time 0.808 loss 52.287
01/12 04:39:02 starting evaluation
01/12 04:43:40 test bleu=4.10 loss=59.51 penalty=0.953 ratio=0.955
01/12 04:43:40 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 04:43:40 finished saving model
01/12 04:43:40 new best model
01/12 05:02:29   decaying learning rate to: 0.429
01/12 05:10:34 step 8000 epoch 4 learning rate 0.429 step-time 0.805 loss 46.768
01/12 05:10:34 starting evaluation
01/12 05:15:09 test bleu=6.78 loss=57.18 penalty=0.983 ratio=0.984
01/12 05:15:09 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 05:15:09 finished saving model
01/12 05:15:09 new best model
01/12 05:40:20   decaying learning rate to: 0.407
01/12 05:42:07 step 10000 epoch 5 learning rate 0.407 step-time 0.806 loss 42.607
01/12 05:42:07 starting evaluation
01/12 05:46:47 test bleu=8.29 loss=55.22 penalty=0.985 ratio=0.985
01/12 05:46:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 05:46:47 finished saving model
01/12 05:46:47 new best model
01/12 06:13:59 step 12000 epoch 5 learning rate 0.407 step-time 0.813 loss 38.957
01/12 06:13:59 starting evaluation
01/12 06:18:05 test bleu=9.25 loss=54.20 penalty=0.817 ratio=0.832
01/12 06:18:05 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 06:18:05 finished saving model
01/12 06:18:05 new best model
01/12 06:22:33   decaying learning rate to: 0.387
01/12 06:45:01 step 14000 epoch 6 learning rate 0.387 step-time 0.806 loss 35.790
01/12 06:45:01 starting evaluation
01/12 06:49:47 test bleu=8.33 loss=54.13 penalty=1.000 ratio=1.133
01/12 06:49:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 06:49:47 finished saving model
01/12 07:00:37   decaying learning rate to: 0.368
01/12 07:16:42 step 16000 epoch 7 learning rate 0.368 step-time 0.805 loss 33.609
01/12 07:16:42 starting evaluation
01/12 07:21:16 test bleu=10.82 loss=54.06 penalty=0.826 ratio=0.839
01/12 07:21:16 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 07:21:16 finished saving model
01/12 07:21:16 new best model
01/12 07:38:19   decaying learning rate to: 0.349
01/12 07:48:21 step 18000 epoch 8 learning rate 0.349 step-time 0.810 loss 31.067
01/12 07:48:21 starting evaluation
01/12 07:52:52 test bleu=12.32 loss=54.78 penalty=0.861 ratio=0.870
01/12 07:52:52 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 07:52:52 finished saving model
01/12 07:52:52 new best model
01/12 08:16:16   decaying learning rate to: 0.332
01/12 08:19:50 step 20000 epoch 9 learning rate 0.332 step-time 0.807 loss 29.276
01/12 08:19:50 starting evaluation
01/12 08:24:02 test bleu=10.93 loss=57.15 penalty=0.736 ratio=0.766
01/12 08:24:02 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 08:24:02 finished saving model
01/12 08:50:56 step 22000 epoch 9 learning rate 0.332 step-time 0.805 loss 26.983
01/12 08:50:56 starting evaluation
01/12 08:55:31 test bleu=12.80 loss=55.28 penalty=0.935 ratio=0.937
01/12 08:55:31 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 08:55:32 finished saving model
01/12 08:55:32 new best model
01/12 08:58:17   decaying learning rate to: 0.315
01/12 09:22:40 step 24000 epoch 10 learning rate 0.315 step-time 0.812 loss 24.614
01/12 09:22:40 starting evaluation
01/12 09:27:12 test bleu=11.82 loss=57.43 penalty=0.884 ratio=0.890
01/12 09:27:12 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 09:27:12 finished saving model
01/12 09:36:16   decaying learning rate to: 0.299
01/12 09:54:01 step 26000 epoch 11 learning rate 0.299 step-time 0.802 loss 22.889
01/12 09:54:01 starting evaluation
01/12 09:58:16 test bleu=12.35 loss=58.93 penalty=0.831 ratio=0.844
01/12 09:58:16 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 09:58:16 finished saving model
01/12 10:13:50   decaying learning rate to: 0.284
01/12 10:25:17 step 28000 epoch 12 learning rate 0.284 step-time 0.808 loss 21.170
01/12 10:25:17 starting evaluation
01/12 10:30:00 test bleu=11.62 loss=62.15 penalty=0.906 ratio=0.911
01/12 10:30:00 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 10:30:00 finished saving model
01/12 10:51:39   decaying learning rate to: 0.27
01/12 10:57:12 step 30000 epoch 13 learning rate 0.27 step-time 0.813 loss 19.733
01/12 10:57:12 starting evaluation
01/12 11:01:41 test bleu=12.27 loss=64.36 penalty=0.880 ratio=0.887
01/12 11:01:41 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 11:01:41 finished saving model
01/12 11:28:34 step 32000 epoch 13 learning rate 0.27 step-time 0.804 loss 18.164
01/12 11:28:34 starting evaluation
01/12 11:33:11 test bleu=12.68 loss=62.88 penalty=0.957 ratio=0.958
01/12 11:33:11 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 11:33:11 finished saving model
01/12 11:34:08   decaying learning rate to: 0.257
01/12 12:00:15 step 34000 epoch 14 learning rate 0.257 step-time 0.810 loss 15.947
01/12 12:00:15 starting evaluation
01/12 12:04:43 test bleu=12.60 loss=66.58 penalty=0.901 ratio=0.905
01/12 12:04:43 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 12:04:44 finished saving model
01/12 12:12:01   decaying learning rate to: 0.244
01/12 12:31:49 step 36000 epoch 15 learning rate 0.244 step-time 0.810 loss 14.699
01/12 12:31:49 starting evaluation
01/12 12:36:27 test bleu=12.50 loss=70.06 penalty=0.983 ratio=0.983
01/12 12:36:27 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 12:36:27 finished saving model
01/12 12:50:04   decaying learning rate to: 0.232
01/12 13:03:27 step 38000 epoch 16 learning rate 0.232 step-time 0.808 loss 13.539
01/12 13:03:27 starting evaluation
01/12 13:08:03 test bleu=12.12 loss=73.19 penalty=0.949 ratio=0.950
01/12 13:08:04 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 13:08:04 finished saving model
01/12 13:28:07   decaying learning rate to: 0.22
01/12 13:35:15 step 40000 epoch 17 learning rate 0.22 step-time 0.814 loss 12.452
01/12 13:35:15 starting evaluation
01/12 13:39:26 test bleu=11.95 loss=77.13 penalty=0.881 ratio=0.888
01/12 13:39:26 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 13:39:27 finished saving model
01/12 14:05:43   decaying learning rate to: 0.209
01/12 14:06:33 step 42000 epoch 18 learning rate 0.209 step-time 0.811 loss 11.375
01/12 14:06:33 starting evaluation
01/12 14:11:21 test bleu=12.18 loss=78.85 penalty=0.973 ratio=0.973
01/12 14:11:21 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 14:11:21 finished saving model
01/12 14:38:22 step 44000 epoch 18 learning rate 0.209 step-time 0.808 loss 9.749
01/12 14:38:22 starting evaluation
01/12 14:42:53 test bleu=12.12 loss=80.63 penalty=0.964 ratio=0.965
01/12 14:42:53 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 14:42:53 finished saving model
01/12 14:48:22   decaying learning rate to: 0.199
01/12 15:10:10 step 46000 epoch 19 learning rate 0.199 step-time 0.816 loss 8.808
01/12 15:10:10 starting evaluation
01/12 15:14:39 test bleu=12.12 loss=85.95 penalty=0.926 ratio=0.928
01/12 15:14:39 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 15:14:39 finished saving model
01/12 15:26:17   decaying learning rate to: 0.189
01/12 15:41:49 step 48000 epoch 20 learning rate 0.189 step-time 0.813 loss 8.055
01/12 15:41:49 starting evaluation
01/12 15:46:26 test bleu=11.94 loss=90.49 penalty=0.964 ratio=0.965
01/12 15:46:26 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 15:46:26 finished saving model
01/12 16:04:29   decaying learning rate to: 0.179
01/12 16:13:21 step 50000 epoch 21 learning rate 0.179 step-time 0.805 loss 7.259
01/12 16:13:21 starting evaluation
01/12 16:17:51 test bleu=11.93 loss=95.52 penalty=0.928 ratio=0.930
01/12 16:17:51 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 16:17:51 finished saving model
01/12 16:42:24   decaying learning rate to: 0.17
01/12 16:45:02 step 52000 epoch 22 learning rate 0.17 step-time 0.813 loss 6.634
01/12 16:45:02 starting evaluation
01/12 16:49:38 test bleu=11.88 loss=97.02 penalty=0.972 ratio=0.973
01/12 16:49:38 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 16:49:38 finished saving model
01/12 17:16:33 step 54000 epoch 22 learning rate 0.17 step-time 0.805 loss 5.719
01/12 17:16:33 starting evaluation
01/12 17:21:03 test bleu=11.27 loss=99.77 penalty=1.000 ratio=1.040
01/12 17:21:03 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 17:21:03 finished saving model
01/12 17:24:54   decaying learning rate to: 0.162
01/12 17:47:57 step 56000 epoch 23 learning rate 0.162 step-time 0.805 loss 4.930
01/12 17:47:57 starting evaluation
01/12 17:52:38 test bleu=11.47 loss=106.49 penalty=0.961 ratio=0.962
01/12 17:52:38 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 17:52:38 finished saving model
01/12 18:02:37   decaying learning rate to: 0.154
01/12 18:19:44 step 58000 epoch 24 learning rate 0.154 step-time 0.810 loss 4.532
01/12 18:19:44 starting evaluation
01/12 18:24:18 test bleu=11.93 loss=111.19 penalty=0.981 ratio=0.982
01/12 18:24:18 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 18:24:19 finished saving model
01/12 18:40:29   decaying learning rate to: 0.146
01/12 18:51:27 step 60000 epoch 25 learning rate 0.146 step-time 0.812 loss 4.085
01/12 18:51:27 starting evaluation
01/12 18:56:02 test bleu=12.11 loss=113.68 penalty=1.000 ratio=1.004
01/12 18:56:02 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 18:56:02 finished saving model
01/12 19:18:39   decaying learning rate to: 0.139
01/12 19:23:00 step 62000 epoch 26 learning rate 0.139 step-time 0.807 loss 3.696
01/12 19:23:00 starting evaluation
01/12 19:27:37 test bleu=11.75 loss=119.34 penalty=1.000 ratio=1.022
01/12 19:27:37 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 19:27:37 finished saving model
01/12 19:54:48 step 64000 epoch 26 learning rate 0.139 step-time 0.813 loss 3.248
01/12 19:54:48 starting evaluation
01/12 19:59:25 test bleu=11.41 loss=120.23 penalty=1.000 ratio=1.022
01/12 19:59:25 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 19:59:25 finished saving model
01/12 20:01:19   decaying learning rate to: 0.132
01/12 20:26:30 step 66000 epoch 27 learning rate 0.132 step-time 0.810 loss 2.739
01/12 20:26:30 starting evaluation
01/12 20:31:10 test bleu=10.96 loss=125.65 penalty=1.000 ratio=1.050
01/12 20:31:10 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 20:31:10 finished saving model
01/12 20:39:36   decaying learning rate to: 0.125
01/12 20:58:06 step 68000 epoch 28 learning rate 0.125 step-time 0.806 loss 2.497
01/12 20:58:06 starting evaluation
01/12 21:02:30 test bleu=11.79 loss=130.74 penalty=0.986 ratio=0.986
01/12 21:02:30 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 21:02:31 finished saving model
01/12 21:17:24   decaying learning rate to: 0.119
01/12 21:29:49 step 70000 epoch 29 learning rate 0.119 step-time 0.817 loss 2.288
01/12 21:29:49 starting evaluation
01/12 21:34:32 test bleu=11.45 loss=135.44 penalty=1.000 ratio=1.020
01/12 21:34:32 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 21:34:32 finished saving model
01/12 21:55:13   decaying learning rate to: 0.113
01/12 22:01:30 step 72000 epoch 30 learning rate 0.113 step-time 0.807 loss 2.067
01/12 22:01:30 starting evaluation
01/12 22:06:07 test bleu=11.69 loss=138.38 penalty=1.000 ratio=1.013
01/12 22:06:07 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 22:06:07 finished saving model
01/12 22:33:15 step 74000 epoch 31 learning rate 0.113 step-time 0.812 loss 1.883
01/12 22:33:15 starting evaluation
01/12 22:37:49 test bleu=11.30 loss=140.07 penalty=1.000 ratio=1.037
01/12 22:37:49 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 22:37:49 finished saving model
01/12 22:37:57   decaying learning rate to: 0.107
01/12 23:05:10 step 76000 epoch 31 learning rate 0.107 step-time 0.818 loss 1.559
01/12 23:05:10 starting evaluation
01/12 23:09:47 test bleu=11.66 loss=146.75 penalty=0.999 ratio=0.999
01/12 23:09:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 23:09:47 finished saving model
01/12 23:16:04   decaying learning rate to: 0.102
01/12 23:36:41 step 78000 epoch 32 learning rate 0.102 step-time 0.805 loss 1.436
01/12 23:36:41 starting evaluation
01/12 23:41:20 test bleu=11.00 loss=149.21 penalty=1.000 ratio=1.046
01/12 23:41:20 saving model to models/sperate/hybrid_pnl/checkpoints
01/12 23:41:20 finished saving model
01/12 23:54:14   decaying learning rate to: 0.0969
01/13 00:08:32 step 80000 epoch 33 learning rate 0.0969 step-time 0.814 loss 1.322
01/13 00:08:32 starting evaluation
01/13 00:13:05 test bleu=11.52 loss=152.36 penalty=1.000 ratio=1.011
01/13 00:13:05 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 00:13:05 finished saving model
01/13 00:32:19   decaying learning rate to: 0.092
01/13 00:40:18 step 82000 epoch 34 learning rate 0.092 step-time 0.814 loss 1.204
01/13 00:40:18 starting evaluation
01/13 00:44:42 test bleu=12.00 loss=155.77 penalty=0.978 ratio=0.978
01/13 00:44:42 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 00:44:43 finished saving model
01/13 01:09:58   decaying learning rate to: 0.0874
01/13 01:11:38 step 84000 epoch 35 learning rate 0.0874 step-time 0.805 loss 1.120
01/13 01:11:38 starting evaluation
01/13 01:16:19 test bleu=11.41 loss=159.72 penalty=1.000 ratio=1.030
01/13 01:16:19 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 01:16:19 finished saving model
01/13 01:43:27 step 86000 epoch 35 learning rate 0.0874 step-time 0.812 loss 0.970
01/13 01:43:27 starting evaluation
01/13 01:47:58 test bleu=11.60 loss=162.01 penalty=1.000 ratio=1.015
01/13 01:47:58 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 01:47:58 finished saving model
01/13 01:52:34   decaying learning rate to: 0.083
01/13 02:15:03 step 88000 epoch 36 learning rate 0.083 step-time 0.810 loss 0.873
01/13 02:15:03 starting evaluation
01/13 02:19:40 test bleu=11.78 loss=165.72 penalty=0.973 ratio=0.973
01/13 02:19:40 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 02:19:40 finished saving model
01/13 02:30:38   decaying learning rate to: 0.0789
01/13 02:46:44 step 90000 epoch 37 learning rate 0.0789 step-time 0.810 loss 0.830
01/13 02:46:44 starting evaluation
01/13 02:51:16 test bleu=11.68 loss=167.76 penalty=1.000 ratio=1.011
01/13 02:51:16 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 02:51:16 finished saving model
01/13 03:08:47   decaying learning rate to: 0.0749
01/13 03:18:34 step 92000 epoch 38 learning rate 0.0749 step-time 0.817 loss 0.768
01/13 03:18:35 starting evaluation
01/13 03:23:10 test bleu=11.64 loss=168.41 penalty=1.000 ratio=1.007
01/13 03:23:10 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 03:23:10 finished saving model
01/13 03:46:42   decaying learning rate to: 0.0712
01/13 03:50:09 step 94000 epoch 39 learning rate 0.0712 step-time 0.807 loss 0.723
01/13 03:50:09 starting evaluation
01/13 03:54:46 test bleu=11.96 loss=172.15 penalty=1.000 ratio=1.005
01/13 03:54:46 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 03:54:46 finished saving model
01/13 04:21:40 step 96000 epoch 39 learning rate 0.0712 step-time 0.804 loss 0.663
01/13 04:21:40 starting evaluation
01/13 04:26:10 test bleu=11.36 loss=173.36 penalty=1.000 ratio=1.055
01/13 04:26:10 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 04:26:11 finished saving model
01/13 04:29:17   decaying learning rate to: 0.0676
01/13 04:53:24 step 98000 epoch 40 learning rate 0.0676 step-time 0.814 loss 0.589
01/13 04:53:24 starting evaluation
01/13 04:58:00 test bleu=11.78 loss=176.58 penalty=0.999 ratio=0.999
01/13 04:58:00 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 04:58:00 finished saving model
01/13 05:06:57   decaying learning rate to: 0.0643
01/13 05:24:53 step 100000 epoch 41 learning rate 0.0643 step-time 0.805 loss 0.565
01/13 05:24:53 starting evaluation
01/13 05:29:33 test bleu=11.50 loss=177.21 penalty=1.000 ratio=1.048
01/13 05:29:33 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 05:29:33 finished saving model
01/13 05:45:05   decaying learning rate to: 0.061
01/13 05:56:36 step 102000 epoch 42 learning rate 0.061 step-time 0.809 loss 0.537
01/13 05:56:36 starting evaluation
01/13 06:01:11 test bleu=11.63 loss=178.34 penalty=0.994 ratio=0.994
01/13 06:01:11 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 06:01:12 finished saving model
01/13 06:23:22   decaying learning rate to: 0.058
01/13 06:28:36 step 104000 epoch 43 learning rate 0.058 step-time 0.820 loss 0.503
01/13 06:28:36 starting evaluation
01/13 06:33:11 test bleu=11.74 loss=180.72 penalty=1.000 ratio=1.007
01/13 06:33:11 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 06:33:11 finished saving model
01/13 07:00:17 step 106000 epoch 43 learning rate 0.058 step-time 0.811 loss 0.484
01/13 07:00:17 starting evaluation
01/13 07:04:54 test bleu=11.45 loss=181.72 penalty=1.000 ratio=1.020
01/13 07:04:54 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 07:04:54 finished saving model
01/13 07:05:58   decaying learning rate to: 0.0551
01/13 07:31:49 step 108000 epoch 44 learning rate 0.0551 step-time 0.805 loss 0.429
01/13 07:31:49 starting evaluation
01/13 07:36:24 test bleu=11.58 loss=182.49 penalty=1.000 ratio=1.028
01/13 07:36:24 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 07:36:24 finished saving model
01/13 07:43:58   decaying learning rate to: 0.0523
01/13 08:03:34 step 110000 epoch 45 learning rate 0.0523 step-time 0.813 loss 0.412
01/13 08:03:34 starting evaluation
01/13 08:08:06 test bleu=11.55 loss=182.81 penalty=1.000 ratio=1.041
01/13 08:08:06 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 08:08:06 finished saving model
01/13 08:21:43   decaying learning rate to: 0.0497
01/13 08:35:05 step 112000 epoch 46 learning rate 0.0497 step-time 0.807 loss 0.390
01/13 08:35:05 starting evaluation
01/13 08:39:38 test bleu=11.56 loss=184.06 penalty=1.000 ratio=1.023
01/13 08:39:38 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 08:39:38 finished saving model
01/13 08:59:31   decaying learning rate to: 0.0472
01/13 09:06:32 step 114000 epoch 47 learning rate 0.0472 step-time 0.804 loss 0.375
01/13 09:06:32 starting evaluation
01/13 09:11:13 test bleu=11.59 loss=184.87 penalty=1.000 ratio=1.041
01/13 09:11:13 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 09:11:13 finished saving model
01/13 09:37:43   decaying learning rate to: 0.0449
01/13 09:38:24 step 116000 epoch 48 learning rate 0.0449 step-time 0.813 loss 0.364
01/13 09:38:24 starting evaluation
01/13 09:43:02 test bleu=11.51 loss=185.14 penalty=1.000 ratio=1.037
01/13 09:43:02 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 09:43:02 finished saving model
01/13 10:10:06 step 118000 epoch 48 learning rate 0.0449 step-time 0.810 loss 0.319
01/13 10:10:06 starting evaluation
01/13 10:14:43 test bleu=11.75 loss=184.78 penalty=1.000 ratio=1.021
01/13 10:14:43 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 10:14:43 finished saving model
01/13 10:20:19   decaying learning rate to: 0.0426
01/13 10:41:56 step 120000 epoch 49 learning rate 0.0426 step-time 0.814 loss 0.306
01/13 10:41:56 starting evaluation
01/13 10:46:27 test bleu=11.92 loss=186.32 penalty=1.000 ratio=1.001
01/13 10:46:27 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 10:46:27 finished saving model
01/13 10:58:34   decaying learning rate to: 0.0405
01/13 11:13:41 step 122000 epoch 50 learning rate 0.0405 step-time 0.815 loss 0.292
01/13 11:13:41 starting evaluation
01/13 11:18:20 test bleu=11.42 loss=184.46 penalty=1.000 ratio=1.041
01/13 11:18:20 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 11:18:20 finished saving model
01/13 11:36:31   decaying learning rate to: 0.0385
01/13 11:45:12 step 124000 epoch 51 learning rate 0.0385 step-time 0.804 loss 0.280
01/13 11:45:12 starting evaluation
01/13 11:49:45 test bleu=11.45 loss=185.42 penalty=1.000 ratio=1.049
01/13 11:49:45 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 11:49:46 finished saving model
01/13 12:13:28   decaying learning rate to: 0.0365
01/13 12:15:53 step 126000 epoch 52 learning rate 0.0365 step-time 0.782 loss 0.261
01/13 12:15:53 starting evaluation
01/13 12:20:14 test bleu=11.44 loss=186.59 penalty=1.000 ratio=1.042
01/13 12:20:14 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 12:20:14 finished saving model
01/13 12:46:42 step 128000 epoch 52 learning rate 0.0365 step-time 0.792 loss 0.246
01/13 12:46:42 starting evaluation
01/13 12:51:21 test bleu=11.58 loss=185.36 penalty=1.000 ratio=1.033
01/13 12:51:21 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 12:51:21 finished saving model
01/13 12:55:06   decaying learning rate to: 0.0347
01/13 13:17:34 step 130000 epoch 53 learning rate 0.0347 step-time 0.784 loss 0.221
01/13 13:17:34 starting evaluation
01/13 13:22:13 test bleu=11.45 loss=186.05 penalty=1.000 ratio=1.039
01/13 13:22:13 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 13:22:13 finished saving model
01/13 13:32:07   decaying learning rate to: 0.033
01/13 13:48:46 step 132000 epoch 54 learning rate 0.033 step-time 0.794 loss 0.212
01/13 13:48:46 starting evaluation
01/13 13:53:16 test bleu=11.69 loss=185.51 penalty=1.000 ratio=1.013
01/13 13:53:16 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 13:53:16 finished saving model
01/13 14:09:32   decaying learning rate to: 0.0313
01/13 14:19:54 step 134000 epoch 55 learning rate 0.0313 step-time 0.797 loss 0.206
01/13 14:19:54 starting evaluation
01/13 14:24:23 test bleu=11.66 loss=185.98 penalty=1.000 ratio=1.029
01/13 14:24:23 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 14:24:23 finished saving model
01/13 14:46:03   decaying learning rate to: 0.0298
01/13 14:50:06 step 136000 epoch 56 learning rate 0.0298 step-time 0.769 loss 0.199
01/13 14:50:06 starting evaluation
01/13 14:54:36 test bleu=11.71 loss=185.32 penalty=1.000 ratio=1.024
01/13 14:54:36 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 14:54:36 finished saving model
01/13 15:20:26 step 138000 epoch 56 learning rate 0.0298 step-time 0.773 loss 0.187
01/13 15:20:26 starting evaluation
01/13 15:24:56 test bleu=11.66 loss=185.44 penalty=1.000 ratio=1.040
01/13 15:24:56 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 15:24:57 finished saving model
01/13 15:26:51   decaying learning rate to: 0.0283
01/13 15:50:39 step 140000 epoch 57 learning rate 0.0283 step-time 0.769 loss 0.173
01/13 15:50:39 starting evaluation
01/13 15:55:08 test bleu=11.71 loss=185.82 penalty=1.000 ratio=1.027
01/13 15:55:08 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 15:55:08 finished saving model
01/13 16:03:09   decaying learning rate to: 0.0269
01/13 16:20:54 step 142000 epoch 58 learning rate 0.0269 step-time 0.771 loss 0.163
01/13 16:20:54 starting evaluation
01/13 16:25:23 test bleu=11.84 loss=186.07 penalty=1.000 ratio=1.017
01/13 16:25:23 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 16:25:23 finished saving model
01/13 16:39:33   decaying learning rate to: 0.0255
01/13 16:51:09 step 144000 epoch 59 learning rate 0.0255 step-time 0.771 loss 0.161
01/13 16:51:09 starting evaluation
01/13 16:55:39 test bleu=11.25 loss=185.51 penalty=1.000 ratio=1.069
01/13 16:55:39 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 16:55:40 finished saving model
01/13 17:15:37   decaying learning rate to: 0.0242
01/13 17:21:19 step 146000 epoch 60 learning rate 0.0242 step-time 0.768 loss 0.153
01/13 17:21:19 starting evaluation
01/13 17:25:39 test bleu=11.65 loss=186.91 penalty=1.000 ratio=1.035
01/13 17:25:39 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 17:25:39 finished saving model
01/13 17:51:24 step 148000 epoch 61 learning rate 0.0242 step-time 0.770 loss 0.151
01/13 17:51:24 starting evaluation
01/13 17:55:47 test bleu=11.80 loss=186.22 penalty=1.000 ratio=1.020
01/13 17:55:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 17:55:47 finished saving model
01/13 17:56:02   decaying learning rate to: 0.023
01/13 18:21:14 step 150000 epoch 61 learning rate 0.023 step-time 0.761 loss 0.134
01/13 18:21:14 starting evaluation
01/13 18:25:51 test bleu=11.62 loss=186.94 penalty=1.000 ratio=1.041
01/13 18:25:51 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 18:25:52 finished saving model
01/13 18:32:05   decaying learning rate to: 0.0219
01/13 18:51:42 step 152000 epoch 62 learning rate 0.0219 step-time 0.773 loss 0.137
01/13 18:51:42 starting evaluation
01/13 18:56:13 test bleu=11.82 loss=187.49 penalty=1.000 ratio=1.024
01/13 18:56:13 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 18:56:14 finished saving model
01/13 19:08:19   decaying learning rate to: 0.0208
01/13 19:21:54 step 154000 epoch 63 learning rate 0.0208 step-time 0.768 loss 0.126
01/13 19:21:54 starting evaluation
01/13 19:26:24 test bleu=11.30 loss=187.07 penalty=1.000 ratio=1.066
01/13 19:26:24 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 19:26:24 finished saving model
01/13 19:44:28   decaying learning rate to: 0.0197
01/13 19:52:04 step 156000 epoch 64 learning rate 0.0197 step-time 0.768 loss 0.128
01/13 19:52:04 starting evaluation
01/13 19:56:34 test bleu=11.85 loss=188.28 penalty=1.000 ratio=1.021
01/13 19:56:34 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 19:56:34 finished saving model
01/13 20:20:52   decaying learning rate to: 0.0188
01/13 20:22:17 step 158000 epoch 65 learning rate 0.0188 step-time 0.769 loss 0.125
01/13 20:22:17 starting evaluation
01/13 20:26:47 test bleu=11.81 loss=188.38 penalty=1.000 ratio=1.020
01/13 20:26:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 20:26:47 finished saving model
01/13 20:52:30 step 160000 epoch 65 learning rate 0.0188 step-time 0.769 loss 0.115
01/13 20:52:30 starting evaluation
01/13 20:56:59 test bleu=11.53 loss=187.36 penalty=1.000 ratio=1.038
01/13 20:56:59 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 20:57:00 finished saving model
01/13 21:01:32   decaying learning rate to: 0.0178
01/13 21:22:52 step 162000 epoch 66 learning rate 0.0178 step-time 0.774 loss 0.110
01/13 21:22:52 starting evaluation
01/13 21:27:19 test bleu=11.89 loss=188.04 penalty=1.000 ratio=1.012
01/13 21:27:19 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 21:27:19 finished saving model
01/13 21:38:03   decaying learning rate to: 0.0169
01/13 21:53:05 step 164000 epoch 67 learning rate 0.0169 step-time 0.771 loss 0.108
01/13 21:53:05 starting evaluation
01/13 21:57:35 test bleu=11.75 loss=188.69 penalty=1.000 ratio=1.023
01/13 21:57:35 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 21:57:35 finished saving model
01/13 22:14:18   decaying learning rate to: 0.0161
01/13 22:23:22 step 166000 epoch 68 learning rate 0.0161 step-time 0.772 loss 0.107
01/13 22:23:22 starting evaluation
01/13 22:27:51 test bleu=11.74 loss=188.94 penalty=1.000 ratio=1.020
01/13 22:27:51 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 22:27:51 finished saving model
01/13 22:50:27   decaying learning rate to: 0.0153
01/13 22:53:34 step 168000 epoch 69 learning rate 0.0153 step-time 0.769 loss 0.105
01/13 22:53:34 starting evaluation
01/13 22:57:55 test bleu=11.65 loss=189.42 penalty=1.000 ratio=1.038
01/13 22:57:55 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 22:57:55 finished saving model
01/13 23:23:34 step 170000 epoch 69 learning rate 0.0153 step-time 0.767 loss 0.100
01/13 23:23:34 starting evaluation
01/13 23:27:54 test bleu=11.85 loss=189.01 penalty=1.000 ratio=1.021
01/13 23:27:54 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 23:27:54 finished saving model
01/13 23:30:49   decaying learning rate to: 0.0145
01/13 23:53:30 step 172000 epoch 70 learning rate 0.0145 step-time 0.766 loss 0.091
01/13 23:53:30 starting evaluation
01/13 23:57:54 test bleu=11.67 loss=189.22 penalty=1.000 ratio=1.034
01/13 23:57:54 saving model to models/sperate/hybrid_pnl/checkpoints
01/13 23:57:55 finished saving model
01/14 00:06:37   decaying learning rate to: 0.0138
01/14 00:23:24 step 174000 epoch 71 learning rate 0.0138 step-time 0.763 loss 0.095
01/14 00:23:24 starting evaluation
01/14 00:28:01 test bleu=11.80 loss=189.50 penalty=1.000 ratio=1.029
01/14 00:28:01 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 00:28:01 finished saving model
01/14 00:42:42   decaying learning rate to: 0.0131
01/14 00:53:40 step 176000 epoch 72 learning rate 0.0131 step-time 0.767 loss 0.092
01/14 00:53:40 starting evaluation
01/14 00:58:10 test bleu=11.84 loss=189.54 penalty=1.000 ratio=1.024
01/14 00:58:10 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 00:58:10 finished saving model
01/14 01:18:52   decaying learning rate to: 0.0124
01/14 01:23:49 step 178000 epoch 73 learning rate 0.0124 step-time 0.767 loss 0.092
01/14 01:23:49 starting evaluation
01/14 01:28:19 test bleu=11.75 loss=190.88 penalty=1.000 ratio=1.021
01/14 01:28:19 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 01:28:19 finished saving model
01/14 01:54:01 step 180000 epoch 73 learning rate 0.0124 step-time 0.769 loss 0.088
01/14 01:54:01 starting evaluation
01/14 01:58:31 test bleu=11.81 loss=191.11 penalty=1.000 ratio=1.023
01/14 01:58:31 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 01:58:31 finished saving model
01/14 01:59:39   decaying learning rate to: 0.0118
01/14 02:24:12 step 182000 epoch 74 learning rate 0.0118 step-time 0.768 loss 0.082
01/14 02:24:12 starting evaluation
01/14 02:28:41 test bleu=11.91 loss=190.59 penalty=1.000 ratio=1.018
01/14 02:28:41 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 02:28:42 finished saving model
01/14 02:35:49   decaying learning rate to: 0.0112
01/14 02:54:29 step 184000 epoch 75 learning rate 0.0112 step-time 0.772 loss 0.081
01/14 02:54:29 starting evaluation
01/14 02:58:59 test bleu=11.93 loss=190.55 penalty=1.000 ratio=1.019
01/14 02:58:59 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 02:59:00 finished saving model
01/14 03:12:11   decaying learning rate to: 0.0107
01/14 03:24:39 step 186000 epoch 76 learning rate 0.0107 step-time 0.768 loss 0.080
01/14 03:24:39 starting evaluation
01/14 03:29:09 test bleu=11.67 loss=191.64 penalty=1.000 ratio=1.038
01/14 03:29:09 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 03:29:09 finished saving model
01/14 03:48:28   decaying learning rate to: 0.0101
01/14 03:54:56 step 188000 epoch 77 learning rate 0.0101 step-time 0.771 loss 0.081
01/14 03:54:56 starting evaluation
01/14 03:59:25 test bleu=11.75 loss=191.79 penalty=1.000 ratio=1.024
01/14 03:59:25 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 03:59:26 finished saving model
01/14 04:24:36   decaying learning rate to: 0.00963
01/14 04:25:07 step 190000 epoch 78 learning rate 0.00963 step-time 0.769 loss 0.080
01/14 04:25:07 starting evaluation
01/14 04:29:40 test bleu=11.66 loss=191.87 penalty=1.000 ratio=1.037
01/14 04:29:40 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 04:29:40 finished saving model
01/14 04:55:17 step 192000 epoch 78 learning rate 0.00963 step-time 0.767 loss 0.074
01/14 04:55:17 starting evaluation
01/14 04:59:40 test bleu=11.50 loss=191.91 penalty=1.000 ratio=1.040
01/14 04:59:40 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 04:59:40 finished saving model
01/14 05:05:22   decaying learning rate to: 0.00915
01/14 05:25:24 step 194000 epoch 79 learning rate 0.00915 step-time 0.770 loss 0.071
01/14 05:25:24 starting evaluation
01/14 05:29:44 test bleu=11.76 loss=192.29 penalty=1.000 ratio=1.024
01/14 05:29:44 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 05:29:44 finished saving model
01/14 05:41:18   decaying learning rate to: 0.00869
01/14 05:55:29 step 196000 epoch 80 learning rate 0.00869 step-time 0.770 loss 0.072
01/14 05:55:29 starting evaluation
01/14 05:59:59 test bleu=11.58 loss=192.78 penalty=1.000 ratio=1.039
01/14 05:59:59 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 05:59:59 finished saving model
01/14 06:17:17   decaying learning rate to: 0.00826
01/14 06:25:31 step 198000 epoch 81 learning rate 0.00826 step-time 0.764 loss 0.074
01/14 06:25:31 starting evaluation
01/14 06:30:06 test bleu=11.81 loss=192.66 penalty=1.000 ratio=1.021
01/14 06:30:06 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 06:30:06 finished saving model
01/14 06:53:31   decaying learning rate to: 0.00784
01/14 06:55:49 step 200000 epoch 82 learning rate 0.00784 step-time 0.769 loss 0.072
01/14 06:55:49 starting evaluation
01/14 07:00:19 test bleu=11.86 loss=193.14 penalty=1.000 ratio=1.022
01/14 07:00:19 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 07:00:19 finished saving model
01/14 07:26:06 step 202000 epoch 82 learning rate 0.00784 step-time 0.772 loss 0.068
01/14 07:26:06 starting evaluation
01/14 07:30:36 test bleu=11.79 loss=192.75 penalty=1.000 ratio=1.026
01/14 07:30:36 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 07:30:36 finished saving model
01/14 07:34:21   decaying learning rate to: 0.00745
01/14 07:56:14 step 204000 epoch 83 learning rate 0.00745 step-time 0.767 loss 0.066
01/14 07:56:14 starting evaluation
01/14 08:00:43 test bleu=11.80 loss=193.20 penalty=1.000 ratio=1.023
01/14 08:00:43 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 08:00:43 finished saving model
01/14 08:10:25   decaying learning rate to: 0.00708
01/14 08:26:26 step 206000 epoch 84 learning rate 0.00708 step-time 0.769 loss 0.067
01/14 08:26:26 starting evaluation
01/14 08:30:55 test bleu=11.77 loss=193.52 penalty=1.000 ratio=1.029
01/14 08:30:55 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 08:30:55 finished saving model
01/14 08:46:53   decaying learning rate to: 0.00673
01/14 08:56:48 step 208000 epoch 85 learning rate 0.00673 step-time 0.774 loss 0.066
01/14 08:56:48 starting evaluation
01/14 09:01:18 test bleu=11.91 loss=193.69 penalty=1.000 ratio=1.020
01/14 09:01:18 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 09:01:18 finished saving model
01/14 09:23:03   decaying learning rate to: 0.00639
01/14 09:26:55 step 210000 epoch 86 learning rate 0.00639 step-time 0.767 loss 0.067
01/14 09:26:55 starting evaluation
01/14 09:31:26 test bleu=11.63 loss=193.99 penalty=1.000 ratio=1.030
01/14 09:31:26 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 09:31:26 finished saving model
01/14 09:57:17 step 212000 epoch 86 learning rate 0.00639 step-time 0.774 loss 0.064
01/14 09:57:17 starting evaluation
01/14 10:01:45 test bleu=11.79 loss=194.08 penalty=1.000 ratio=1.035
01/14 10:01:45 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 10:01:46 finished saving model
01/14 10:03:49   decaying learning rate to: 0.00607
01/14 10:27:31 step 214000 epoch 87 learning rate 0.00607 step-time 0.771 loss 0.061
01/14 10:27:31 starting evaluation
01/14 10:32:01 test bleu=12.12 loss=194.23 penalty=1.000 ratio=1.000
01/14 10:32:01 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 10:32:02 finished saving model
01/14 10:40:15   decaying learning rate to: 0.00577
01/14 10:57:38 step 216000 epoch 88 learning rate 0.00577 step-time 0.766 loss 0.062
01/14 10:57:38 starting evaluation
01/14 11:01:58 test bleu=11.68 loss=194.50 penalty=1.000 ratio=1.029
01/14 11:01:58 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 11:01:59 finished saving model
01/14 11:16:10   decaying learning rate to: 0.00548
01/14 11:27:39 step 218000 epoch 89 learning rate 0.00548 step-time 0.768 loss 0.061
01/14 11:27:39 starting evaluation
01/14 11:32:03 test bleu=11.68 loss=195.06 penalty=1.000 ratio=1.029
01/14 11:32:03 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 11:32:03 finished saving model
01/14 11:51:53   decaying learning rate to: 0.0052
01/14 11:57:19 step 220000 epoch 90 learning rate 0.0052 step-time 0.756 loss 0.061
01/14 11:57:19 starting evaluation
01/14 12:01:47 test bleu=11.86 loss=194.51 penalty=1.000 ratio=1.021
01/14 12:01:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 12:01:47 finished saving model
01/14 12:26:02 step 222000 epoch 91 learning rate 0.0052 step-time 0.725 loss 0.062
01/14 12:26:02 starting evaluation
01/14 12:29:18 test bleu=11.80 loss=194.85 penalty=1.000 ratio=1.030
01/14 12:29:18 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 12:29:18 finished saving model
01/14 12:29:39   decaying learning rate to: 0.00494
01/14 12:53:17 step 224000 epoch 91 learning rate 0.00494 step-time 0.717 loss 0.057
01/14 12:53:17 starting evaluation
01/14 12:56:33 test bleu=11.90 loss=194.99 penalty=1.000 ratio=1.021
01/14 12:56:33 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 12:56:33 finished saving model
01/14 13:02:29   decaying learning rate to: 0.0047
01/14 13:20:19 step 226000 epoch 92 learning rate 0.0047 step-time 0.711 loss 0.058
01/14 13:20:19 starting evaluation
01/14 13:23:35 test bleu=11.80 loss=195.45 penalty=1.000 ratio=1.024
01/14 13:23:35 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 13:23:36 finished saving model
01/14 13:35:07   decaying learning rate to: 0.00446
01/14 13:47:29 step 228000 epoch 93 learning rate 0.00446 step-time 0.714 loss 0.058
01/14 13:47:29 starting evaluation
01/14 13:50:46 test bleu=11.79 loss=195.52 penalty=1.000 ratio=1.030
01/14 13:50:46 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 13:50:46 finished saving model
01/14 14:07:45   decaying learning rate to: 0.00424
01/14 14:14:36 step 230000 epoch 94 learning rate 0.00424 step-time 0.713 loss 0.058
01/14 14:14:36 starting evaluation
01/14 14:17:50 test bleu=11.84 loss=195.45 penalty=1.000 ratio=1.026
01/14 14:17:50 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 14:17:51 finished saving model
01/14 14:40:36   decaying learning rate to: 0.00403
01/14 14:41:50 step 232000 epoch 95 learning rate 0.00403 step-time 0.718 loss 0.059
01/14 14:41:50 starting evaluation
01/14 14:45:01 test bleu=11.91 loss=195.70 penalty=1.000 ratio=1.016
01/14 14:45:01 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 14:45:01 finished saving model
01/14 15:08:58 step 234000 epoch 95 learning rate 0.00403 step-time 0.716 loss 0.055
01/14 15:08:58 starting evaluation
01/14 15:12:16 test bleu=11.72 loss=195.60 penalty=1.000 ratio=1.032
01/14 15:12:16 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 15:12:16 finished saving model
01/14 15:16:38   decaying learning rate to: 0.00383
01/14 15:36:08 step 236000 epoch 96 learning rate 0.00383 step-time 0.714 loss 0.056
01/14 15:36:08 starting evaluation
01/14 15:39:24 test bleu=11.89 loss=195.94 penalty=1.000 ratio=1.023
01/14 15:39:24 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 15:39:24 finished saving model
01/14 15:49:20   decaying learning rate to: 0.00363
01/14 16:03:19 step 238000 epoch 97 learning rate 0.00363 step-time 0.715 loss 0.055
01/14 16:03:19 starting evaluation
01/14 16:06:34 test bleu=11.86 loss=196.10 penalty=1.000 ratio=1.022
01/14 16:06:34 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 16:06:34 finished saving model
01/14 16:21:58   decaying learning rate to: 0.00345
01/14 16:30:19 step 240000 epoch 98 learning rate 0.00345 step-time 0.710 loss 0.056
01/14 16:30:19 starting evaluation
01/14 16:33:36 test bleu=11.71 loss=196.38 penalty=1.000 ratio=1.031
01/14 16:33:36 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 16:33:36 finished saving model
01/14 16:54:41   decaying learning rate to: 0.00328
01/14 16:57:30 step 242000 epoch 99 learning rate 0.00328 step-time 0.715 loss 0.056
01/14 16:57:30 starting evaluation
01/14 17:00:47 test bleu=11.88 loss=196.45 penalty=1.000 ratio=1.022
01/14 17:00:47 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 17:00:47 finished saving model
01/14 17:24:33 step 244000 epoch 99 learning rate 0.00328 step-time 0.711 loss 0.054
01/14 17:24:33 starting evaluation
01/14 17:27:50 test bleu=11.86 loss=196.35 penalty=1.000 ratio=1.024
01/14 17:27:50 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 17:27:51 finished saving model
01/14 17:30:39   decaying learning rate to: 0.00312
01/14 17:51:51 step 246000 epoch 100 learning rate 0.00312 step-time 0.718 loss 0.053
01/14 17:51:51 starting evaluation
01/14 17:55:07 test bleu=11.75 loss=196.64 penalty=1.000 ratio=1.028
01/14 17:55:07 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 17:55:07 finished saving model
01/14 18:02:21 finished training
01/14 18:02:21 exiting...
01/14 18:02:21 saving model to models/sperate/hybrid_pnl/checkpoints
01/14 18:02:21 finished saving model
