nohup: ignoring input
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:107: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:30: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

01/12 03:10:25 label: default
01/12 03:10:25 description:
  default configuration
  next line of description
  last line
01/12 03:10:25 /root/icpc/icpc/translate/__main__.py config/sperate/hybrid_all/config.yaml --train -v
01/12 03:10:25 commit hash 74e0554cb3eb5df835cef993ad570ff8de651f71
01/12 03:10:25 tensorflow version: 1.14.0
01/12 03:10:25 program arguments
01/12 03:10:25   aggregation_method   'sum'
01/12 03:10:25   align_encoder_id     0
01/12 03:10:25   allow_growth         True
01/12 03:10:25   attention_type       'global'
01/12 03:10:25   attn_filter_length   0
01/12 03:10:25   attn_filters         0
01/12 03:10:25   attn_prev_word       False
01/12 03:10:25   attn_size            128
01/12 03:10:25   attn_temperature     1.0
01/12 03:10:25   attn_window_size     0
01/12 03:10:25   average              False
01/12 03:10:25   baseline_activation  None
01/12 03:10:25   baseline_learning_rate 0.001
01/12 03:10:25   baseline_optimizer   'adam'
01/12 03:10:25   baseline_steps       0
01/12 03:10:25   batch_mode           'standard'
01/12 03:10:25   batch_size           64
01/12 03:10:25   beam_size            5
01/12 03:10:25   bidir                True
01/12 03:10:25   bidir_projection     False
01/12 03:10:25   binary               False
01/12 03:10:25   cell_size            256
01/12 03:10:25   cell_type            'GRU'
01/12 03:10:25   character_level      False
01/12 03:10:25   checkpoints          []
01/12 03:10:25   conditional_rnn      False
01/12 03:10:25   config               'config/sperate/hybrid_all/config.yaml'
01/12 03:10:25   convolutions         None
01/12 03:10:25   data_dir             'data/speratedata'
01/12 03:10:25   debug                False
01/12 03:10:25   decay_after_n_epoch  1
01/12 03:10:25   decay_every_n_epoch  1
01/12 03:10:25   decay_if_no_progress None
01/12 03:10:25   decoders             [{'max_len': 40, 'name': 'nl'}]
01/12 03:10:25   description          'default configuration\nnext line of description\nlast line\n'
01/12 03:10:25   dev_prefix           'test'
01/12 03:10:25   early_stopping       True
01/12 03:10:25   embedding_dropout    0.0
01/12 03:10:25   embedding_initializer None
01/12 03:10:25   embedding_size       256
01/12 03:10:25   embedding_weight_scale None
01/12 03:10:25   embeddings_on_cpu    True
01/12 03:10:25   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 200, 'name': 'sbt'},
 {'attention_type': 'global', 'max_len': 200, 'name': 'pnl'}]
01/12 03:10:25   ensemble             False
01/12 03:10:25   eval_burn_in         0
01/12 03:10:25   feed_previous        0.0
01/12 03:10:25   final_state          'last'
01/12 03:10:25   freeze_variables     []
01/12 03:10:25   generate_first       True
01/12 03:10:25   gpu_id               2
01/12 03:10:25   highway_layers       0
01/12 03:10:25   initial_state_dropout 0.0
01/12 03:10:25   initializer          None
01/12 03:10:25   input_layer_dropout  0.0
01/12 03:10:25   input_layers         None
01/12 03:10:25   keep_best            5
01/12 03:10:25   keep_every_n_hours   0
01/12 03:10:25   label                'default'
01/12 03:10:25   layer_norm           False
01/12 03:10:25   layers               1
01/12 03:10:25   learning_rate        0.5
01/12 03:10:25   learning_rate_decay_factor 0.95
01/12 03:10:25   len_normalization    1.0
01/12 03:10:25   log_file             'log.txt'
01/12 03:10:25   loss_function        'xent'
01/12 03:10:25   max_dev_size         0
01/12 03:10:25   max_epochs           100
01/12 03:10:25   max_gradient_norm    5.0
01/12 03:10:25   max_len              50
01/12 03:10:25   max_steps            600000
01/12 03:10:25   max_test_size        0
01/12 03:10:25   max_to_keep          1
01/12 03:10:25   max_train_size       0
01/12 03:10:25   maxout_stride        None
01/12 03:10:25   mem_fraction         1.0
01/12 03:10:25   min_learning_rate    1e-06
01/12 03:10:25   model_dir            'models/sperate/hybrid_all'
01/12 03:10:25   moving_average       None
01/12 03:10:25   no_gpu               False
01/12 03:10:25   optimizer            'sgd'
01/12 03:10:25   orthogonal_init      False
01/12 03:10:25   output               None
01/12 03:10:25   output_dropout       0.0
01/12 03:10:25   parallel_iterations  16
01/12 03:10:25   pervasive_dropout    False
01/12 03:10:25   pooling_avg          True
01/12 03:10:25   post_process_script  None
01/12 03:10:25   pred_deep_layer      False
01/12 03:10:25   pred_edits           False
01/12 03:10:25   pred_embed_proj      True
01/12 03:10:25   pred_maxout_layer    True
01/12 03:10:25   purge                False
01/12 03:10:25   raw_output           False
01/12 03:10:25   read_ahead           1
01/12 03:10:25   reconstruction_attn_weight 0.05
01/12 03:10:25   reconstruction_decoders False
01/12 03:10:25   reconstruction_weight 1.0
01/12 03:10:25   reinforce_after_n_epoch None
01/12 03:10:25   remove_unk           False
01/12 03:10:25   reverse              False
01/12 03:10:25   reverse_input        True
01/12 03:10:25   reward_function      'sentence_bleu'
01/12 03:10:25   rnn_feed_attn        True
01/12 03:10:25   rnn_input_dropout    0.0
01/12 03:10:25   rnn_output_dropout   0.0
01/12 03:10:25   rnn_state_dropout    0.0
01/12 03:10:25   save                 False
01/12 03:10:25   score_function       'corpus_bleu'
01/12 03:10:25   score_functions      ['bleu', 'loss']
01/12 03:10:25   script_dir           'scripts'
01/12 03:10:25   sgd_after_n_epoch    None
01/12 03:10:25   sgd_learning_rate    1.0
01/12 03:10:25   shuffle              True
01/12 03:10:25   softmax_temperature  1.0
01/12 03:10:25   steps_per_checkpoint 2000
01/12 03:10:25   steps_per_eval       2000
01/12 03:10:25   swap_memory          True
01/12 03:10:25   tie_embeddings       False
01/12 03:10:25   time_pooling         None
01/12 03:10:25   train                True
01/12 03:10:25   train_initial_states True
01/12 03:10:25   train_prefix         'train'
01/12 03:10:25   truncate_lines       True
01/12 03:10:25   update_first         False
01/12 03:10:25   use_baseline         False
01/12 03:10:25   use_dropout          False
01/12 03:10:25   use_lstm_full_state  False
01/12 03:10:25   use_previous_word    True
01/12 03:10:25   verbose              True
01/12 03:10:25   vocab_prefix         'vocab'
01/12 03:10:25   weight_scale         None
01/12 03:10:25   word_dropout         0.0
01/12 03:10:25 python random seed: 7256623933552428587
01/12 03:10:25 tf random seed:     6249760628747378582
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:203: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

01/12 03:10:25 creating model
01/12 03:10:25 using device: /gpu:2
WARNING:tensorflow:From /root/icpc/icpc/translate/__main__.py:230: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

01/12 03:10:25 copying vocab to models/sperate/hybrid_all/data/vocab.code
01/12 03:10:25 copying vocab to models/sperate/hybrid_all/data/vocab.sbt
01/12 03:10:25 copying vocab to models/sperate/hybrid_all/data/vocab.pnl
01/12 03:10:25 copying vocab to models/sperate/hybrid_all/data/vocab.nl
01/12 03:10:25 reading vocabularies
01/12 03:10:25 creating model
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:33: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f1685e51828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f1685e51828>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/rnn.py:226: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f1685e51128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f1685e51128>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170aa85dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170aa85dd8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170aa85908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170aa85908>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170a764898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170a764898>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170a764780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f170a764780>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1685e43fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1685e43fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:838: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a368f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a368f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a368f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a368f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:432: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:435: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a27b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a27b668>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a1e1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a1e1fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a182b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a182b00>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a0d7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f170a0d7fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709ffcef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709ffcef0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709fb4eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709fb4eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709dd13c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709dd13c8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c99f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c99f60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709d1ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709d1ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c2cf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c2cf60>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709feb588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709feb588>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c532e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c532e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c532e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1709c532e8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /root/icpc/icpc/translate/models.py:919: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.random.categorical` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f16b9f4ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f16b9f4ef60>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:10: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /root/icpc/icpc/translate/seq2seq_model.py:131: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

WARNING:tensorflow:From /root/icpc/icpc/translate/beam_search.py:223: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:Entity <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f16a273e6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <translate.rnn.GRUCell object at 0x7f16a273e6d8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26e1ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26e1ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26e1ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26e1ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26f05c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26f05c0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26560b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a26560b8>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a2548f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a2548f98>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f5da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f5da0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f59b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f59b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f59b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f59b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f59b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f16a24f59b0>>: AssertionError: Bad argument number for Name: 3, expecting 4
01/12 03:10:34 model parameters (60)
01/12 03:10:34   baseline_step:0 ()
01/12 03:10:34   decoder_nl/attention_code/U_a/kernel:0 (512, 128)
01/12 03:10:34   decoder_nl/attention_code/W_a/bias:0 (128,)
01/12 03:10:34   decoder_nl/attention_code/W_a/kernel:0 (256, 128)
01/12 03:10:34   decoder_nl/attention_code/v_a:0 (128,)
01/12 03:10:34   decoder_nl/attention_pnl/U_a/kernel:0 (512, 128)
01/12 03:10:34   decoder_nl/attention_pnl/W_a/bias:0 (128,)
01/12 03:10:34   decoder_nl/attention_pnl/W_a/kernel:0 (256, 128)
01/12 03:10:34   decoder_nl/attention_pnl/v_a:0 (128,)
01/12 03:10:34   decoder_nl/attention_sbt/U_a/kernel:0 (512, 128)
01/12 03:10:34   decoder_nl/attention_sbt/W_a/bias:0 (128,)
01/12 03:10:34   decoder_nl/attention_sbt/W_a/kernel:0 (256, 128)
01/12 03:10:34   decoder_nl/attention_sbt/v_a:0 (128,)
01/12 03:10:34   decoder_nl/code_sbt_pnl/initial_state_projection/bias:0 (256,)
01/12 03:10:34   decoder_nl/code_sbt_pnl/initial_state_projection/kernel:0 (768, 256)
01/12 03:10:34   decoder_nl/gru_cell/candidate/bias:0 (256,)
01/12 03:10:34   decoder_nl/gru_cell/candidate/kernel:0 (1024, 256)
01/12 03:10:34   decoder_nl/gru_cell/gates/bias:0 (512,)
01/12 03:10:34   decoder_nl/gru_cell/gates/kernel:0 (1024, 512)
01/12 03:10:34   decoder_nl/maxout/bias:0 (256,)
01/12 03:10:34   decoder_nl/maxout/kernel:0 (1024, 256)
01/12 03:10:34   decoder_nl/softmax0/kernel:0 (128, 256)
01/12 03:10:34   decoder_nl/softmax1/bias:0 (37188,)
01/12 03:10:34   decoder_nl/softmax1/kernel:0 (256, 37188)
01/12 03:10:34   embedding_code:0 (50000, 256)
01/12 03:10:34   embedding_nl:0 (37188, 256)
01/12 03:10:34   embedding_pnl:0 (36244, 256)
01/12 03:10:34   embedding_sbt:0 (87, 256)
01/12 03:10:34   encoder_code/initial_state_bw:0 (256,)
01/12 03:10:34   encoder_code/initial_state_fw:0 (256,)
01/12 03:10:34   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
01/12 03:10:34   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:10:34   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
01/12 03:10:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:10:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
01/12 03:10:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:10:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
01/12 03:10:35   encoder_code/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:10:35   encoder_pnl/initial_state_bw:0 (256,)
01/12 03:10:35   encoder_pnl/initial_state_fw:0 (256,)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
01/12 03:10:35   encoder_pnl/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:10:35   encoder_sbt/initial_state_bw:0 (256,)
01/12 03:10:35   encoder_sbt/initial_state_fw:0 (256,)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/bias:0 (256,)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/bias:0 (512,)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/bias:0 (256,)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/candidate/kernel:0 (512, 256)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/bias:0 (512,)
01/12 03:10:35   encoder_sbt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/gru_cell/gates/kernel:0 (512, 512)
01/12 03:10:35   global_step:0 ()
01/12 03:10:35   learning_rate:0 ()
01/12 03:10:35 number of parameters: 45.12M
WARNING:tensorflow:From /root/icpc/icpc/translate/translation_model.py:666: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

01/12 03:10:36 global step: 0
01/12 03:10:36 baseline step: 0
01/12 03:10:36 reading training data
01/12 03:10:36 total line count: 157832
01/12 03:10:48   lines read: 100000
01/12 03:10:55 files: data/speratedata/train.code data/speratedata/train.sbt data/speratedata/train.pnl data/speratedata/train.nl
01/12 03:10:55 lines reads: 157832
01/12 03:10:55 reading development data
01/12 03:10:56 files: data/speratedata/test.code data/speratedata/test.sbt data/speratedata/test.pnl data/speratedata/test.nl
01/12 03:10:56 lines reads: 16302
01/12 03:10:57 starting training
01/12 03:54:18 step 2000 epoch 1 learning rate 0.5 step-time 1.298 loss 83.971
01/12 03:54:18 starting evaluation
01/12 03:59:49 test bleu=0.88 loss=70.16 penalty=0.760 ratio=0.784
01/12 03:59:49 saving model to models/sperate/hybrid_all/checkpoints
01/12 03:59:50 finished saving model
01/12 03:59:50 new best model
01/12 04:09:57   decaying learning rate to: 0.475
01/12 04:43:03 step 4000 epoch 2 learning rate 0.475 step-time 1.294 loss 61.038
01/12 04:43:03 starting evaluation
01/12 04:48:31 test bleu=2.13 loss=63.00 penalty=1.000 ratio=1.007
01/12 04:48:31 saving model to models/sperate/hybrid_all/checkpoints
WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
01/12 04:48:31 finished saving model
01/12 04:48:31 new best model
01/12 05:08:33   decaying learning rate to: 0.451
01/12 05:31:38 step 6000 epoch 3 learning rate 0.451 step-time 1.291 loss 53.540
01/12 05:31:38 starting evaluation
01/12 05:36:58 test bleu=2.56 loss=60.25 penalty=0.742 ratio=0.770
01/12 05:36:58 saving model to models/sperate/hybrid_all/checkpoints
01/12 05:36:58 finished saving model
01/12 05:36:58 new best model
01/12 06:07:17   decaying learning rate to: 0.429
01/12 06:20:12 step 8000 epoch 4 learning rate 0.429 step-time 1.294 loss 48.118
01/12 06:20:12 starting evaluation
01/12 06:25:17 test bleu=4.74 loss=57.83 penalty=0.656 ratio=0.703
01/12 06:25:17 saving model to models/sperate/hybrid_all/checkpoints
01/12 06:25:17 finished saving model
01/12 06:25:17 new best model
01/12 07:05:30   decaying learning rate to: 0.407
01/12 07:08:21 step 10000 epoch 5 learning rate 0.407 step-time 1.290 loss 43.978
01/12 07:08:21 starting evaluation
01/12 07:13:26 test bleu=6.90 loss=55.92 penalty=0.706 ratio=0.742
01/12 07:13:26 saving model to models/sperate/hybrid_all/checkpoints
01/12 07:13:26 finished saving model
01/12 07:13:26 new best model
01/12 07:56:41 step 12000 epoch 5 learning rate 0.407 step-time 1.295 loss 40.257
01/12 07:56:41 starting evaluation
01/12 08:01:59 test bleu=7.51 loss=56.04 penalty=0.653 ratio=0.701
01/12 08:01:59 saving model to models/sperate/hybrid_all/checkpoints
01/12 08:01:59 finished saving model
01/12 08:01:59 new best model
01/12 08:09:12   decaying learning rate to: 0.387
01/12 08:45:05 step 14000 epoch 6 learning rate 0.387 step-time 1.290 loss 37.064
01/12 08:45:05 starting evaluation
01/12 08:50:20 test bleu=8.80 loss=54.67 penalty=0.767 ratio=0.791
01/12 08:50:20 saving model to models/sperate/hybrid_all/checkpoints
01/12 08:50:21 finished saving model
01/12 08:50:21 new best model
01/12 09:07:40   decaying learning rate to: 0.368
01/12 09:33:24 step 16000 epoch 7 learning rate 0.368 step-time 1.289 loss 34.619
01/12 09:33:24 starting evaluation
01/12 09:38:54 test bleu=10.24 loss=54.60 penalty=1.000 ratio=1.012
01/12 09:38:54 saving model to models/sperate/hybrid_all/checkpoints
01/12 09:38:54 finished saving model
01/12 09:38:54 new best model
01/12 10:06:12   decaying learning rate to: 0.349
01/12 10:22:02 step 18000 epoch 8 learning rate 0.349 step-time 1.291 loss 32.368
01/12 10:22:02 starting evaluation
01/12 10:27:32 test bleu=9.36 loss=54.94 penalty=1.000 ratio=1.124
01/12 10:27:32 saving model to models/sperate/hybrid_all/checkpoints
01/12 10:27:32 finished saving model
01/12 11:04:58   decaying learning rate to: 0.332
01/12 11:10:40 step 20000 epoch 9 learning rate 0.332 step-time 1.292 loss 30.285
01/12 11:10:40 starting evaluation
01/12 11:16:00 test bleu=11.23 loss=55.37 penalty=0.854 ratio=0.864
01/12 11:16:00 saving model to models/sperate/hybrid_all/checkpoints
01/12 11:16:00 finished saving model
01/12 11:16:00 new best model
01/12 11:59:14 step 22000 epoch 9 learning rate 0.332 step-time 1.294 loss 28.172
01/12 11:59:14 starting evaluation
01/12 12:04:30 test bleu=10.93 loss=54.97 penalty=0.819 ratio=0.833
01/12 12:04:30 saving model to models/sperate/hybrid_all/checkpoints
01/12 12:04:30 finished saving model
01/12 12:08:54   decaying learning rate to: 0.315
01/12 12:47:42 step 24000 epoch 10 learning rate 0.315 step-time 1.293 loss 25.848
01/12 12:47:42 starting evaluation
01/12 12:52:55 test bleu=11.73 loss=56.88 penalty=0.784 ratio=0.804
01/12 12:52:55 saving model to models/sperate/hybrid_all/checkpoints
01/12 12:52:55 finished saving model
01/12 12:52:55 new best model
01/12 13:07:28   decaying learning rate to: 0.299
01/12 13:36:09 step 26000 epoch 11 learning rate 0.299 step-time 1.294 loss 24.110
01/12 13:36:09 starting evaluation
01/12 13:41:31 test bleu=11.48 loss=58.73 penalty=0.828 ratio=0.842
01/12 13:41:31 saving model to models/sperate/hybrid_all/checkpoints
01/12 13:41:32 finished saving model
01/12 14:06:03   decaying learning rate to: 0.284
01/12 14:24:48 step 28000 epoch 12 learning rate 0.284 step-time 1.296 loss 22.483
01/12 14:24:48 starting evaluation
01/12 14:30:16 test bleu=12.73 loss=59.61 penalty=0.984 ratio=0.984
01/12 14:30:16 saving model to models/sperate/hybrid_all/checkpoints
01/12 14:30:17 finished saving model
01/12 14:30:17 new best model
01/12 15:04:53   decaying learning rate to: 0.27
01/12 15:13:24 step 30000 epoch 13 learning rate 0.27 step-time 1.291 loss 20.906
01/12 15:13:24 starting evaluation
01/12 15:18:45 test bleu=11.65 loss=62.40 penalty=0.915 ratio=0.919
01/12 15:18:45 saving model to models/sperate/hybrid_all/checkpoints
01/12 15:18:45 finished saving model
01/12 16:01:59 step 32000 epoch 13 learning rate 0.27 step-time 1.294 loss 19.397
01/12 16:01:59 starting evaluation
01/12 16:07:09 test bleu=11.49 loss=62.65 penalty=0.833 ratio=0.846
01/12 16:07:09 saving model to models/sperate/hybrid_all/checkpoints
01/12 16:07:09 finished saving model
01/12 16:08:41   decaying learning rate to: 0.257
01/12 16:50:19 step 34000 epoch 14 learning rate 0.257 step-time 1.293 loss 17.163
01/12 16:50:19 starting evaluation
01/12 16:55:44 test bleu=11.58 loss=63.57 penalty=0.930 ratio=0.932
01/12 16:55:44 saving model to models/sperate/hybrid_all/checkpoints
01/12 16:55:45 finished saving model
01/12 17:07:18   decaying learning rate to: 0.244
01/12 17:39:07 step 36000 epoch 15 learning rate 0.244 step-time 1.299 loss 15.850
01/12 17:39:07 starting evaluation
01/12 17:44:24 test bleu=11.75 loss=67.47 penalty=0.878 ratio=0.885
01/12 17:44:24 saving model to models/sperate/hybrid_all/checkpoints
01/12 17:44:24 finished saving model
01/12 18:06:12   decaying learning rate to: 0.232
01/12 18:27:41 step 38000 epoch 16 learning rate 0.232 step-time 1.296 loss 14.663
01/12 18:27:41 starting evaluation
01/12 18:33:00 test bleu=11.70 loss=71.50 penalty=0.873 ratio=0.881
01/12 18:33:00 saving model to models/sperate/hybrid_all/checkpoints
01/12 18:33:00 finished saving model
01/12 19:04:40   decaying learning rate to: 0.22
01/12 19:16:02 step 40000 epoch 17 learning rate 0.22 step-time 1.289 loss 13.431
01/12 19:16:02 starting evaluation
01/12 19:21:21 test bleu=11.51 loss=74.60 penalty=0.877 ratio=0.884
01/12 19:21:21 saving model to models/sperate/hybrid_all/checkpoints
01/12 19:21:21 finished saving model
01/12 20:03:14   decaying learning rate to: 0.209
01/12 20:04:33 step 42000 epoch 18 learning rate 0.209 step-time 1.294 loss 12.454
01/12 20:04:33 starting evaluation
01/12 20:09:54 test bleu=11.69 loss=76.76 penalty=0.914 ratio=0.917
01/12 20:09:54 saving model to models/sperate/hybrid_all/checkpoints
01/12 20:09:54 finished saving model
01/12 20:53:14 step 44000 epoch 18 learning rate 0.209 step-time 1.297 loss 10.711
01/12 20:53:14 starting evaluation
01/12 20:58:37 test bleu=11.40 loss=76.95 penalty=0.934 ratio=0.937
01/12 20:58:37 saving model to models/sperate/hybrid_all/checkpoints
01/12 20:58:37 finished saving model
01/12 21:07:30   decaying learning rate to: 0.199
01/12 21:42:04 step 46000 epoch 19 learning rate 0.199 step-time 1.301 loss 9.676
01/12 21:42:04 starting evaluation
01/12 21:47:26 test bleu=11.19 loss=82.51 penalty=0.873 ratio=0.880
01/12 21:47:26 saving model to models/sperate/hybrid_all/checkpoints
01/12 21:47:26 finished saving model
01/12 22:06:11   decaying learning rate to: 0.189
01/12 22:30:37 step 48000 epoch 20 learning rate 0.189 step-time 1.293 loss 8.884
01/12 22:30:37 starting evaluation
01/12 22:35:57 test bleu=11.48 loss=86.88 penalty=0.923 ratio=0.926
01/12 22:35:57 saving model to models/sperate/hybrid_all/checkpoints
01/12 22:35:57 finished saving model
01/12 23:04:59   decaying learning rate to: 0.179
01/12 23:19:06 step 50000 epoch 21 learning rate 0.179 step-time 1.292 loss 8.020
01/12 23:19:06 starting evaluation
01/12 23:24:35 test bleu=11.18 loss=90.34 penalty=1.000 ratio=1.022
01/12 23:24:35 saving model to models/sperate/hybrid_all/checkpoints
01/12 23:24:36 finished saving model
01/13 00:03:41   decaying learning rate to: 0.17
01/13 00:07:55 step 52000 epoch 22 learning rate 0.17 step-time 1.297 loss 7.349
01/13 00:07:55 starting evaluation
01/13 00:13:23 test bleu=11.63 loss=94.04 penalty=0.992 ratio=0.992
01/13 00:13:23 saving model to models/sperate/hybrid_all/checkpoints
01/13 00:13:23 finished saving model
01/13 00:56:37 step 54000 epoch 22 learning rate 0.17 step-time 1.294 loss 6.356
01/13 00:56:37 starting evaluation
01/13 01:01:58 test bleu=11.63 loss=94.58 penalty=1.000 ratio=1.012
01/13 01:01:58 saving model to models/sperate/hybrid_all/checkpoints
01/13 01:01:58 finished saving model
01/13 01:07:51   decaying learning rate to: 0.162
01/13 01:45:08 step 56000 epoch 23 learning rate 0.162 step-time 1.293 loss 5.557
01/13 01:45:08 starting evaluation
01/13 01:50:37 test bleu=11.07 loss=100.99 penalty=0.999 ratio=0.999
01/13 01:50:37 saving model to models/sperate/hybrid_all/checkpoints
01/13 01:50:37 finished saving model
01/13 02:06:37   decaying learning rate to: 0.154
01/13 02:33:53 step 58000 epoch 24 learning rate 0.154 step-time 1.295 loss 5.022
01/13 02:33:53 starting evaluation
01/13 02:39:20 test bleu=11.84 loss=104.43 penalty=0.992 ratio=0.992
01/13 02:39:20 saving model to models/sperate/hybrid_all/checkpoints
01/13 02:39:20 finished saving model
01/13 03:05:19   decaying learning rate to: 0.146
01/13 03:22:29 step 60000 epoch 25 learning rate 0.146 step-time 1.292 loss 4.539
01/13 03:22:29 starting evaluation
01/13 03:27:54 test bleu=11.29 loss=110.43 penalty=0.999 ratio=0.999
01/13 03:27:54 saving model to models/sperate/hybrid_all/checkpoints
01/13 03:27:54 finished saving model
01/13 04:04:14   decaying learning rate to: 0.139
01/13 04:11:14 step 62000 epoch 26 learning rate 0.139 step-time 1.298 loss 4.137
01/13 04:11:14 starting evaluation
01/13 04:16:36 test bleu=11.53 loss=112.34 penalty=0.978 ratio=0.978
01/13 04:16:36 saving model to models/sperate/hybrid_all/checkpoints
01/13 04:16:36 finished saving model
01/13 04:59:53 step 64000 epoch 26 learning rate 0.139 step-time 1.296 loss 3.606
01/13 04:59:53 starting evaluation
01/13 05:05:22 test bleu=10.92 loss=114.88 penalty=1.000 ratio=1.049
01/13 05:05:22 saving model to models/sperate/hybrid_all/checkpoints
01/13 05:05:22 finished saving model
01/13 05:08:26   decaying learning rate to: 0.132
01/13 05:48:35 step 66000 epoch 27 learning rate 0.132 step-time 1.294 loss 3.065
01/13 05:48:35 starting evaluation
01/13 05:54:02 test bleu=11.09 loss=120.10 penalty=1.000 ratio=1.011
01/13 05:54:02 saving model to models/sperate/hybrid_all/checkpoints
01/13 05:54:02 finished saving model
01/13 06:07:14   decaying learning rate to: 0.125
01/13 06:37:22 step 68000 epoch 28 learning rate 0.125 step-time 1.298 loss 2.773
01/13 06:37:22 starting evaluation
01/13 06:42:49 test bleu=10.92 loss=126.09 penalty=1.000 ratio=1.037
01/13 06:42:49 saving model to models/sperate/hybrid_all/checkpoints
01/13 06:42:49 finished saving model
01/13 07:06:09   decaying learning rate to: 0.119
01/13 07:26:03 step 70000 epoch 29 learning rate 0.119 step-time 1.295 loss 2.548
01/13 07:26:03 starting evaluation
01/13 07:31:29 test bleu=11.51 loss=130.28 penalty=0.992 ratio=0.992
01/13 07:31:29 saving model to models/sperate/hybrid_all/checkpoints
01/13 07:31:29 finished saving model
01/13 08:04:39   decaying learning rate to: 0.113
01/13 08:14:36 step 72000 epoch 30 learning rate 0.113 step-time 1.291 loss 2.278
01/13 08:14:36 starting evaluation
01/13 08:19:59 test bleu=11.38 loss=133.85 penalty=1.000 ratio=1.008
01/13 08:19:59 saving model to models/sperate/hybrid_all/checkpoints
01/13 08:19:59 finished saving model
01/13 09:03:10 step 74000 epoch 31 learning rate 0.113 step-time 1.293 loss 2.068
01/13 09:03:10 starting evaluation
01/13 09:08:39 test bleu=11.19 loss=136.18 penalty=1.000 ratio=1.020
01/13 09:08:39 saving model to models/sperate/hybrid_all/checkpoints
01/13 09:08:40 finished saving model
01/13 09:08:52   decaying learning rate to: 0.107
01/13 09:51:49 step 76000 epoch 31 learning rate 0.107 step-time 1.292 loss 1.714
01/13 09:51:49 starting evaluation
01/13 09:57:18 test bleu=11.14 loss=141.81 penalty=1.000 ratio=1.002
01/13 09:57:18 saving model to models/sperate/hybrid_all/checkpoints
01/13 09:57:18 finished saving model
01/13 10:07:46   decaying learning rate to: 0.102
01/13 10:40:42 step 78000 epoch 32 learning rate 0.102 step-time 1.299 loss 1.576
01/13 10:40:42 starting evaluation
01/13 10:46:04 test bleu=11.18 loss=145.10 penalty=0.948 ratio=0.949
01/13 10:46:04 saving model to models/sperate/hybrid_all/checkpoints
01/13 10:46:04 finished saving model
01/13 11:06:26   decaying learning rate to: 0.0969
01/13 11:29:12 step 80000 epoch 33 learning rate 0.0969 step-time 1.292 loss 1.437
01/13 11:29:12 starting evaluation
01/13 11:34:37 test bleu=11.33 loss=148.18 penalty=0.987 ratio=0.987
01/13 11:34:37 saving model to models/sperate/hybrid_all/checkpoints
01/13 11:34:37 finished saving model
01/13 12:03:57   decaying learning rate to: 0.092
01/13 12:16:03 step 82000 epoch 34 learning rate 0.092 step-time 1.241 loss 1.308
01/13 12:16:03 starting evaluation
01/13 12:21:26 test bleu=10.97 loss=151.36 penalty=1.000 ratio=1.047
01/13 12:21:26 saving model to models/sperate/hybrid_all/checkpoints
01/13 12:21:26 finished saving model
01/13 13:00:41   decaying learning rate to: 0.0874
01/13 13:03:14 step 84000 epoch 35 learning rate 0.0874 step-time 1.251 loss 1.204
01/13 13:03:14 starting evaluation
01/13 13:08:30 test bleu=11.66 loss=155.16 penalty=0.957 ratio=0.958
01/13 13:08:30 saving model to models/sperate/hybrid_all/checkpoints
01/13 13:08:30 finished saving model
01/13 13:50:15 step 86000 epoch 35 learning rate 0.0874 step-time 1.250 loss 1.042
01/13 13:50:15 starting evaluation
01/13 13:55:42 test bleu=10.84 loss=157.95 penalty=1.000 ratio=1.013
01/13 13:55:42 saving model to models/sperate/hybrid_all/checkpoints
01/13 13:55:42 finished saving model
01/13 14:03:01   decaying learning rate to: 0.083
01/13 14:37:33 step 88000 epoch 36 learning rate 0.083 step-time 1.253 loss 0.949
01/13 14:37:33 starting evaluation
01/13 14:42:50 test bleu=11.20 loss=160.73 penalty=1.000 ratio=1.020
01/13 14:42:50 saving model to models/sperate/hybrid_all/checkpoints
01/13 14:42:50 finished saving model
01/13 14:59:34   decaying learning rate to: 0.0789
01/13 15:24:07 step 90000 epoch 37 learning rate 0.0789 step-time 1.236 loss 0.873
01/13 15:24:07 starting evaluation
01/13 15:29:27 test bleu=10.84 loss=164.16 penalty=1.000 ratio=1.053
01/13 15:29:27 saving model to models/sperate/hybrid_all/checkpoints
01/13 15:29:28 finished saving model
01/13 15:55:46   decaying learning rate to: 0.0749
01/13 16:10:39 step 92000 epoch 38 learning rate 0.0749 step-time 1.234 loss 0.809
01/13 16:10:39 starting evaluation
01/13 16:15:56 test bleu=11.47 loss=166.66 penalty=1.000 ratio=1.000
01/13 16:15:56 saving model to models/sperate/hybrid_all/checkpoints
01/13 16:15:56 finished saving model
01/13 16:51:52   decaying learning rate to: 0.0712
01/13 16:57:03 step 94000 epoch 39 learning rate 0.0712 step-time 1.232 loss 0.760
01/13 16:57:03 starting evaluation
01/13 17:02:23 test bleu=11.04 loss=168.70 penalty=1.000 ratio=1.041
01/13 17:02:23 saving model to models/sperate/hybrid_all/checkpoints
01/13 17:02:23 finished saving model
01/13 17:43:28 step 96000 epoch 39 learning rate 0.0712 step-time 1.230 loss 0.688
01/13 17:43:28 starting evaluation
01/13 17:48:46 test bleu=11.26 loss=171.62 penalty=0.997 ratio=0.997
01/13 17:48:46 saving model to models/sperate/hybrid_all/checkpoints
01/13 17:48:46 finished saving model
01/13 17:53:14   decaying learning rate to: 0.0676
01/13 18:29:57 step 98000 epoch 40 learning rate 0.0676 step-time 1.233 loss 0.619
01/13 18:29:57 starting evaluation
01/13 18:35:18 test bleu=11.04 loss=173.13 penalty=1.000 ratio=1.049
01/13 18:35:18 saving model to models/sperate/hybrid_all/checkpoints
01/13 18:35:18 finished saving model
01/13 18:49:20   decaying learning rate to: 0.0643
01/13 19:16:34 step 100000 epoch 41 learning rate 0.0643 step-time 1.236 loss 0.583
01/13 19:16:34 starting evaluation
01/13 19:21:52 test bleu=11.31 loss=175.40 penalty=0.963 ratio=0.964
01/13 19:21:52 saving model to models/sperate/hybrid_all/checkpoints
01/13 19:21:52 finished saving model
01/13 19:45:24   decaying learning rate to: 0.061
01/13 20:02:57 step 102000 epoch 42 learning rate 0.061 step-time 1.231 loss 0.553
01/13 20:02:57 starting evaluation
01/13 20:08:13 test bleu=10.99 loss=176.09 penalty=1.000 ratio=1.013
01/13 20:08:13 saving model to models/sperate/hybrid_all/checkpoints
01/13 20:08:13 finished saving model
01/13 20:41:27   decaying learning rate to: 0.058
01/13 20:49:23 step 104000 epoch 43 learning rate 0.058 step-time 1.233 loss 0.520
01/13 20:49:23 starting evaluation
01/13 20:54:42 test bleu=11.51 loss=175.39 penalty=0.999 ratio=0.999
01/13 20:54:42 saving model to models/sperate/hybrid_all/checkpoints
01/13 20:54:42 finished saving model
01/13 21:35:52 step 106000 epoch 43 learning rate 0.058 step-time 1.233 loss 0.501
01/13 21:35:52 starting evaluation
01/13 21:41:11 test bleu=11.05 loss=178.21 penalty=1.000 ratio=1.015
01/13 21:41:11 saving model to models/sperate/hybrid_all/checkpoints
01/13 21:41:12 finished saving model
01/13 21:42:52   decaying learning rate to: 0.0551
01/13 22:22:26 step 108000 epoch 44 learning rate 0.0551 step-time 1.235 loss 0.437
01/13 22:22:26 starting evaluation
01/13 22:27:46 test bleu=11.46 loss=180.48 penalty=0.995 ratio=0.995
01/13 22:27:46 saving model to models/sperate/hybrid_all/checkpoints
01/13 22:27:46 finished saving model
01/13 22:39:00   decaying learning rate to: 0.0523
01/13 23:08:49 step 110000 epoch 45 learning rate 0.0523 step-time 1.230 loss 0.427
01/13 23:08:49 starting evaluation
01/13 23:14:08 test bleu=11.16 loss=181.77 penalty=1.000 ratio=1.032
01/13 23:14:08 saving model to models/sperate/hybrid_all/checkpoints
01/13 23:14:08 finished saving model
01/13 23:34:59   decaying learning rate to: 0.0497
01/13 23:55:13 step 112000 epoch 46 learning rate 0.0497 step-time 1.230 loss 0.401
01/13 23:55:13 starting evaluation
01/14 00:00:28 test bleu=11.37 loss=183.28 penalty=1.000 ratio=1.002
01/14 00:00:28 saving model to models/sperate/hybrid_all/checkpoints
01/14 00:00:28 finished saving model
01/14 00:31:00   decaying learning rate to: 0.0472
01/14 00:41:35 step 114000 epoch 47 learning rate 0.0472 step-time 1.232 loss 0.385
01/14 00:41:35 starting evaluation
01/14 00:46:48 test bleu=11.58 loss=183.96 penalty=0.987 ratio=0.987
01/14 00:46:48 saving model to models/sperate/hybrid_all/checkpoints
01/14 00:46:49 finished saving model
01/14 01:26:48   decaying learning rate to: 0.0449
01/14 01:27:50 step 116000 epoch 48 learning rate 0.0449 step-time 1.229 loss 0.372
01/14 01:27:50 starting evaluation
01/14 01:33:07 test bleu=10.99 loss=183.53 penalty=1.000 ratio=1.042
01/14 01:33:07 saving model to models/sperate/hybrid_all/checkpoints
01/14 01:33:07 finished saving model
01/14 02:14:16 step 118000 epoch 48 learning rate 0.0449 step-time 1.232 loss 0.328
01/14 02:14:16 starting evaluation
01/14 02:19:33 test bleu=11.36 loss=184.31 penalty=1.000 ratio=1.015
01/14 02:19:33 saving model to models/sperate/hybrid_all/checkpoints
01/14 02:19:33 finished saving model
01/14 02:28:03   decaying learning rate to: 0.0426
01/14 03:00:40 step 120000 epoch 49 learning rate 0.0426 step-time 1.232 loss 0.315
01/14 03:00:40 starting evaluation
01/14 03:05:59 test bleu=11.31 loss=184.40 penalty=1.000 ratio=1.032
01/14 03:05:59 saving model to models/sperate/hybrid_all/checkpoints
01/14 03:05:59 finished saving model
01/14 03:24:05   decaying learning rate to: 0.0405
01/14 03:47:07 step 122000 epoch 50 learning rate 0.0405 step-time 1.232 loss 0.299
01/14 03:47:07 starting evaluation
01/14 03:52:25 test bleu=11.51 loss=185.32 penalty=1.000 ratio=1.001
01/14 03:52:25 saving model to models/sperate/hybrid_all/checkpoints
01/14 03:52:25 finished saving model
01/14 04:20:13   decaying learning rate to: 0.0385
01/14 04:33:34 step 124000 epoch 51 learning rate 0.0385 step-time 1.233 loss 0.286
01/14 04:33:34 starting evaluation
01/14 04:38:50 test bleu=11.41 loss=185.85 penalty=1.000 ratio=1.018
01/14 04:38:50 saving model to models/sperate/hybrid_all/checkpoints
01/14 04:38:50 finished saving model
01/14 05:16:05   decaying learning rate to: 0.0365
01/14 05:19:51 step 126000 epoch 52 learning rate 0.0365 step-time 1.228 loss 0.274
01/14 05:19:51 starting evaluation
01/14 05:25:07 test bleu=11.53 loss=185.88 penalty=1.000 ratio=1.001
01/14 05:25:07 saving model to models/sperate/hybrid_all/checkpoints
01/14 05:25:07 finished saving model
01/14 06:06:15 step 128000 epoch 52 learning rate 0.0365 step-time 1.232 loss 0.250
01/14 06:06:15 starting evaluation
01/14 06:11:32 test bleu=11.74 loss=185.68 penalty=1.000 ratio=1.008
01/14 06:11:32 saving model to models/sperate/hybrid_all/checkpoints
01/14 06:11:32 finished saving model
01/14 06:17:24   decaying learning rate to: 0.0347
01/14 06:52:39 step 130000 epoch 53 learning rate 0.0347 step-time 1.232 loss 0.233
01/14 06:52:39 starting evaluation
01/14 06:57:57 test bleu=11.58 loss=185.30 penalty=0.996 ratio=0.996
01/14 06:57:57 saving model to models/sperate/hybrid_all/checkpoints
01/14 06:57:57 finished saving model
01/14 07:13:27   decaying learning rate to: 0.033
01/14 07:39:10 step 132000 epoch 54 learning rate 0.033 step-time 1.235 loss 0.220
01/14 07:39:10 starting evaluation
01/14 07:44:28 test bleu=11.22 loss=186.92 penalty=1.000 ratio=1.026
01/14 07:44:28 saving model to models/sperate/hybrid_all/checkpoints
01/14 07:44:28 finished saving model
01/14 08:09:27   decaying learning rate to: 0.0313
01/14 08:25:32 step 134000 epoch 55 learning rate 0.0313 step-time 1.230 loss 0.212
01/14 08:25:32 starting evaluation
01/14 08:30:49 test bleu=11.57 loss=186.31 penalty=1.000 ratio=1.000
01/14 08:30:49 saving model to models/sperate/hybrid_all/checkpoints
01/14 08:30:49 finished saving model
01/14 09:05:24   decaying learning rate to: 0.0298
01/14 09:11:54 step 136000 epoch 56 learning rate 0.0298 step-time 1.230 loss 0.205
01/14 09:11:54 starting evaluation
01/14 09:17:10 test bleu=11.72 loss=184.66 penalty=0.998 ratio=0.998
01/14 09:17:10 saving model to models/sperate/hybrid_all/checkpoints
01/14 09:17:11 finished saving model
01/14 09:58:21 step 138000 epoch 56 learning rate 0.0298 step-time 1.233 loss 0.193
01/14 09:58:21 starting evaluation
01/14 10:03:37 test bleu=11.39 loss=185.54 penalty=1.000 ratio=1.002
01/14 10:03:37 saving model to models/sperate/hybrid_all/checkpoints
01/14 10:03:37 finished saving model
01/14 10:06:45   decaying learning rate to: 0.0283
01/14 10:44:46 step 140000 epoch 57 learning rate 0.0283 step-time 1.233 loss 0.173
01/14 10:44:46 starting evaluation
01/14 10:50:03 test bleu=11.18 loss=185.91 penalty=1.000 ratio=1.029
01/14 10:50:03 saving model to models/sperate/hybrid_all/checkpoints
01/14 10:50:03 finished saving model
01/14 11:02:51   decaying learning rate to: 0.0269
01/14 11:31:18 step 142000 epoch 58 learning rate 0.0269 step-time 1.235 loss 0.169
01/14 11:31:18 starting evaluation
01/14 11:36:32 test bleu=11.72 loss=187.24 penalty=1.000 ratio=1.000
01/14 11:36:32 saving model to models/sperate/hybrid_all/checkpoints
01/14 11:36:32 finished saving model
01/14 11:58:35   decaying learning rate to: 0.0255
01/14 12:17:45 step 144000 epoch 59 learning rate 0.0255 step-time 1.234 loss 0.164
01/14 12:17:45 starting evaluation
01/14 12:23:08 test bleu=11.71 loss=185.79 penalty=1.000 ratio=1.004
01/14 12:23:08 saving model to models/sperate/hybrid_all/checkpoints
01/14 12:23:08 finished saving model
01/14 12:56:21   decaying learning rate to: 0.0242
01/14 13:05:53 step 146000 epoch 60 learning rate 0.0242 step-time 1.281 loss 0.158
01/14 13:05:53 starting evaluation
01/14 13:11:19 test bleu=11.44 loss=186.67 penalty=1.000 ratio=1.012
01/14 13:11:19 saving model to models/sperate/hybrid_all/checkpoints
01/14 13:11:20 finished saving model
01/14 13:54:05 step 148000 epoch 61 learning rate 0.0242 step-time 1.281 loss 0.156
01/14 13:54:05 starting evaluation
01/14 13:59:28 test bleu=11.82 loss=186.67 penalty=0.981 ratio=0.981
01/14 13:59:28 saving model to models/sperate/hybrid_all/checkpoints
01/14 13:59:29 finished saving model
01/14 13:59:55   decaying learning rate to: 0.023
01/14 14:42:19 step 150000 epoch 61 learning rate 0.023 step-time 1.283 loss 0.134
01/14 14:42:19 starting evaluation
01/14 14:47:43 test bleu=11.36 loss=186.30 penalty=1.000 ratio=1.019
01/14 14:47:43 saving model to models/sperate/hybrid_all/checkpoints
01/14 14:47:43 finished saving model
01/14 14:58:05   decaying learning rate to: 0.0219
01/14 15:30:28 step 152000 epoch 62 learning rate 0.0219 step-time 1.280 loss 0.138
01/14 15:30:28 starting evaluation
01/14 15:35:54 test bleu=11.47 loss=186.48 penalty=1.000 ratio=1.025
01/14 15:35:54 saving model to models/sperate/hybrid_all/checkpoints
01/14 15:35:54 finished saving model
01/14 15:56:18   decaying learning rate to: 0.0208
01/14 16:18:39 step 154000 epoch 63 learning rate 0.0208 step-time 1.280 loss 0.129
01/14 16:18:39 starting evaluation
01/14 16:24:05 test bleu=11.33 loss=187.53 penalty=1.000 ratio=1.023
01/14 16:24:05 saving model to models/sperate/hybrid_all/checkpoints
01/14 16:24:05 finished saving model
01/14 16:54:24   decaying learning rate to: 0.0197
01/14 17:06:47 step 156000 epoch 64 learning rate 0.0197 step-time 1.279 loss 0.130
01/14 17:06:47 starting evaluation
01/14 17:12:13 test bleu=11.69 loss=186.89 penalty=0.995 ratio=0.995
01/14 17:12:13 saving model to models/sperate/hybrid_all/checkpoints
01/14 17:12:13 finished saving model
01/14 17:52:36   decaying learning rate to: 0.0188
01/14 17:55:00 step 158000 epoch 65 learning rate 0.0188 step-time 1.281 loss 0.128
01/14 17:55:00 starting evaluation
01/14 18:00:25 test bleu=11.26 loss=187.66 penalty=1.000 ratio=1.030
01/14 18:00:25 saving model to models/sperate/hybrid_all/checkpoints
01/14 18:00:25 finished saving model
01/14 18:45:30 step 160000 epoch 65 learning rate 0.0188 step-time 1.350 loss 0.113
01/14 18:45:30 starting evaluation
01/14 18:51:16 test bleu=11.65 loss=187.91 penalty=1.000 ratio=1.010
01/14 18:51:16 saving model to models/sperate/hybrid_all/checkpoints
01/14 18:51:16 finished saving model
01/14 18:59:18   decaying learning rate to: 0.0178
01/14 19:36:31 step 162000 epoch 66 learning rate 0.0178 step-time 1.355 loss 0.112
01/14 19:36:31 starting evaluation
01/14 19:42:18 test bleu=11.74 loss=188.39 penalty=0.993 ratio=0.993
01/14 19:42:18 saving model to models/sperate/hybrid_all/checkpoints
01/14 19:42:18 finished saving model
01/14 20:00:49   decaying learning rate to: 0.0169
01/14 20:26:55 step 164000 epoch 67 learning rate 0.0169 step-time 1.336 loss 0.111
01/14 20:26:55 starting evaluation
01/14 20:32:18 test bleu=11.38 loss=187.89 penalty=1.000 ratio=1.029
01/14 20:32:18 saving model to models/sperate/hybrid_all/checkpoints
01/14 20:32:18 finished saving model
01/14 21:00:07   decaying learning rate to: 0.0161
01/14 21:15:17 step 166000 epoch 68 learning rate 0.0161 step-time 1.287 loss 0.107
01/14 21:15:17 starting evaluation
01/14 21:20:47 test bleu=11.54 loss=188.24 penalty=1.000 ratio=1.020
01/14 21:20:47 saving model to models/sperate/hybrid_all/checkpoints
01/14 21:20:48 finished saving model
01/14 21:58:15   decaying learning rate to: 0.0153
01/14 22:03:28 step 168000 epoch 69 learning rate 0.0153 step-time 1.277 loss 0.106
01/14 22:03:28 starting evaluation
01/14 22:09:00 test bleu=11.49 loss=189.59 penalty=1.000 ratio=1.024
01/14 22:09:00 saving model to models/sperate/hybrid_all/checkpoints
01/14 22:09:00 finished saving model
01/14 22:52:00 step 170000 epoch 69 learning rate 0.0153 step-time 1.288 loss 0.099
01/14 22:52:00 starting evaluation
01/14 22:57:23 test bleu=11.65 loss=188.67 penalty=1.000 ratio=1.001
01/14 22:57:23 saving model to models/sperate/hybrid_all/checkpoints
01/14 22:57:23 finished saving model
01/14 23:02:05   decaying learning rate to: 0.0145
01/14 23:40:13 step 172000 epoch 70 learning rate 0.0145 step-time 1.282 loss 0.096
01/14 23:40:13 starting evaluation
01/14 23:45:44 test bleu=11.75 loss=188.72 penalty=1.000 ratio=1.002
01/14 23:45:44 saving model to models/sperate/hybrid_all/checkpoints
01/14 23:45:45 finished saving model
01/15 00:00:39   decaying learning rate to: 0.0138
01/15 00:28:46 step 174000 epoch 71 learning rate 0.0138 step-time 1.288 loss 0.095
01/15 00:28:46 starting evaluation
01/15 00:34:19 test bleu=11.68 loss=189.03 penalty=1.000 ratio=1.007
01/15 00:34:19 saving model to models/sperate/hybrid_all/checkpoints
01/15 00:34:20 finished saving model
01/15 00:59:13   decaying learning rate to: 0.0131
01/15 01:17:18 step 176000 epoch 72 learning rate 0.0131 step-time 1.286 loss 0.091
01/15 01:17:18 starting evaluation
01/15 01:22:48 test bleu=11.67 loss=189.95 penalty=0.993 ratio=0.993
01/15 01:22:48 saving model to models/sperate/hybrid_all/checkpoints
01/15 01:22:48 finished saving model
01/15 01:57:31   decaying learning rate to: 0.0124
01/15 02:05:28 step 178000 epoch 73 learning rate 0.0124 step-time 1.278 loss 0.092
01/15 02:05:28 starting evaluation
01/15 02:11:00 test bleu=11.65 loss=190.15 penalty=1.000 ratio=1.012
01/15 02:11:00 saving model to models/sperate/hybrid_all/checkpoints
01/15 02:11:00 finished saving model
01/15 02:53:44 step 180000 epoch 73 learning rate 0.0124 step-time 1.280 loss 0.089
01/15 02:53:44 starting evaluation
01/15 02:59:13 test bleu=11.72 loss=190.30 penalty=0.998 ratio=0.998
01/15 02:59:13 saving model to models/sperate/hybrid_all/checkpoints
01/15 02:59:13 finished saving model
01/15 03:01:09   decaying learning rate to: 0.0118
01/15 03:42:01 step 182000 epoch 74 learning rate 0.0118 step-time 1.281 loss 0.083
01/15 03:42:01 starting evaluation
01/15 03:47:31 test bleu=11.63 loss=190.80 penalty=1.000 ratio=1.006
01/15 03:47:31 saving model to models/sperate/hybrid_all/checkpoints
01/15 03:47:32 finished saving model
01/15 03:59:24   decaying learning rate to: 0.0112
01/15 04:30:22 step 184000 epoch 75 learning rate 0.0112 step-time 1.283 loss 0.080
01/15 04:30:22 starting evaluation
01/15 04:35:52 test bleu=11.82 loss=190.31 penalty=1.000 ratio=1.002
01/15 04:35:52 saving model to models/sperate/hybrid_all/checkpoints
01/15 04:35:53 finished saving model
01/15 04:57:58   decaying learning rate to: 0.0107
01/15 05:18:58 step 186000 epoch 76 learning rate 0.0107 step-time 1.290 loss 0.082
01/15 05:18:58 starting evaluation
01/15 05:25:28 test bleu=11.78 loss=190.84 penalty=1.000 ratio=1.000
01/15 05:25:28 saving model to models/sperate/hybrid_all/checkpoints
01/15 05:25:29 finished saving model
01/15 06:00:16   decaying learning rate to: 0.0101
01/15 06:12:11 step 188000 epoch 77 learning rate 0.0101 step-time 1.398 loss 0.080
01/15 06:12:11 starting evaluation
01/15 06:18:42 test bleu=11.74 loss=191.58 penalty=1.000 ratio=1.007
01/15 06:18:42 saving model to models/sperate/hybrid_all/checkpoints
01/15 06:18:43 finished saving model
01/15 07:08:25   decaying learning rate to: 0.00963
01/15 07:09:31 step 190000 epoch 78 learning rate 0.00963 step-time 1.521 loss 0.079
01/15 07:09:31 starting evaluation
01/15 07:17:23 test bleu=11.54 loss=191.26 penalty=1.000 ratio=1.011
01/15 07:17:23 saving model to models/sperate/hybrid_all/checkpoints
01/15 07:17:24 finished saving model
01/15 08:10:13 step 192000 epoch 78 learning rate 0.00963 step-time 1.581 loss 0.075
01/15 08:10:13 starting evaluation
01/15 08:18:09 test bleu=11.53 loss=191.80 penalty=1.000 ratio=1.004
01/15 08:18:09 saving model to models/sperate/hybrid_all/checkpoints
01/15 08:18:09 finished saving model
01/15 08:29:28   decaying learning rate to: 0.00915
01/15 09:11:03 step 194000 epoch 79 learning rate 0.00915 step-time 1.584 loss 0.073
01/15 09:11:03 starting evaluation
01/15 09:18:57 test bleu=11.64 loss=191.67 penalty=1.000 ratio=1.000
01/15 09:18:57 saving model to models/sperate/hybrid_all/checkpoints
01/15 09:18:57 finished saving model
01/15 09:42:37   decaying learning rate to: 0.00869
01/15 10:11:55 step 196000 epoch 80 learning rate 0.00869 step-time 1.586 loss 0.072
01/15 10:11:55 starting evaluation
01/15 10:19:53 test bleu=11.76 loss=191.97 penalty=1.000 ratio=1.004
01/15 10:19:53 saving model to models/sperate/hybrid_all/checkpoints
01/15 10:19:53 finished saving model
01/15 10:55:45   decaying learning rate to: 0.00826
01/15 11:12:41 step 198000 epoch 81 learning rate 0.00826 step-time 1.581 loss 0.073
01/15 11:12:41 starting evaluation
01/15 11:20:34 test bleu=11.64 loss=192.39 penalty=1.000 ratio=1.011
01/15 11:20:34 saving model to models/sperate/hybrid_all/checkpoints
01/15 11:20:34 finished saving model
01/15 12:08:48   decaying learning rate to: 0.00784
01/15 12:13:23 step 200000 epoch 82 learning rate 0.00784 step-time 1.581 loss 0.071
01/15 12:13:23 starting evaluation
01/15 12:21:17 test bleu=11.67 loss=191.92 penalty=1.000 ratio=1.010
01/15 12:21:17 saving model to models/sperate/hybrid_all/checkpoints
01/15 12:21:17 finished saving model
01/15 13:14:29 step 202000 epoch 82 learning rate 0.00784 step-time 1.593 loss 0.068
01/15 13:14:29 starting evaluation
01/15 13:22:24 test bleu=11.67 loss=191.93 penalty=1.000 ratio=1.011
01/15 13:22:24 saving model to models/sperate/hybrid_all/checkpoints
01/15 13:22:24 finished saving model
01/15 13:30:10   decaying learning rate to: 0.00745
01/15 14:20:27 step 204000 epoch 83 learning rate 0.00745 step-time 1.738 loss 0.067
01/15 14:20:27 starting evaluation
01/15 14:29:32 test bleu=11.53 loss=192.48 penalty=1.000 ratio=1.019
01/15 14:29:32 saving model to models/sperate/hybrid_all/checkpoints
01/15 14:29:32 finished saving model
01/15 14:52:20   decaying learning rate to: 0.00708
01/15 15:29:29 step 206000 epoch 84 learning rate 0.00708 step-time 1.795 loss 0.066
01/15 15:29:29 starting evaluation
01/15 15:38:35 test bleu=11.77 loss=192.88 penalty=1.000 ratio=1.004
01/15 15:38:35 saving model to models/sperate/hybrid_all/checkpoints
01/15 15:38:35 finished saving model
01/15 16:15:23   decaying learning rate to: 0.00673
01/15 16:38:31 step 208000 epoch 85 learning rate 0.00673 step-time 1.795 loss 0.066
01/15 16:38:31 starting evaluation
01/15 16:47:36 test bleu=11.64 loss=193.30 penalty=1.000 ratio=1.010
01/15 16:47:36 saving model to models/sperate/hybrid_all/checkpoints
01/15 16:47:36 finished saving model
01/15 17:38:09   decaying learning rate to: 0.00639
01/15 17:47:11 step 210000 epoch 86 learning rate 0.00639 step-time 1.784 loss 0.066
01/15 17:47:11 starting evaluation
01/15 17:56:14 test bleu=11.69 loss=192.99 penalty=1.000 ratio=1.004
01/15 17:56:14 saving model to models/sperate/hybrid_all/checkpoints
01/15 17:56:14 finished saving model
01/15 18:55:31 step 212000 epoch 86 learning rate 0.00639 step-time 1.775 loss 0.064
01/15 18:55:31 starting evaluation
01/15 19:04:35 test bleu=11.74 loss=192.85 penalty=1.000 ratio=1.006
01/15 19:04:35 saving model to models/sperate/hybrid_all/checkpoints
01/15 19:04:36 finished saving model
01/15 19:09:22   decaying learning rate to: 0.00607
01/15 20:03:55 step 214000 epoch 87 learning rate 0.00607 step-time 1.777 loss 0.061
01/15 20:03:55 starting evaluation
01/15 20:12:58 test bleu=11.77 loss=193.25 penalty=0.997 ratio=0.997
01/15 20:12:58 saving model to models/sperate/hybrid_all/checkpoints
01/15 20:12:58 finished saving model
01/15 20:31:41   decaying learning rate to: 0.00577
01/15 21:12:34 step 216000 epoch 88 learning rate 0.00577 step-time 1.784 loss 0.061
01/15 21:12:34 starting evaluation
01/15 21:21:36 test bleu=11.86 loss=193.70 penalty=1.000 ratio=1.001
01/15 21:21:36 saving model to models/sperate/hybrid_all/checkpoints
01/15 21:21:36 finished saving model
01/15 21:54:08   decaying learning rate to: 0.00548
01/15 22:21:19 step 218000 epoch 89 learning rate 0.00548 step-time 1.788 loss 0.060
01/15 22:21:19 starting evaluation
01/15 22:30:25 test bleu=11.64 loss=194.14 penalty=1.000 ratio=1.009
01/15 22:30:26 saving model to models/sperate/hybrid_all/checkpoints
01/15 22:30:26 finished saving model
01/15 23:17:23   decaying learning rate to: 0.0052
01/15 23:30:25 step 220000 epoch 90 learning rate 0.0052 step-time 1.797 loss 0.062
01/15 23:30:25 starting evaluation
01/15 23:39:30 test bleu=11.48 loss=194.09 penalty=1.000 ratio=1.012
01/15 23:39:30 saving model to models/sperate/hybrid_all/checkpoints
01/15 23:39:30 finished saving model
01/16 00:39:09 step 222000 epoch 91 learning rate 0.0052 step-time 1.786 loss 0.061
01/16 00:39:09 starting evaluation
01/16 00:48:11 test bleu=11.66 loss=194.21 penalty=1.000 ratio=1.012
01/16 00:48:11 saving model to models/sperate/hybrid_all/checkpoints
01/16 00:48:12 finished saving model
01/16 00:49:04   decaying learning rate to: 0.00494
01/16 01:47:47 step 224000 epoch 91 learning rate 0.00494 step-time 1.785 loss 0.058
01/16 01:47:47 starting evaluation
01/16 01:56:52 test bleu=11.76 loss=194.39 penalty=1.000 ratio=1.003
01/16 01:56:52 saving model to models/sperate/hybrid_all/checkpoints
01/16 01:56:52 finished saving model
01/16 02:11:35   decaying learning rate to: 0.0047
01/16 02:56:09 step 226000 epoch 92 learning rate 0.0047 step-time 1.775 loss 0.057
01/16 02:56:09 starting evaluation
01/16 03:05:13 test bleu=11.75 loss=194.27 penalty=1.000 ratio=1.001
01/16 03:05:13 saving model to models/sperate/hybrid_all/checkpoints
01/16 03:05:14 finished saving model
01/16 03:33:56   decaying learning rate to: 0.00446
01/16 04:04:46 step 228000 epoch 93 learning rate 0.00446 step-time 1.783 loss 0.056
01/16 04:04:46 starting evaluation
01/16 04:13:50 test bleu=11.77 loss=194.78 penalty=0.996 ratio=0.996
01/16 04:13:50 saving model to models/sperate/hybrid_all/checkpoints
01/16 04:13:50 finished saving model
01/16 04:56:16   decaying learning rate to: 0.00424
01/16 05:13:12 step 230000 epoch 94 learning rate 0.00424 step-time 1.778 loss 0.058
01/16 05:13:12 starting evaluation
01/16 05:22:14 test bleu=11.78 loss=194.70 penalty=0.999 ratio=0.999
01/16 05:22:14 saving model to models/sperate/hybrid_all/checkpoints
01/16 05:22:15 finished saving model
